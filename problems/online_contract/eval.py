import pickle
import time

import numpy as np
from scipy.optimize import linprog
import sys

from os import path
import logging
from utils.utils import extract_contract_elements
from utils.utils import get_func_name
sys.path.insert(0, path.abspath(path.join(path.dirname(__file__), '../..', '..')))
from problems.online_contract import gpt

possible_func_names = ["agent_solver", "agent_solver_v1", "agent_solver_v2", "agent_solver_v3"]

func_name = get_func_name(gpt, possible_func_names)
llm_agent_solver = getattr(gpt, func_name)


def contract_oracle_solver(p, c, v):
    # --------------------------------------------------------------------
    # assume you already have:
    #   p         : np.ndarray, shape (n_actions, m_outcomes)
    #   costs     : np.ndarray, shape (n_actions,)     # your c vector
    #   v         : np.ndarray, shape (m_outcomes,)
    #   n_actions = p.shape[0]
    # --------------------------------------------------------------------
    n_actions = p.shape[0]
    epsilon = 1e-8  # small slack to enforce strict IC/IR
    tol = 1e-6  # tolerance for post‐solve check

    best_princ_util = -np.inf
    best_contract = None
    best_action = None

    for a_star in range(n_actions):
        # 1) objective: minimize p[a_star]·w
        c_lp = p[a_star].copy()

        # 2) build IC constraints in one go
        #    (p[a] - p[a_star])·w <= costs[a] - costs[a_star] - ε
        IC_A = p - p[a_star]  # shape (n_actions, m_outcomes)
        IC_b = c - c[a_star] - epsilon
        mask = np.arange(n_actions) != a_star
        A_ub = IC_A[mask]
        b_ub = IC_b[mask]

        # 3) IR constraint: -p[a_star]·w <= -costs[a_star] - ε
        A_ub = np.vstack([A_ub, -p[a_star]])
        b_ub = np.append(b_ub, -c[a_star] - epsilon)

        # 4) bounds: 0 ≤ w_i ≤ v_i
        bounds = [(0, v_i) for v_i in v]

        # 5) solve with Highs
        res = linprog(
            c=c_lp,
            A_ub=A_ub,
            b_ub=b_ub,
            bounds=bounds,
            method='highs',
        )
        if not res.success:
            continue

        w_opt = res.x

        # 6) verify IC with tolerance
        agent_utils = p.dot(w_opt) - c
        max_util = agent_utils.max()
        if agent_utils[a_star] + tol < max_util:
            # still violating IC
            print(
                f"IC violation for a*={a_star}: best at {np.argmax(agent_utils)} (Δ={max_util - agent_utils[a_star]:.2e})")
            continue

        # 7) compute principal’s utility
        princ_util = p[a_star].dot(v - w_opt)
        if princ_util > best_princ_util:
            best_princ_util = princ_util
            best_contract = w_opt.copy()
            best_action = a_star

    print("→ Best principal utility:", best_princ_util)
    # print("→ Best action index:   ", best_action)
    # print("→ Best contract w:      ", best_contract)
    # print("→ Best agent utility:   ", (p.dot(best_contract) - c).max())

    return best_princ_util, best_contract


def evaluate_llm(contract_elements: tuple):
    p, c, v, contract_logs = contract_elements

    oracle_best_prin_u, _ = contract_oracle_solver(p, c, v)

    # This contract is generated by the llm generated method or code
    content = contract_logs.to_dict(orient="records")
    # The inferred agent setting should be a ndarray in a shape of (inferred_n_actions, m_outcomes+1)
    time_start = time.time()
    inferred_agent_setting = llm_agent_solver(v, content)
    time_end = time.time()
    print(f"The running time is：{time_end - time_start:.4f} seconds")
    inferred_p = inferred_agent_setting[:, :-1]
    inferred_c = inferred_agent_setting[:, -1].reshape(-1)
    _, inferred_contract = contract_oracle_solver(inferred_p, inferred_c, v)

    agent_u = np.dot(p, inferred_contract) - c
    agent_inx = np.argmax(agent_u)
    real_agent_u = agent_u[agent_inx]
    real_prin_u = np.dot(p[agent_inx], (v - inferred_contract))
    print("→ Inferred agent&principal utility:   ", real_agent_u, real_prin_u)

    _flag = 1 if real_agent_u < -0.1 else 0

    # Step 1: Check agent IR
    if real_agent_u < 0:
        real_prin_u = 0.0

    # Step 2: Compute components, oracle_best_prin_u is a constant since p,c,v are fixed, so oracle_best_prin_u
    # is redundant here. The only reason of add it here, is to ensure the utility score is positive
    prin_gap = oracle_best_prin_u - real_prin_u
    ir_penalty = max(0, -real_agent_u)

    # Step 3: Combine
    _obj = prin_gap + ir_penalty
    print("→ Agent and principal score:   ", ir_penalty, prin_gap)

    return _obj, _flag


def extract_data(dataset_path):
    with open(dataset_path, "rb") as f:
        data = pickle.load(f)
        agent_setting = data["agent_setting"]
        contract_logs = data["contract_logs"]
        v = data["v"]

    print(f"[*] Dataset loaded: {dataset_path} with {n_instances} instances.")
    p, c = extract_contract_elements(agent_setting)

    return p, c, v, contract_logs


if __name__ == '__main__':
    print("[*] Running ...")

    # n_actions and m_outcomes are only used for validation, which are 100 and 5 by default during the training phase
    _n_actions = int(sys.argv[1])
    _m_outcomes = int(sys.argv[2])
    mode = sys.argv[3]
    n_instances = 5

    # Identical with the path in the gen_instance.py
    dataset_path = path.join(path.dirname(__file__), "dataset")

    if mode == 'train':
        obj_list = []
        for i in range(n_instances):
            _dataset_path = path.join(dataset_path, f"train_0{i + 1}.pkl")
            _p, _c, _v, _contract_logs = extract_data(_dataset_path)
            obj, _ = evaluate_llm((_p, _c, _v, _contract_logs))
            print(f"[*] Instance {i}: {obj}")
            obj_list.append(obj)

        print("[*] Average:")
        print(np.mean(obj_list))
    else:
        obj_list = []
        flag_list = []
        for i in range(n_instances):
            _dataset_path = path.join(dataset_path, f"eval{_n_actions}_{_m_outcomes}_0{i + 1}.pkl")
            _p, _c, _v, _contract_logs = extract_data(_dataset_path)
            logging.info(f"[*] Evaluating {_dataset_path}")
            obj, flag = evaluate_llm((_p, _c, _v, _contract_logs))
            flag_list.append(flag)
            obj_list.append(obj)
        print(f"[*] Average IR violation rate is {np.mean(flag_list):.4f}")
        print(f"[*] Average for the problem setting of {_n_actions}-{_m_outcomes}: {np.mean(obj_list)}")
