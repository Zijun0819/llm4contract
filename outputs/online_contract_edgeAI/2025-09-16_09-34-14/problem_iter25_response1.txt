```python
import numpy as np
from scipy.optimize import linprog
from sklearn.mixture import GaussianMixture

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    n_candidates = 10
    m_outcomes = v.shape[0]
    L = len(content)

    def mini_lp_p(w: np.ndarray, u: float) -> np.ndarray | None:
        m = len(w)
        A_eq = [np.ones(m), v - w]
        b_eq = [1.0, u]
        bounds = [(0, 1)] * m
        res = linprog(-w, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        return res.x if res.success else None

    candidate_ps = []
    for log in content:
        if log['Agent Action'] == 1:
            w_i = np.array(log['Contract'])
            u_i = log['Principal Utility']
            p_i = mini_lp_p(w_i, u_i)
            if p_i is not None:
                candidate_ps.append(p_i)

    if not candidate_ps:
        raise ValueError("No valid accepted logs to infer agent strategies.")

    all_p = np.array(candidate_ps)

    n_components = min(n_candidates, len(candidate_ps), int(np.sqrt(len(candidate_ps))))
    gmm = GaussianMixture(n_components=n_components, random_state=0, n_init=10, max_iter=2000, tol=1e-6, reg_covar=1e-6).fit(all_p)
    p0 = gmm.means_

    assigns = np.full(L, -1, dtype=int)
    for i, log in enumerate(content):
        if log['Agent Action'] == 1:
            w = np.array(log['Contract'])
            assigns[i] = int(np.argmax(p0 @ w))

    c_ir = np.zeros(n_components)
    for a in range(n_components):
        idx = np.where(assigns == a)[0]
        if idx.size > 0:
            wages = np.array([content[i]['Contract'] for i in idx]).T
            c_ir[a] = p0[a] @ wages.min(axis=1)
        else:
            c_ir[a] = 0.0

    rej_idx = [i for i, log in enumerate(content) if log['Agent Action'] == -1]
    if rej_idx:
        wages_rej = np.array([content[i]['Contract'] for i in rej_idx]).T
        rej_utils = p0 @ wages_rej
        c_rej = rej_utils.max(axis=0)
    else:
        c_rej = np.zeros(n_components)

    c_init = np.maximum(c_ir, c_rej)
    c_init = np.clip(c_init, 0, None)  # Ensure non-negativity

    # L1 regularization
    alpha = 0.01
    c_init_l1 = (1 - alpha) * c_init + alpha * np.mean(c_init)

    # L2 regularization
    beta = 0.001
    c_init_l2 = c_init / (1 + beta * n_components)

    # Elastic Net regularization
    gamma = 0.005
    c_init_en = c_init / (1 + gamma * np.sum(np.abs(c_init)))

    # Additional regularization to handle high-dimensional data
    delta = 0.001
    c_init_hd = c_init / (1 + delta * np.linalg.norm(c_init))

    # Choose the best regularization technique based on the data
    reg_techniques = [c_init_l1, c_init_l2, c_init_en, c_init_hd]
    best_reg = np.argmin([np.sum(np.abs(c)) for c in reg_techniques])
    c_init = reg_techniques[best_reg]

    agent_setting = np.hstack([p0, c_init[:, np.newaxis]])
    return agent_setting
```
