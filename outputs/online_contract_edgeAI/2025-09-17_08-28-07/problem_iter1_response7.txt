```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog, minimize
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from itertools import combinations

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    m_outcomes = len(v)
    L = len(content)
    
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    if not accepted_logs:
        return np.array([[1/m_outcomes] * m_outcomes + [0]])
    
    def solve_dual_lp(w, u):
        c = np.concatenate([w, [0]])
        A_eq = np.array([np.concatenate([v - w, [1]])])
        b_eq = np.array([u])
        A_ub = np.array([np.concatenate([-np.eye(m_outcomes), np.zeros((m_outcomes, 1))]),
                        np.concatenate([np.eye(m_outcomes), np.zeros((m_outcomes, 1))])])
        b_ub = np.concatenate([np.zeros(m_outcomes), np.ones(m_outcomes)])
        bounds = [(None, None)] * (m_outcomes + 1)
        
        res = linprog(c, A_eq=A_eq, b_eq=b_eq, A_ub=A_ub, b_ub=b_ub, method='highs')
        if res.success:
            p = res.x[:m_outcomes]
            p = np.maximum(p, 0)
            p = p / np.sum(p) if np.sum(p) > 0 else np.ones(m_outcomes) / m_outcomes
            return p
        return None
    
    candidate_ps = []
    utilities = []
    
    for log in accepted_logs:
        w = np.array(log['Contract'])
        u = log['Principal Utility']
        utilities.append(u)
        
        p = solve_dual_lp(w, u)
        if p is not None:
            candidate_ps.append(p)
        else:
            uniform_p = np.ones(m_outcomes) / m_outcomes
            candidate_ps.append(uniform_p)
    
    if len(candidate_ps) < 2:
        p_matrix = np.array([np.ones(m_outcomes) / m_outcomes])
        costs = np.array([0.0])
    else:
        candidate_ps = np.array(candidate_ps)
        utilities = np.array(utilities)
        
        pca = PCA(n_components=min(3, len(candidate_ps)))
        ps_transformed = pca.fit_transform(candidate_ps)
        
        n_clusters = min(max(2, len(candidate_ps) // 5), 8)
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20)
        cluster_labels = kmeans.fit_predict(ps_transformed)
        
        p_matrix = []
        costs = []
        
        for cluster_id in range(n_clusters):
            cluster_mask = cluster_labels == cluster_id
            if np.sum(cluster_mask) == 0:
                continue
                
            cluster_ps = candidate_ps[cluster_mask]
            cluster_utilities = utilities[cluster_mask]
            
            weights = cluster_utilities / np.sum(cluster_utilities)
            p_avg = np.average(cluster_ps, axis=0, weights=weights)
            p_avg = np.maximum(p_avg, 1e-6)
            p_avg = p_avg / np.sum(p_avg)
            
            cluster_wages = [np.array(accepted_logs[i]['Contract']) 
                           for i in range(len(accepted_logs)) if cluster_mask[i]]
            
            if cluster_wages:
                expected_payments = [p_avg @ w for w in cluster_wages]
                cost = np.percentile(expected_payments, 25)
            else:
                cost = 0.0
            
            p_matrix.append(p_avg)
            costs.append(max(cost, 0.0))
    
    if rejected_logs:
        rejected_wages = [np.array(log['Contract']) for log in rejected_logs]
        
        for i, p in enumerate(p_matrix):
            rejected_utilities = [p @ w for w in rejected_wages]
            if rejected_utilities:
                max_rejected_util = np.max(rejected_utilities)
                costs[i] = max(costs[i], max_rejected_util + 1e-6)
    
    p_matrix = np.array(p_matrix)
    costs = np.array(costs)
    
    def refine_actions(p_mat, cost_vec):
        n_actions = len(p_mat)
        
        def objective(params):
            p_flat = params[:n_actions * m_outcomes].reshape(n_actions, m_outcomes)
            c_vec = params[n_actions * m_outcomes:]
            
            penalty = 0
            
            for i, p_row in enumerate(p_flat):
                if np.sum(p_row) <= 0:
                    penalty += 1000
                else:
                    p_norm = p_row / np.sum(p_row)
                    if np.any(p_norm < 0):
                        penalty += 1000
            
            for log in accepted_logs:
                w = np.array(log['Contract'])
                best_util = -np.inf
                for j in range(n_actions):
                    if np.sum(p_flat[j]) > 0:
                        p_norm = p_flat[j] / np.sum(p_flat[j])
                        util = p_norm @ w - c_vec[j]
                        best_util = max(best_util, util)
                
                if best_util < -1e-6:
                    penalty += (abs(best_util) + 1e-6) * 100
            
            for log in rejected_logs:
                w = np.array(log['Contract'])
                for j in range(n_actions):
                    if np.sum(p_flat[j]) > 0:
                        p_norm = p_flat[j] / np.sum(p_flat[j])
                        util = p_norm @ w - c_vec[j]
                        if util >= 1e-6:
                            penalty += (util + 1e-6) * 100
            
            return penalty + np.sum((p_flat - p_mat)**2) + np.sum((c_vec - cost_vec)**2)
        
        x0 = np.concatenate([p_mat.flatten(), cost_vec])
        
        bounds = [(1e-6, 1)] * (n_actions * m_outcomes) + [(0, None)] * n_actions
        
        constraints = []
        for i in range(n_actions):
            def sum_constraint(x, action_idx=i):
                p_flat = x[:n_actions * m_outcomes].reshape(n_actions, m_outcomes)
                return np.sum(p_flat[action_idx]) - 1.0
            
            constraints.append({'type': 'eq', 'fun': sum_constraint})
        
        try:
            result = minimize(objective, x0, bounds=bounds, constraints=constraints, 
                            method='SLSQP', options={'maxiter': 1000})
            
            if result.success:
                p_opt = result.x[:n_actions * m_outcomes].reshape(n_actions, m_outcomes)
                c_opt = result.x[n_actions * m_outcomes:]
                
                for i in range(n_actions):
                    p_opt[i] = np.maximum(p_opt[i], 1e-6)
                    p_opt[i] = p_opt[i] / np.sum(p_opt[i])
                
                return p_opt, np.maximum(c_opt, 0)
        except:
            pass
        
        return p_mat, cost_vec
    
    p_matrix, costs = refine_actions(p_matrix, costs)
    
    agent_setting = np.hstack([p_matrix, costs.reshape(-1, 1)])
    
    return agent_setting
```
