```python
import numpy as np
import pandas as pd
from scipy.optimize import minimize, linprog
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
import warnings
warnings.filterwarnings('ignore')

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    m_outcomes = len(v)
    L = len(content)
    
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    if not accepted_logs:
        default_p = np.ones(m_outcomes) / m_outcomes
        default_c = 0.01
        return np.hstack([default_p.reshape(1, -1), np.array([[default_c]])])
    
    def solve_dual_p(w, u):
        c = -np.array(w)
        A_eq = np.array([np.ones(m_outcomes), v - np.array(w)])
        b_eq = np.array([1.0, u])
        bounds = [(0, 1)] * m_outcomes
        res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        return res.x if res.success else None
    
    candidate_ps = []
    utilities = []
    
    for log in accepted_logs:
        w = log['Contract']
        u = log['Principal Utility']
        p = solve_dual_p(w, u)
        if p is not None and np.all(p >= 0) and np.abs(np.sum(p) - 1) < 1e-6:
            candidate_ps.append(p)
            utilities.append(u)
    
    if not candidate_ps:
        default_p = np.ones(m_outcomes) / m_outcomes
        default_c = 0.01
        return np.hstack([default_p.reshape(1, -1), np.array([[default_c]])])
    
    candidate_ps = np.array(candidate_ps)
    utilities = np.array(utilities)
    
    n_actions = min(max(2, len(candidate_ps) // 5), 8)
    
    if len(candidate_ps) >= n_actions:
        gmm = GaussianMixture(n_components=n_actions, random_state=42, covariance_type='full')
        gmm.fit(candidate_ps)
        p_centers = gmm.means_
        
        for i in range(n_actions):
            p_centers[i] = np.maximum(p_centers[i], 1e-8)
            p_centers[i] /= np.sum(p_centers[i])
    else:
        p_centers = candidate_ps.copy()
        n_actions = len(p_centers)
    
    action_assignments = []
    for p in candidate_ps:
        distances = [np.linalg.norm(p - center) for center in p_centers]
        action_assignments.append(np.argmin(distances))
    
    costs = np.zeros(n_actions)
    
    for a in range(n_actions):
        assigned_indices = [i for i, assignment in enumerate(action_assignments) if assignment == a]
        
        if assigned_indices:
            assigned_wages = [accepted_logs[i]['Contract'] for i in assigned_indices]
            min_utilities = [np.dot(p_centers[a], w) for w in assigned_wages]
            costs[a] = max(0, min(min_utilities) - 1e-6)
        else:
            costs[a] = 1e-6
    
    if rejected_logs:
        rejected_wages = [log['Contract'] for log in rejected_logs]
        for a in range(n_actions):
            max_rejected_utility = max([np.dot(p_centers[a], w) for w in rejected_wages])
            costs[a] = max(costs[a], max_rejected_utility + 1e-6)
    
    def objective(x):
        n = int(len(x) / (m_outcomes + 1))
        ps = x[:n*m_outcomes].reshape(n, m_outcomes)
        cs = x[n*m_outcomes:]
        
        penalty = 0
        for i in range(n):
            penalty += max(0, abs(np.sum(ps[i]) - 1) - 1e-6) * 1000
            penalty += sum(max(0, -ps[i][j]) * 1000 for j in range(m_outcomes))
            penalty += max(0, -cs[i]) * 1000
        
        consistency_penalty = 0
        for i, log in enumerate(accepted_logs):
            w = log['Contract']
            best_action = np.argmax([np.dot(ps[a], w) - cs[a] for a in range(n)])
            if np.dot(ps[best_action], w) - cs[best_action] < -1e-6:
                consistency_penalty += 1000
        
        for i, log in enumerate(rejected_logs):
            w = log['Contract']
            max_utility = max([np.dot(ps[a], w) - cs[a] for a in range(n)])
            if max_utility >= 1e-6:
                consistency_penalty += 1000
        
        return penalty + consistency_penalty
    
    x0 = np.hstack([p_centers.flatten(), costs])
    
    bounds = [(1e-8, 1)] * (n_actions * m_outcomes) + [(1e-8, None)] * n_actions
    
    constraints = []
    for i in range(n_actions):
        def make_constraint(idx):
            def constraint(x):
                ps = x[:n_actions*m_outcomes].reshape(n_actions, m_outcomes)
                return np.sum(ps[idx]) - 1
            return constraint
        constraints.append({'type': 'eq', 'fun': make_constraint(i)})
    
    try:
        result = minimize(objective, x0, bounds=bounds, constraints=constraints, method='SLSQP')
        if result.success:
            optimized_ps = result.x[:n_actions*m_outcomes].reshape(n_actions, m_outcomes)
            optimized_cs = result.x[n_actions*m_outcomes:]
            
            for i in range(n_actions):
                optimized_ps[i] = np.maximum(optimized_ps[i], 1e-8)
                optimized_ps[i] /= np.sum(optimized_ps[i])
                optimized_cs[i] = max(optimized_cs[i], 1e-8)
            
            agent_setting = np.hstack([optimized_ps, optimized_cs.reshape(-1, 1)])
        else:
            for i in range(n_actions):
                p_centers[i] = np.maximum(p_centers[i], 1e-8)
                p_centers[i] /= np.sum(p_centers[i])
                costs[i] = max(costs[i], 1e-8)
            agent_setting = np.hstack([p_centers, costs.reshape(-1, 1)])
    except:
        for i in range(n_actions):
            p_centers[i] = np.maximum(p_centers[i], 1e-8)
            p_centers[i] /= np.sum(p_centers[i])
            costs[i] = max(costs[i], 1e-8)
        agent_setting = np.hstack([p_centers, costs.reshape(-1, 1)])
    
    return agent_setting
```
