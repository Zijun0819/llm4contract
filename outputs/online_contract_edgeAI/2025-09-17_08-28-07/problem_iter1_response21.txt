```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog, minimize
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from itertools import combinations

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    m_outcomes = len(v)
    L = len(content)
    
    def extract_contracts_and_actions():
        contracts = []
        actions = []
        utilities = []
        for log in content:
            contracts.append(np.array(log['Contract']))
            actions.append(log['Agent Action'])
            utilities.append(log['Principal Utility'])
        return np.array(contracts), np.array(actions), np.array(utilities)
    
    contracts, actions, utilities = extract_contracts_and_actions()
    accepted_idx = np.where(actions == 1)[0]
    rejected_idx = np.where(actions == -1)[0]
    
    def generate_candidate_distributions():
        candidates = []
        
        # Uniform distribution
        candidates.append(np.ones(m_outcomes) / m_outcomes)
        
        # Extreme distributions (concentrated on single outcomes)
        for i in range(m_outcomes):
            dist = np.zeros(m_outcomes)
            dist[i] = 1.0
            candidates.append(dist)
        
        # High-value focused distributions
        sorted_idx = np.argsort(v)[::-1]
        for k in range(2, min(6, m_outcomes + 1)):
            dist = np.zeros(m_outcomes)
            dist[sorted_idx[:k]] = 1.0 / k
            candidates.append(dist)
        
        # Random sparse distributions
        np.random.seed(42)
        for _ in range(5):
            dist = np.random.exponential(1, m_outcomes)
            dist = dist / np.sum(dist)
            candidates.append(dist)
        
        # PCA-based distributions from accepted contracts
        if len(accepted_idx) > 1:
            try:
                pca = PCA(n_components=min(3, len(accepted_idx)))
                pca_result = pca.fit_transform(contracts[accepted_idx])
                for i in range(pca.n_components_):
                    weights = np.abs(pca.components_[i])
                    weights = weights / np.sum(weights)
                    candidates.append(weights)
            except:
                pass
        
        return np.array(candidates)
    
    def solve_dual_problem(p_candidates):
        n_actions = len(p_candidates)
        
        # Solve for costs that satisfy all constraints
        def objective(costs):
            penalty = 0
            
            # IR constraint penalty for accepted contracts
            for i in accepted_idx:
                w = contracts[i]
                max_util = max(p_candidates[a] @ w - costs[a] for a in range(n_actions))
                if max_util < -1e-6:
                    penalty += (max_util) ** 2
            
            # IC constraint penalty for rejected contracts
            for i in rejected_idx:
                w = contracts[i]
                max_util = max(p_candidates[a] @ w - costs[a] for a in range(n_actions))
                if max_util > 1e-6:
                    penalty += (max_util) ** 2
            
            # Regularization
            penalty += 0.01 * np.sum(costs ** 2)
            
            return penalty
        
        # Initial guess
        x0 = np.zeros(n_actions)
        for a in range(n_actions):
            if len(accepted_idx) > 0:
                min_payment = np.min([p_candidates[a] @ contracts[i] for i in accepted_idx])
                x0[a] = max(0, min_payment * 0.9)
        
        # Bounds (costs must be non-negative)
        bounds = [(0, None) for _ in range(n_actions)]
        
        result = minimize(objective, x0, bounds=bounds, method='L-BFGS-B')
        
        return result.x if result.success else x0
    
    def adaptive_clustering(base_candidates, target_size=8):
        if len(base_candidates) <= target_size:
            return base_candidates
        
        # Use KMeans to reduce to target size
        kmeans = KMeans(n_clusters=target_size, random_state=42, n_init=10)
        kmeans.fit(base_candidates)
        return kmeans.cluster_centers_
    
    def validate_and_refine(p_matrix, costs):
        n_actions = len(p_matrix)
        
        # Check constraint satisfaction
        violation_count = 0
        
        for i in accepted_idx:
            w = contracts[i]
            max_util = max(p_matrix[a] @ w - costs[a] for a in range(n_actions))
            if max_util < -1e-6:
                violation_count += 1
        
        for i in rejected_idx:
            w = contracts[i]
            max_util = max(p_matrix[a] @ w - costs[a] for a in range(n_actions))
            if max_util > 1e-6:
                violation_count += 1
        
        # If too many violations, adjust costs
        if violation_count > len(content) * 0.1:
            for a in range(n_actions):
                if len(accepted_idx) > 0:
                    min_accepted = min(p_matrix[a] @ contracts[i] for i in accepted_idx)
                    costs[a] = max(costs[a], min_accepted * 0.95)
                
                if len(rejected_idx) > 0:
                    max_rejected = max(p_matrix[a] @ contracts[i] for i in rejected_idx)
                    costs[a] = max(costs[a], max_rejected + 1e-6)
        
        return costs
    
    # Main algorithm
    base_candidates = generate_candidate_distributions()
    p_matrix = adaptive_clustering(base_candidates, target_size=6)
    
    # Ensure probability constraints
    for i in range(len(p_matrix)):
        p_matrix[i] = np.maximum(p_matrix[i], 0)
        p_matrix[i] = p_matrix[i] / np.sum(p_matrix[i])
    
    # Solve for costs
    costs = solve_dual_problem(p_matrix)
    costs = validate_and_refine(p_matrix, costs)
    costs = np.maximum(costs, 0)
    
    # Construct final agent setting
    agent_setting = np.column_stack([p_matrix, costs])
    
    return agent_setting
```
