```python
import numpy as np
import pandas as pd
from scipy.optimize import minimize, linprog
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
import itertools

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    m_outcomes = len(v)
    L = len(content)
    
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    if not accepted_logs:
        return np.array([[1/m_outcomes] * m_outcomes + [0.0]])
    
    def extract_features(log):
        contract = np.array(log['Contract'])
        principal_util = log['Principal Utility']
        return np.concatenate([contract, [principal_util]])
    
    accepted_features = np.array([extract_features(log) for log in accepted_logs])
    
    if len(accepted_logs) < 3:
        n_actions = 2
    else:
        n_actions = min(5, max(2, len(accepted_logs) // 3))
    
    gmm = GaussianMixture(n_components=n_actions, random_state=42, max_iter=200)
    cluster_labels = gmm.fit_predict(accepted_features)
    
    agent_actions = []
    
    for cluster_id in range(n_actions):
        cluster_indices = np.where(cluster_labels == cluster_id)[0]
        
        if len(cluster_indices) == 0:
            prob_dist = np.ones(m_outcomes) / m_outcomes
            cost = 0.0
        else:
            cluster_contracts = [np.array(accepted_logs[i]['Contract']) for i in cluster_indices]
            cluster_utils = [accepted_logs[i]['Principal Utility'] for i in cluster_indices]
            
            def objective(p):
                p = np.abs(p)
                p = p / np.sum(p)
                total_error = 0
                for j, contract in enumerate(cluster_contracts):
                    expected_payment = np.dot(p, contract)
                    expected_value = np.dot(p, v)
                    predicted_util = expected_value - expected_payment
                    actual_util = cluster_utils[j]
                    total_error += (predicted_util - actual_util) ** 2
                entropy_reg = -np.sum(p * np.log(p + 1e-10))
                return total_error - 0.01 * entropy_reg
            
            initial_p = np.random.dirichlet([1] * m_outcomes)
            
            constraints = [{'type': 'eq', 'fun': lambda p: np.sum(p) - 1}]
            bounds = [(0.001, 0.999)] * m_outcomes
            
            result = minimize(objective, initial_p, method='SLSQP', 
                            bounds=bounds, constraints=constraints, 
                            options={'maxiter': 1000})
            
            if result.success:
                prob_dist = np.abs(result.x)
                prob_dist = prob_dist / np.sum(prob_dist)
            else:
                prob_dist = np.ones(m_outcomes) / m_outcomes
            
            cluster_payments = [np.dot(prob_dist, contract) for contract in cluster_contracts]
            min_payment = min(cluster_payments) if cluster_payments else 0.0
            cost = max(0.0, min_payment * 0.95)
        
        agent_actions.append(np.concatenate([prob_dist, [cost]]))
    
    if rejected_logs:
        rejected_contracts = [np.array(log['Contract']) for log in rejected_logs]
        
        for i, action in enumerate(agent_actions):
            prob_dist = action[:m_outcomes]
            max_rejected_utility = 0.0
            
            for contract in rejected_contracts:
                utility = np.dot(prob_dist, contract)
                max_rejected_utility = max(max_rejected_utility, utility)
            
            current_cost = action[m_outcomes]
            adjusted_cost = max(current_cost, max_rejected_utility + 1e-6)
            agent_actions[i][m_outcomes] = adjusted_cost
    
    return np.array(agent_actions)
```
