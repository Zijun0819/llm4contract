```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog, minimize
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
import itertools

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    m_outcomes = len(v)
    L = len(content)
    
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    if not accepted_logs:
        return np.array([[1/m_outcomes] * m_outcomes + [0]])
    
    def solve_dual_p(w, u):
        c = -np.array(w)
        A_eq = np.array([np.ones(m_outcomes), v - np.array(w)])
        b_eq = np.array([1.0, u])
        bounds = [(0, None)] * m_outcomes
        
        res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            return res.x
        return None
    
    candidate_distributions = []
    for log in accepted_logs:
        w = log['Contract']
        u = log['Principal Utility']
        p = solve_dual_p(w, u)
        if p is not None and np.all(p >= -1e-10):
            p = np.maximum(p, 0)
            p = p / np.sum(p) if np.sum(p) > 0 else np.ones(m_outcomes) / m_outcomes
            candidate_distributions.append(p)
    
    if not candidate_distributions:
        return np.array([[1/m_outcomes] * m_outcomes + [0]])
    
    X = np.array(candidate_distributions)
    
    n_actions = min(max(2, len(accepted_logs) // 10 + 1), 8)
    
    if len(X) >= n_actions:
        gm = GaussianMixture(n_components=n_actions, random_state=42, max_iter=200)
        gm.fit(X)
        action_probs = gm.means_
    else:
        kmeans = KMeans(n_clusters=n_actions, random_state=42, n_init=20)
        kmeans.fit(X)
        action_probs = kmeans.cluster_centers_
    
    action_probs = np.maximum(action_probs, 1e-8)
    action_probs = action_probs / action_probs.sum(axis=1, keepdims=True)
    
    costs = np.zeros(n_actions)
    
    for a in range(n_actions):
        p_a = action_probs[a]
        
        min_utility = float('inf')
        for log in accepted_logs:
            w = log['Contract']
            utility = np.dot(p_a, w)
            min_utility = min(min_utility, utility)
        
        if min_utility != float('inf'):
            costs[a] = max(0, min_utility - 1e-6)
    
    for log in rejected_logs:
        w = log['Contract']
        for a in range(n_actions):
            p_a = action_probs[a]
            utility = np.dot(p_a, w)
            costs[a] = max(costs[a], utility + 1e-5)
    
    def consistency_penalty():
        penalty = 0
        for log in content:
            w = np.array(log['Contract'])
            action = log['Agent Action']
            
            best_utility = -float('inf')
            best_action = -1
            
            for a in range(n_actions):
                p_a = action_probs[a]
                c_a = costs[a]
                utility = np.dot(p_a, w) - c_a
                if utility > best_utility:
                    best_utility = utility
                    best_action = a
            
            if action == 1 and best_utility < -1e-6:
                penalty += abs(best_utility)
            elif action == -1 and best_utility > 1e-6:
                penalty += best_utility
        
        return penalty
    
    def objective(x):
        global action_probs, costs
        costs = x
        return consistency_penalty() + 0.01 * np.sum(costs**2)
    
    from scipy.optimize import minimize
    result = minimize(objective, costs, method='L-BFGS-B', 
                     bounds=[(0, 10)] * n_actions)
    if result.success:
        costs = result.x
    
    costs = np.maximum(costs, 0)
    
    agent_setting = np.hstack([action_probs, costs.reshape(-1, 1)])
    return agent_setting
```
