[2025-09-17 07:41:28,868][root][INFO] - Workspace: ]8;;file://E:\Coding\pythonProject\llm4contract\outputs\online_contract_edgeAI\2025-09-17_07-41-28\E:\Coding\pythonProject\llm4contract\outputs\online_contract_edgeAI\2025-09-17_07-41-28]8;;\
[2025-09-17 07:41:28,868][root][INFO] - Project Root: ]8;;file://E:\Coding\pythonProject\llm4contract\E:\Coding\pythonProject\llm4contract]8;;\
[2025-09-17 07:41:28,868][root][INFO] - Using LLM: gemini-2.5-flash
[2025-09-17 07:41:30,957][root][INFO] - Problem: online_contract_edgeAI
[2025-09-17 07:41:30,957][root][INFO] - Problem description: Inferring a valid agent setting via "agent_solver" that satisfies all historical interaction logs between the principal and agent regarding an online contract design problem.
[2025-09-17 07:41:30,968][root][INFO] - Function name: agent_solver
[2025-09-17 07:41:30,979][root][INFO] - Evaluating seed function...
[2025-09-17 07:41:30,979][root][INFO] - Seed function code: 
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import KMeans


def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    n_candidates = 7
    m_outcomes = v.shape[0]
    L = len(content)

    def mini_lp_p(w: np.ndarray, u: float) -> np.ndarray | None:
        """Solve for agent outcome distribution p given wage vector w and utility u."""
        m = len(w)
        A_eq = [np.ones(m), v - w]
        b_eq = [1.0, u]
        bounds = [(0, 1)] * m
        res = linprog(w, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        return res.x if res.success else None

    # Step 1: Filter accepted contracts and solve mini LPs
    candidate_ps = []
    for log in content:
        if log['Agent Action'] == 1:
            w_i = log['Contract']
            u_i = log['Principal Utility']
            p_i = mini_lp_p(w_i, u_i)
            if p_i is not None:
                candidate_ps.append(p_i)

    if not candidate_ps:
        raise ValueError("No valid accepted logs to infer agent strategies.")

    all_p = np.array(candidate_ps)

    # Step 2: Cluster inferred p vectors
    kmeans = KMeans(n_clusters=n_candidates, random_state=0, n_init=10).fit(all_p)
    p0 = kmeans.cluster_centers_

    # Step 3: Assign each accepted log to best-fitting action
    assigns = np.full(L, -1, dtype=int)
    for i, log in enumerate(content):
        if log['Agent Action'] == 1:
            w = log['Contract']
            assigns[i] = int(np.argmax(p0 @ w))

    # Step 4: Compute IR-consistent cost for each action
    c_ir = np.zeros(n_candidates)
    for a in range(n_candidates):
        idx = np.where(assigns == a)[0]
        if idx.size > 0:
            wages = np.array([content[i]['Contract'] for i in idx]).T
            c_ir[a] = p0[a] @ wages.min(axis=1)
        else:
            c_ir[a] = 0.0

    # Step 5: Ensure rejection consistency
    rej_idx = [i for i, log in enumerate(content) if log['Agent Action'] == -1]
    if rej_idx:
        wages_rej = np.array([content[i]['Contract'] for i in rej_idx]).T
        rej_utils = p0 @ wages_rej
        c_rej = rej_utils.max(axis=1)
    else:
        c_rej = np.zeros(n_candidates)

    # Step 6: Final cost = max(IR, rejection threshold)
    c_init = np.maximum(c_ir, c_rej)

    # Step 7: Format agent setting
    agent_setting = np.hstack([p0, c_init[:, np.newaxis]])
    return agent_setting
[2025-09-17 07:41:30,979][root][INFO] - Iteration 0: Running Code 0
[2025-09-17 07:41:33,635][root][INFO] - Iteration 0: Code Run 0 successful! (see ]8;;file://E:\Coding\pythonProject\llm4contract\outputs\online_contract_edgeAI\2025-09-17_07-41-28\problem_iter0_stdout0.txt\stdout]8;;\)
[2025-09-17 07:41:35,129][root][INFO] - Iteration 0, response_id 0: Objective value: 0.0002915838738214187
[2025-09-17 07:41:35,129][root][INFO] - Iteration 0: Elitist: 0.0002915838738214187
[2025-09-17 07:41:35,130][root][INFO] - Best obj: 0.0002915838738214187, Best Code Path: ]8;;file://E:\Coding\pythonProject\llm4contract\outputs\online_contract_edgeAI\2025-09-17_07-41-28\problem_iter0_response0.txt\problem_iter0_code0.py]8;;\
[2025-09-17 07:41:35,130][root][INFO] - Iteration 0 finished...
[2025-09-17 07:41:35,130][root][INFO] - Function Evals: 1
[2025-09-17 07:41:35,130][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are an expert in the domain of online learning contract design. Your task is to infer a valid agent setting upon historical interaction logs between the principal and the agent, so as to effectively augment the principal's utility under the agent's IR and IC constraints.
Your response outputs Python code without annotation and nothing else. Please ensure the generated Python code is complete, robust, and runnable. Format your code as a Python code string: "```python ... ```".
User Prompt: 
Write a agent_solver function for Inferring a valid agent setting via "agent_solver" that satisfies all historical interaction logs between the principal and agent regarding an online contract design problem.

The `agent_solver` function takes a principal's reward 'v' and historical interaction logs between the principal and the agent 'content' as inputs. Notably, Each log includes:

- Contract: a 12-dimensional payment vector for 12 outcomes,
- Principal Utility: principal's utility under the contract, which will be zero if the agent rejects the contract,
- Agent Action: where `1` indicates acceptance (expected utility ¡Ý 0) and `-1` indicates rejection (expected utility < 0).

The function returns an inferred valid agent setting represented by an n \times (12 + 1) matrix:

- The number of actions n can be adaptively selected to sufficiently explain the data.
- Each row corresponds to a possible agent action.
- The first 12 columns are probabilities over the 12 outcomes (summing to 1).
- The final column is the agent's cost (non-negative) of performing that action.

The 'v' example is shown as:
[0.00030864 0.00034612 0.0003836  0.00042108 0.00045856 0.00049603
 0.00053351 0.00057098 0.00060845 0.00064593 0.00068339 0.00072086]
The 'content' example is shown as:
                                             Contract  ...  Agent Action
0   [0.00048462001738628946, 0.0003518371354986871...  ...             1
1   [0.0005969043600751138, 0.000159726691207727, ...  ...             1
2   [0.0006477983805553537, 0.0003980847732223108,...  ...             1
3   [0.00016959469101641172, 7.6079774319487e-05, ...  ...             1
4   [0.00036553431748904844, 0.0005816466308603646...  ...             1
..                                                ...  ...           ...
95  [0.0006912695365717878, 1.8941655778408166e-05...  ...             1
96  [0.0001619004548222183, 0.0006209899250736761,...  ...             1
97  [0.0003015832142848912, 8.734102922542198e-05,...  ...             1
98  [0.0004232348302242724, 0.0002444499816337658,...  ...             1
99  [0.00014323942361522658, 0.0001113720688359591...  ...             1

[100 rows x 3 columns].
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import KMeans


def agent_solver_v1(v: np.ndarray, content: list[dict]) -> np.ndarray:
    n_candidates = 7
    m_outcomes = v.shape[0]
    L = len(content)

    def mini_lp_p(w: np.ndarray, u: float) -> np.ndarray | None:
        """Solve for agent outcome distribution p given wage vector w and utility u."""
        m = len(w)
        A_eq = [np.ones(m), v - w]
        b_eq = [1.0, u]
        bounds = [(0, 1)] * m
        res = linprog(w, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        return res.x if res.success else None

    # Step 1: Filter accepted contracts and solve mini LPs
    candidate_ps = []
    for log in content:
        if log['Agent Action'] == 1:
            w_i = log['Contract']
            u_i = log['Principal Utility']
            p_i = mini_lp_p(w_i, u_i)
            if p_i is not None:
                candidate_ps.append(p_i)

    if not candidate_ps:
        raise ValueError("No valid accepted logs to infer agent strategies.")

    all_p = np.array(candidate_ps)

    # Step 2: Cluster inferred p vectors
    kmeans = KMeans(n_clusters=n_candidates, random_state=0, n_init=10).fit(all_p)
    p0 = kmeans.cluster_centers_

    # Step 3: Assign each accepted log to best-fitting action
    assigns = np.full(L, -1, dtype=int)
    for i, log in enumerate(content):
        if log['Agent Action'] == 1:
            w = log['Contract']
            assigns[i] = int(np.argmax(p0 @ w))

    # Step 4: Compute IR-consistent cost for each action
    c_ir = np.zeros(n_candidates)
    for a in range(n_candidates):
        idx = np.where(assigns == a)[0]
        if idx.size > 0:
            wages = np.array([content[i]['Contract'] for i in idx]).T
            c_ir[a] = p0[a] @ wages.min(axis=1)
        else:
            c_ir[a] = 0.0

    # Step 5: Ensure rejection consistency
    rej_idx = [i for i, log in enumerate(content) if log['Agent Action'] == -1]
    if rej_idx:
        wages_rej = np.array([content[i]['Contract'] for i in rej_idx]).T
        rej_utils = p0 @ wages_rej
        c_rej = rej_utils.max(axis=1)
    else:
        c_rej = np.zeros(n_candidates)

    # Step 6: Final cost = max(IR, rejection threshold)
    c_init = np.maximum(c_ir, c_rej)

    # Step 7: Format agent setting
    agent_setting = np.hstack([p0, c_init[:, np.newaxis]])
    return agent_setting


Refer to the format of a trivial design above. Be very creative and give `agent_solver_v2`. Output code only without any comments and enclose your code with Python code block: ```python ... ```. Please ensure the generated Python code is complete.


[2025-09-17 07:41:35,176][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,223][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,239][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,255][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,303][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,535][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,643][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,659][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,676][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,676][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,738][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,738][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,769][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,784][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,816][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:41:35,971][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:28,832][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:28,834][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,837][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:28,837][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:28,838][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:28,847][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:28,848][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:28,849][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,851][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,851][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,852][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,852][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,853][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,853][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,857][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,857][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,859][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,859][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,921][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:28,922][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,922][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,938][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:28,939][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:28,939][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,060][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:29,061][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,062][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,361][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:29,363][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,363][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,366][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:29,367][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,369][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,371][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:29,371][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,372][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,413][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:29,415][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,415][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,459][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:29,460][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,461][utils.llm_clients.base][INFO] - Attempt 1 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:29,860][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:29,860][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:29,860][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:29,860][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:29,860][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:29,861][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:29,923][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:29,954][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:30,064][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:30,377][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:30,377][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:30,377][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:30,424][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:30,471][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:36,594][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:36,595][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:36,595][utils.llm_clients.base][INFO] - Attempt 2 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:37,609][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:39,844][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:39,845][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:39,846][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:39,847][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:39,847][utils.llm_clients.base][INFO] - Attempt 3 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:39,849][utils.llm_clients.base][INFO] - Attempt 2 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:39,851][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-09-17 07:42:39,852][utils.llm_clients.base][ERROR] - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\base.py", line 31, in chat_completion
    response_cur = self._chat_completion_api(messages, temperature, n)
  File "E:\Coding\pythonProject\llm4contract\utils\llm_clients\gemini.py", line 50, in _chat_completion_api
    response = self.client.models.generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 6565, in generate_content
    response = self._generate_content(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\models.py", line 5377, in _generate_content
    response = self._api_client.request(
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1290, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1126, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "D:\Software\anaconda3\envs\llm4contract\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\_api_client.py", line 1103, in _request_once
    errors.APIError.raise_for_response(response)
  File "D:\Software\anaconda3\envs\llm4contract\lib\site-packages\google\genai\errors.py", line 110, in raise_for_response
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:39,852][utils.llm_clients.base][INFO] - Attempt 2 failed with error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
[2025-09-17 07:42:40,858][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:40,858][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:42:40,859][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:44:10,024][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:44:10,028][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:44:10,818][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:45:13,278][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:45:13,279][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:45:13,610][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:45:17,453][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:45:17,456][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:45:17,793][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:45:17,795][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:45:17,986][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:45:18,283][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:45:20,328][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:45:20,329][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:45:20,512][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:45:20,513][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:45:20,669][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:45:20,856][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:45:23,156][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:45:23,158][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:45:23,311][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:45:32,085][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:45:32,086][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:45:32,255][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:45:47,348][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:45:47,351][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:45:48,221][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:45:57,308][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:45:57,309][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:45:57,756][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:45:58,386][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:45:58,387][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:45:58,635][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:45:59,452][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:45:59,453][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:46:00,282][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:46:26,145][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:46:26,148][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:46:26,932][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:46:48,438][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:46:48,441][google_genai.models][INFO] - AFC remote call 1 is done.
[2025-09-17 07:46:49,057][google_genai.models][INFO] - AFC is enabled with max remote calls: 10.
[2025-09-17 07:46:59,191][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-09-17 07:46:59,193][google_genai.models][INFO] - AFC remote call 1 is done.
