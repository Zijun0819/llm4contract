```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog, minimize, LinearConstraint, Bounds
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture

def agent_solver(v: np.ndarray, content: list[dict]) -> np.ndarray:
    n_candidates = 12
    m_outcomes = len(v)
    L = len(content)
    
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    if not accepted_logs:
        raise ValueError("No accepted logs to infer agent strategies.")

    def solve_p_opt(w, u):
        res = linprog(w, A_eq=[np.ones(m_outcomes), v - w], b_eq=[1.0, u], bounds=[(0,1)]*m_outcomes, method='highs')
        return res.x if res.success else None

    candidate_p = []
    for log in accepted_logs:
        p_opt = solve_p_opt(log['Contract'], log['Principal Utility'])
        if p_opt is not None:
            candidate_p.append(p_opt)
    
    if not candidate_p:
        raise ValueError("No valid p vectors from accepted logs.")

    candidate_p = np.array(candidate_p)
    if len(candidate_p) > n_candidates:
        gmm = GaussianMixture(n_components=n_candidates, random_state=0).fit(candidate_p)
        p0 = gmm.means_
    else:
        p0 = candidate_p
        n_candidates = len(p0)
    
    def cost_lp(a):
        c_lb = []
        for log in accepted_logs:
            w = np.array(log['Contract'])
            if p0[a] @ w >= 0:
                c_lb.append(p0[a] @ w)
        return max(c_lb) if c_lb else 0.0

    c_min = np.array([cost_lp(a) for a in range(n_candidates)])
    
    rejection_constraints = np.zeros(n_candidates)
    if rejected_logs:
        for log in rejected_logs:
            w_rej = np.array(log['Contract'])
            for a in range(n_candidates):
                if p0[a] @ w_rej > rejection_constraints[a]:
                    rejection_constraints[a] = p0[a] @ w_rej
    
    c_final = np.maximum(c_min, rejection_constraints)
    
    refinement_mask = np.any(p0 > 1e-6, axis=1)
    p0_refined = p0[refinement_mask]
    c_final_refined = c_final[refinement_mask]
    
    agent_setting = np.hstack([p0_refined, c_final_refined.reshape(-1,1)])
    return agent_setting
```
