```python
import numpy as np
from scipy.optimize import linprog, minimize
from sklearn.mixture import GaussianMixture
from sklearn.neighbors import KernelDensity
import warnings
warnings.filterwarnings('ignore')

def agent_solver(v: np.ndarray, content: list) -> np.ndarray:
    n_outcomes = len(v)
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    if not content:
        uniform_p = np.ones(n_outcomes) / n_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])
    
    def solve_p(w, u_target):
        c = -w
        A_eq = np.vstack([np.ones(n_outcomes), v - w])
        b_eq = np.array([1.0, u_target])
        bounds = [(0, 1) for _ in range(n_outcomes)]
        res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs', options={'tol': 1e-12})
        if res.success:
            p = res.x
            if np.all(p >= -1e-12) and abs(np.sum(p) - 1) < 1e-12:
                return np.clip(p, 0, 1)
        return None

    candidate_ps = []
    for log in accepted_logs:
        w = np.array(log['Contract'])
        u_target = log['Principal Utility']
        p = solve_p(w, u_target)
        if p is not None:
            candidate_ps.append(p)
    
    if not candidate_ps:
        candidate_ps = [np.ones(n_outcomes) / n_outcomes]
    
    X = np.array(candidate_ps)
    n_actions = min(10, len(X))
    if len(X) > 1:
        n_components_range = range(1, n_actions + 1)
        bics = []
        for n in n_components_range:
            gmm = GaussianMixture(n_components=n, random_state=42, n_init=10, max_iter=200, tol=1e-12)
            gmm.fit(X)
            bics.append(gmm.bic(X))
        best_n = n_components_range[np.argmin(bics)]
        gmm = GaussianMixture(n_components=best_n, random_state=42, n_init=10, max_iter=200, tol=1e-12)
        gmm.fit(X)
        p0 = gmm.means_
        kde = KernelDensity(kernel='gaussian', bandwidth=0.05)
        kde.fit(p0)
        log_dens = kde.score_samples(p0)
        weights = np.exp(log_dens - np.max(log_dens))
        weights /= weights.sum()
        p0 = p0 * weights[:, np.newaxis]
        p0 = np.clip(p0, 0, 1)
        row_sums = p0.sum(axis=1, keepdims=True)
        p0 = np.where(row_sums > 0, p0 / row_sums, 1/n_outcomes)
    else:
        p0 = X
    
    n_actions = len(p0)
    costs_init = np.zeros(n_actions)
    for i in range(n_actions):
        p_i = p0[i]
        min_accept = float('inf')
        for log in accepted_logs:
            w = np.array(log['Contract'])
            util = np.dot(p_i, w)
            if util < min_accept:
                min_accept = util
        costs_init[i] = min_accept if min_accept != float('inf') else 0.0
        
        for log in rejected_logs:
            w = np.array(log['Contract'])
            util = np.dot(p_i, w)
            if util >= costs_init[i]:
                costs_init[i] = util + 1e-12
    
    def objective(params):
        p_flat = params[:n_actions * n_outcomes].reshape(n_actions, n_outcomes)
        c = params[n_actions * n_outcomes: n_actions * n_outcomes + n_actions]
        penalty = 0.0
        ir_ic_weight = 1e6
        
        for log in content:
            w = np.array(log['Contract'])
            agent_utils = np.array([np.dot(p, w) - cost for p, cost in zip(p_flat, c)])
            max_agent_util = np.max(agent_utils)
            
            if log['Agent Action'] == 1:
                if max_agent_util < -1e-12:
                    penalty += ir_ic_weight * (-max_agent_util)
                best_action = np.argmax(agent_utils)
                principal_util_actual = np.dot(p_flat[best_action], v - w)
                penalty += (principal_util_actual - log['Principal Utility']) ** 2
            else:
                if max_agent_util >= -1e-12:
                    penalty += ir_ic_weight * max_agent_util
        
        for i in range(n_actions):
            p_sum = np.sum(p_flat[i])
            if not np.isclose(p_sum, 1.0, atol=1e-12):
                penalty += ir_ic_weight * (p_sum - 1.0) ** 2
            neg_penalty = np.sum(np.clip(-p_flat[i], 0, None))
            penalty += ir_ic_weight * neg_penalty
        
        return penalty
    
    constraints = [
        {'type': 'eq', 'fun': lambda x, i=i: np.sum(x[i*n_outcomes:(i+1)*n_outcomes]) - 1.0}
        for i in range(n_actions)
    ]
    
    bounds = [(0, 1)] * (n_actions * n_outcomes) + [(0, None)] * n_actions
    x0 = np.concatenate([p0.flatten(), costs_init])
    
    res = minimize(
        objective, 
        x0, 
        method='SLSQP', 
        bounds=bounds, 
        constraints=constraints, 
        options={'maxiter': 100000, 'ftol': 1e-12, 'disp': False}
    )
    
    x_opt = res.x
    p_opt = x_opt[:n_actions * n_outcomes].reshape(n_actions, n_outcomes)
    c_opt = x_opt[n_actions * n_outcomes: n_actions * n_outcomes + n_actions]
    
    valid_rows = []
    for i in range(n_actions):
        if np.all(p_opt[i] >= -1e-12) and np.isclose(np.sum(p_opt[i]), 1.0, atol=1e-12) and c_opt[i] >= -1e-12:
            valid_rows.append(i)
    
    if not valid_rows:
        uniform_p = np.ones(n_outcomes) / n_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])
    
    p_final = p_opt[valid_rows]
    c_final = c_opt[valid_rows]
    
    return np.hstack([p_final, c_final.reshape(-1, 1)])
```
