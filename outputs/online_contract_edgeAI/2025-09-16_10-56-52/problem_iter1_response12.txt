```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog, minimize
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
from scipy.special import softmax

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    m_outcomes = len(v)
    n_candidates = min(15, len(content) // 10)
    n_candidates = max(3, n_candidates)
    
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    def solve_p(w, u_target):
        c = -w
        A_eq = np.vstack([np.ones(m_outcomes), v - w])
        b_eq = np.array([1.0, u_target])
        bounds = [(0, 1) for _ in range(m_outcomes)]
        res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        return res.x if res.success else None

    candidate_ps = []
    candidate_utils = []
    for log in accepted_logs:
        p = solve_p(np.array(log['Contract']), log['Principal Utility'])
        if p is not None:
            candidate_ps.append(p)
            candidate_utils.append(np.dot(p, np.array(log['Contract'])))
    
    if not candidate_ps:
        candidate_ps = [np.ones(m_outcomes) / m_outcomes]
        candidate_utils = [0.0]
    
    X = np.array(candidate_ps)
    if len(X) > n_candidates:
        gmm = GaussianMixture(n_components=n_candidates, random_state=0, n_init=5)
        gmm.fit(X)
        p0 = gmm.means_
        weights = gmm.weights_
    else:
        p0 = X
        weights = np.ones(len(X)) / len(X)
    
    n_candidates = len(p0)
    assignments = {}
    utility_thresholds = np.zeros(n_candidates)
    
    for a in range(n_candidates):
        relevant_logs = []
        for i, log in enumerate(accepted_logs):
            w = np.array(log['Contract'])
            if np.argmax([np.dot(p, w) for p in p0]) == a:
                relevant_logs.append((w, np.dot(p0[a], w)))
        if relevant_logs:
            wages, utils = zip(*relevant_logs)
            utility_thresholds[a] = min(utils)
        else:
            utility_thresholds[a] = 0.0
    
    rej_thresholds = np.full(n_candidates, -np.inf)
    for log in rejected_logs:
        w = np.array(log['Contract'])
        for a in range(n_candidates):
            u = np.dot(p0[a], w)
            if u > rej_thresholds[a]:
                rej_thresholds[a] = u
    
    costs = np.maximum(utility_thresholds, rej_thresholds)
    costs = np.where(np.isfinite(costs), costs, 0.0)
    costs = np.clip(costs, 0, None)
    
    def refine_params(params):
        p_flat = params[:n_candidates * m_outcomes].reshape(n_candidates, m_outcomes)
        c = params[n_candidates * m_outcomes:]
        penalty = 0.0
        for log in content:
            w = np.array(log['Contract'])
            u_vals = [np.dot(p, w) - cost for p, cost in zip(p_flat, c)]
            max_u = max(u_vals)
            if log['Agent Action'] == 1:
                if max_u < 0:
                    penalty += (max_u ** 2) * 100
                best_a = np.argmax(u_vals)
                if np.abs(np.dot(p_flat[best_a], v - w) - log['Principal Utility']) > 1e-6:
                    penalty += (np.dot(p_flat[best_a], v - w) - log['Principal Utility']) ** 2 * 100
            else:
                if max_u >= 0:
                    penalty += (max_u ** 2) * 100
        return penalty
    
    initial_params = np.concatenate([p0.flatten(), costs])
    bounds = [(0, 1)] * (n_candidates * m_outcomes) + [(0, None)] * n_candidates
    constraints = []
    for i in range(n_candidates):
        def sum_constraint(params, idx=i):
            p = params[idx*m_outcomes:(idx+1)*m_outcomes]
            return np.sum(p) - 1
        constraints.append({'type': 'eq', 'fun': sum_constraint})
    
    res = minimize(refine_params, initial_params, bounds=bounds, constraints=constraints, method='SLSQP', tol=1e-8)
    if res.success:
        optimized_params = res.x
        p_opt = optimized_params[:n_candidates * m_outcomes].reshape(n_candidates, m_outcomes)
        c_opt = optimized_params[n_candidates * m_outcomes:]
        agent_setting = np.hstack([p_opt, c_opt.reshape(-1, 1)])
    else:
        agent_setting = np.hstack([p0, costs.reshape(-1, 1)])
    
    return agent_setting
```
