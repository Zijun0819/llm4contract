```python
import numpy as np
from scipy.optimize import minimize, linprog
from sklearn.mixture import GaussianMixture
import warnings
warnings.filterwarnings('ignore')

def agent_solver(v: np.ndarray, content: list[dict]) -> np.ndarray:
    n_outcomes = len(v)
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    if not accepted_logs:
        return np.hstack([np.ones((1, n_outcomes)) / n_outcomes, np.zeros((1, 1))])
    
    def solve_feasible_p(w, u_target):
        c = -w
        A_eq = np.vstack([np.ones(n_outcomes), v - w])
        b_eq = np.array([1.0, u_target])
        bounds = [(0, 1) for _ in range(n_outcomes)]
        res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        return res.x if res.success else None
    
    candidate_ps = []
    for log in accepted_logs:
        p_candidate = solve_feasible_p(np.array(log['Contract']), log['Principal Utility'])
        if p_candidate is not None:
            candidate_ps.append(p_candidate)
    
    if not candidate_ps:
        candidate_ps = [np.ones(n_outcomes) / n_outcomes]
    
    X = np.array(candidate_ps)
    n_candidates = min(20, max(3, len(X) // 5))
    
    if len(X) > n_candidates:
        bics = []
        models = []
        for n_comp in range(1, min(11, len(X))):
            gmm = GaussianMixture(n_components=n_comp, random_state=0, n_init=10, max_iter=200)
            gmm.fit(X)
            bics.append(gmm.bic(X))
            models.append(gmm)
        best_idx = np.argmin(bics)
        best_gmm = models[best_idx]
        p0 = best_gmm.means_
        labels = best_gmm.predict(X)
    else:
        p0 = X
        labels = np.arange(len(p0))
    
    n_actions = len(p0)
    
    utility_thresholds = np.full(n_actions, np.inf)
    for idx, log in enumerate(accepted_logs):
        w = np.array(log['Contract'])
        if idx < len(labels):
            a_label = labels[idx]
        else:
            dists = np.array([np.linalg.norm(p - w) for p in p0])
            a_label = np.argmin(dists)
        u_val = np.dot(p0[a_label], w)
        if u_val < utility_thresholds[a_label]:
            utility_thresholds[a_label] = u_val
    
    rej_thresholds = np.full(n_actions, -np.inf)
    for log in rejected_logs:
        w = np.array(log['Contract'])
        for a in range(n_actions):
            u_val = np.dot(p0[a], w)
            if u_val > rej_thresholds[a]:
                rej_thresholds[a] = u_val
    
    cost_initial = np.maximum(utility_thresholds, rej_thresholds, np.zeros(n_actions))
    cost_initial = np.where(np.isfinite(cost_initial), cost_initial, 0.0)
    
    def objective(params):
        p_flat = params[:n_actions * n_outcomes].reshape(n_actions, n_outcomes)
        c = params[n_actions * n_outcomes: n_actions * n_outcomes + n_actions]
        penalty = 0.0
        
        for log in content:
            w = np.array(log['Contract'])
            u_vals = np.array([np.dot(p, w) - cost for p, cost in zip(p_flat, c)])
            max_u = np.max(u_vals)
            best_a = np.argmax(u_vals)
            
            if log['Agent Action'] == 1:
                if max_u < 0:
                    penalty += (0 - max_u) ** 2
                principal_util = np.dot(p_flat[best_a], v - w)
                penalty += (log['Principal Utility'] - principal_util) ** 2
            else:
                if max_u >= 0:
                    penalty += (max_u - 0) ** 2
        
        for p in p_flat:
            penalty += 1e-6 * np.sum(np.maximum(0, -p)) + 1e-6 * np.sum(np.maximum(0, p - 1))
        for cost_val in c:
            penalty += 1e-6 * np.maximum(0, -cost_val)
        
        return penalty
    
    constraints = []
    for i in range(n_actions):
        constraints.append({'type': 'eq', 'fun': lambda x, idx=i: np.sum(x[idx*n_outcomes:(idx+1)*n_outcomes]) - 1})
    
    bounds = [(0, 1) for _ in range(n_actions * n_outcomes)] + [(0, None) for _ in range(n_actions)]
    initial_params = np.concatenate([p0.flatten(), cost_initial])
    
    res = minimize(objective, initial_params, method='SLSQP', bounds=bounds, constraints=constraints, tol=1e-6, options={'maxiter': 1000})
    
    if res.success:
        optimized_params = res.x
        p_opt = optimized_params[:n_actions * n_outcomes].reshape(n_actions, n_outcomes)
        c_opt = optimized_params[n_actions * n_outcomes: n_actions * n_outcomes + n_actions]
    else:
        p_opt, c_opt = p0, cost_initial
    
    return np.hstack([p_opt, c_opt.reshape(-1, 1)])
```
