```python
import numpy as np
from scipy.optimize import minimize, Bounds, NonlinearConstraint, LinearConstraint
from sklearn.mixture import GaussianMixture

def agent_solver(v: np.ndarray, content: list) -> np.ndarray:
    warnings.filterwarnings('ignore')
    n_outcomes = len(v)
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    if not accepted_logs:
        return np.hstack([np.ones((1, n_outcomes)) / n_outcomes, np.zeros((1, 1))])
    
    candidate_ps = []
    for log in accepted_logs:
        w = np.array(log['Contract'])
        u_target = log['Principal Utility']
        c = -w
        A_eq = np.vstack([np.ones(n_outcomes), v - w])
        b_eq = np.array([1.0, u_target])
        res = minimize(lambda x: np.dot(c, x), 
                      x0=np.ones(n_outcomes)/n_outcomes, 
                      constraints=[{'type': 'eq', 'fun': lambda x: A_eq @ x - b_eq}],
                      bounds=[(0,1)]*n_outcomes,
                      method='SLSQP')
        if res.success:
            candidate_ps.append(res.x)
    
    if not candidate_ps:
        candidate_ps = [np.ones(n_outcomes) / n_outcomes]
    
    X = np.array(candidate_ps)
    max_clusters = min(10, len(X))
    bics = []
    models = []
    for n_comp in range(1, max_clusters+1):
        gmm = GaussianMixture(n_components=n_comp, random_state=0, n_init=5)
        gmm.fit(X)
        bics.append(gmm.bic(X))
        models.append(gmm)
    best_gmm = models[np.argmin(bics)]
    n_actions = best_gmm.n_components
    p0 = best_gmm.means_
    c0 = np.zeros(n_actions)
    
    for i in range(n_actions):
        min_util = np.inf
        for log in accepted_logs:
            w = np.array(log['Contract'])
            util = np.dot(p0[i], w)
            if util < min_util:
                min_util = util
        max_rej = -np.inf
        for log in rejected_logs:
            w = np.array(log['Contract'])
            util = np.dot(p0[i], w)
            if util > max_rej:
                max_rej = util
        c0[i] = max(0, min_util, max_rej, 0) + 1e-10
    
    x0 = np.concatenate([p0.flatten(), c0])
    
    def objective(x):
        p = x[:n_actions*n_outcomes].reshape(n_actions, n_outcomes)
        c = x[n_actions*n_outcomes:]
        penalty = 0.0
        for log in content:
            w = np.array(log['Contract'])
            utilities = p @ w - c
            max_u = np.max(utilities)
            best_action = np.argmax(utilities)
            if log['Agent Action'] == 1:
                if max_u < 0:
                    penalty += (max_u)**2 * 1000
                principal_util = np.dot(p[best_action], v - w)
                penalty += (principal_util - log['Principal Utility'])**2
            else:
                if max_u >= 0:
                    penalty += (max_u)**2 * 1000
        return penalty
    
    constraints = []
    for i in range(n_actions):
        constraints.append(LinearConstraint(
            np.eye(n_outcomes, n_actions*n_outcomes, i*n_outcomes), 
            0, 1
        ))
        constraints.append(LinearConstraint(
            np.ones((1, n_outcomes)) @ np.eye(n_outcomes, n_actions*n_outcomes, i*n_outcomes), 
            1, 1
        ))
    constraints.append(LinearConstraint(
        np.eye(n_actions, len(x0), n_actions*n_outcomes), 
        0, None
    ))
    
    bounds = Bounds([0]*len(x0), [1]*(n_actions*n_outcomes) + [np.inf]*n_actions)
    
    res = minimize(objective, x0, method='trust-constr', bounds=bounds, constraints=constraints, options={'maxiter': 1000})
    
    if res.success:
        x_opt = res.x
    else:
        x_opt = x0
    
    p_opt = x_opt[:n_actions*n_outcomes].reshape(n_actions, n_outcomes)
    c_opt = x_opt[n_actions*n_outcomes:]
    return np.hstack([p_opt, c_opt.reshape(-1,1)])
```
