```python
def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    import numpy as np
    from scipy.optimize import linprog, minimize
    from sklearn.mixture import GaussianMixture
    import warnings
    warnings.filterwarnings('ignore')
    
    n_outcomes = len(v)
    logs = content
    
    if not logs:
        uniform_p = np.ones(n_outcomes) / n_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])
    
    accepted_logs = [log for log in logs if log['Agent Action'] == 1]
    rejected_logs = [log for log in logs if log['Agent Action'] == -1]
    
    sample_weights = []
    candidate_ps = []
    
    for log in accepted_logs:
        w = np.array(log['Contract'])
        u_target = log['Principal Utility']
        c = -w
        A_eq = np.vstack([np.ones(n_outcomes), v - w])
        b_eq = np.array([1.0, u_target])
        bounds = [(0, 1) for _ in range(n_outcomes)]
        res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs', options={'tol': 1e-10})
        if res.success:
            p = res.x
            if np.all(p >= -1e-8) and np.isclose(np.sum(p), 1.0, atol=1e-8):
                candidate_ps.append(p)
                sample_weights.append(1.0)
    
    for log in rejected_logs:
        w = np.array(log['Contract'])
        c = -w
        A_eq = np.ones((1, n_outcomes))
        b_eq = np.array([1.0])
        bounds = [(0, 1) for _ in range(n_outcomes)]
        res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs', options={'tol': 1e-10})
        if res.success:
            p = res.x
            if np.all(p >= -1e-8) and np.isclose(np.sum(p), 1.0, atol=1e-8):
                candidate_ps.append(p)
                sample_weights.append(10.0)
    
    if not candidate_ps:
        uniform_p = np.ones(n_outcomes) / n_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])
    
    X = np.array(candidate_ps)
    weights = np.array(sample_weights)
    
    max_components = min(20, len(X))
    n_components_range = range(1, max_components + 1)
    bics = []
    gmm_models = []
    
    for n in n_components_range:
        gmm = GaussianMixture(n_components=n, random_state=42, n_init=50, max_iter=2000, tol=1e-10)
        if len(weights) == len(X):
            gmm.fit(X, sample_weight=weights)
        else:
            gmm.fit(X)
        bics.append(gmm.bic(X))
        gmm_models.append(gmm)
    
    best_idx = np.argmin(bics)
    best_gmm = gmm_models[best_idx]
    p0 = best_gmm.means_
    n_actions = len(p0)
    
    utility_thresholds = np.full(n_actions, np.inf)
    for log in accepted_logs:
        w = np.array(log['Contract'])
        dists = np.array([np.linalg.norm(p - w) for p in p0])
        a_label = np.argmin(dists)
        u = np.dot(p0[a_label], w)
        if u < utility_thresholds[a_label]:
            utility_thresholds[a_label] = u
    
    rej_thresholds = np.full(n_actions, -np.inf)
    for log in rejected_logs:
        w = np.array(log['Contract'])
        dists = np.array([np.linalg.norm(p - w) for p in p0])
        a_label = np.argmin(dists)
        u = np.dot(p0[a_label], w)
        if u > rej_thresholds[a_label]:
            rej_thresholds[a_label] = u
    
    costs_init = np.maximum(utility_thresholds, rej_thresholds + 1e-10)
    costs_init = np.clip(costs_init, 0, None)
    
    def objective(params):
        p_flat = params[:n_actions * n_outcomes].reshape(n_actions, n_outcomes)
        c = params[n_actions * n_outcomes: n_actions * n_outcomes + n_actions]
        penalty = 0.0
        ir_ic_weight = 10000.0
        
        for log in logs:
            w = np.array(log['Contract'])
            u_vals = np.array([np.dot(p, w) - cost_val for p, cost_val in zip(p_flat, c)])
            max_u = np.max(u_vals)
            
            if log['Agent Action'] == 1:
                if max_u < -1e-8:
                    penalty += ir_ic_weight * (max_u ** 2)
                best_a = np.argmax(u_vals)
                principal_util = np.dot(p_flat[best_a], v - w)
                penalty += (principal_util - log['Principal Utility']) ** 2
            else:
                if max_u >= -1e-8:
                    penalty += ir_ic_weight * (max_u ** 2)
        
        for i in range(n_actions):
            p_sum = np.sum(p_flat[i])
            if not np.isclose(p_sum, 1.0, atol=1e-10):
                penalty += ir_ic_weight * (p_sum - 1.0) ** 2
            neg_penalty = np.sum(np.clip(-p_flat[i], 0, None) ** 2)
            penalty += ir_ic_weight * neg_penalty
        
        return penalty
    
    constraints = [
        {'type': 'eq', 'fun': lambda x, idx=i: np.sum(x[idx*n_outcomes:(idx+1)*n_outcomes]) - 1.0}
        for i in range(n_actions)
    ]
    
    bounds = [(0, 1)] * (n_actions * n_outcomes) + [(0, None)] * n_actions
    initial_params = np.concatenate([p0.flatten(), costs_init])
    
    res = minimize(
        objective, 
        initial_params, 
        method='SLSQP', 
        bounds=bounds, 
        constraints=constraints, 
        tol=1e-12, 
        options={'maxiter': 50000, 'ftol': 1e-12, 'disp': False}
    )
    
    optimized_params = res.x
    p_opt = optimized_params[:n_actions * n_outcomes].reshape(n_actions, n_outcomes)
    c_opt = optimized_params[n_actions * n_outcomes: n_actions * n_outcomes + n_actions]
    
    for i in range(n_actions):
        p_opt[i] = np.clip(p_opt[i], 0, 1)
        p_opt[i] /= np.sum(p_opt[i])
        c_opt[i] = max(0, c_opt[i])
    
    valid_rows = []
    for i in range(n_actions):
        if np.all(p_opt[i] >= -1e-10) and np.isclose(np.sum(p_opt[i]), 1.0, atol=1e-10) and c_opt[i] >= -1e-10:
            valid_rows.append(i)
    
    if not valid_rows:
        uniform_p = np.ones(n_outcomes) / n_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])
    
    p_opt = p_opt[valid_rows]
    c_opt = c_opt[valid_rows]
    
    return np.hstack([p_opt, c_opt.reshape(-1, 1)])
```
