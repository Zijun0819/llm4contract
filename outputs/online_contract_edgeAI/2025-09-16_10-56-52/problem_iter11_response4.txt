```python
import numpy as np
from scipy.optimize import minimize, Bounds, LinearConstraint, NonlinearConstraint
from sklearn.mixture import GaussianMixture
from scipy.stats import multivariate_normal
import warnings
warnings.filterwarnings('ignore')

def agent_solver_v2(v: np.ndarray, content: list) -> np.ndarray:
    n_outcomes = len(v)
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    if not accepted_logs:
        uniform_p = np.ones(n_outcomes) / n_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])
    
    def solve_p(w, u_target):
        c = -w
        A_eq = np.vstack([np.ones(n_outcomes), v - w])
        b_eq = np.array([1.0, u_target])
        bounds = [(0, 1) for _ in range(n_outcomes)]
        res = minimize(lambda x: np.dot(c, x), 
                      x0=np.ones(n_outcomes)/n_outcomes,
                      constraints=[{'type': 'eq', 'fun': lambda x: np.dot(np.ones(n_outcomes), x) - 1},
                                  {'type': 'eq', 'fun': lambda x: np.dot(v - w, x) - u_target}],
                      bounds=bounds,
                      method='SLSQP',
                      options={'ftol': 1e-10, 'maxiter': 1000})
        return res.x if res.success and np.all(x >= -1e-8) and np.isclose(np.sum(x), 1.0, atol=1e-8) else None

    candidate_ps = []
    for log in accepted_logs:
        w = np.array(log['Contract'])
        u_target = log['Principal Utility']
        p = solve_p(w, u_target)
        if p is not None:
            candidate_ps.append(p)
    
    if not candidate_ps:
        candidate_ps = [np.ones(n_outcomes) / n_outcomes]
    
    X = np.array(candidate_ps)
    weights = np.ones(len(X))
    if rejected_logs:
        rej_weights = []
        for p in X:
            rej_count = 0
            for log in rejected_logs:
                w = np.array(log['Contract'])
                if np.dot(p, w) >= 0:
                    rej_count += 1
            rej_weights.append(rej_count)
        weights = 1.0 / (1.0 + np.array(rej_weights))
    
    n_components_range = range(1, min(20, len(X)) + 1)
    bics = []
    gmm_models = []
    for n in n_components_range:
        gmm = GaussianMixture(n_components=n, random_state=42, n_init=20, max_iter=500, tol=1e-8)
        gmm.fit(X, sample_weight=weights)
        bics.append(gmm.bic(X))
        gmm_models.append(gmm)
    best_idx = np.argmin(bics)
    best_gmm = gmm_models[best_idx]
    p0 = best_gmm.means_
    n_actions = len(p0)
    
    utility_thresholds = np.full(n_actions, np.inf)
    for log in accepted_logs:
        w = np.array(log['Contract'])
        dists = np.array([multivariate_normal.logpdf(w, mean=p, cov=np.eye(n_outcomes)*1e-6) for p in p0])
        a_label = np.argmax(dists)
        u = np.dot(p0[a_label], w)
        if u < utility_thresholds[a_label]:
            utility_thresholds[a_label] = u
    
    rej_thresholds = np.full(n_actions, -np.inf)
    for log in rejected_logs:
        w = np.array(log['Contract'])
        for a in range(n_actions):
            u = np.dot(p0[a], w)
            if u > rej_thresholds[a]:
                rej_thresholds[a] = u
    
    costs_init = np.maximum(utility_thresholds, rej_thresholds + 1e-10)
    costs_init = np.clip(costs_init, 0, None)
    
    def objective(params):
        p_flat = params[:n_actions * n_outcomes].reshape(n_actions, n_outcomes)
        c = params[n_actions * n_outcomes: n_actions * n_outcomes + n_actions]
        penalty = 0.0
        
        for log in content:
            w = np.array(log['Contract'])
            u_vals = np.array([np.dot(p, w) - cost_val for p, cost_val in zip(p_flat, c)])
            max_u = np.max(u_vals)
            
            if log['Agent Action'] == 1:
                if max_u < -1e-10:
                    penalty += 1e6 * (max_u ** 2)
                best_a = np.argmax(u_vals)
                principal_util = np.dot(p_flat[best_a], v - w)
                penalty += 1e4 * (principal_util - log['Principal Utility']) ** 2
            else:
                if max_u >= 1e-10:
                    penalty += 1e6 * (max_u ** 2)
        
        for i in range(n_actions):
            p_sum = np.sum(p_flat[i])
            if not np.isclose(p_sum, 1.0, atol=1e-10):
                penalty += 1e6 * (p_sum - 1.0) ** 2
            if np.any(p_flat[i] < -1e-10):
                penalty += 1e6 * np.sum(np.clip(-p_flat[i], 0, None) ** 2)
        
        return penalty
    
    constraints = []
    for i in range(n_actions):
        constraints.append(NonlinearConstraint(lambda x, idx=i: np.sum(x[idx*n_outcomes:(idx+1)*n_outcomes]), 1.0, 1.0))
    
    bounds = Bounds([0]*n_actions*n_outcomes + [0]*n_actions, [1]*n_actions*n_outcomes + [np.inf]*n_actions)
    initial_params = np.concatenate([p0.flatten(), costs_init])
    
    res = minimize(
        objective, 
        initial_params, 
        method='trust-constr',
        bounds=bounds, 
        constraints=constraints, 
        options={'maxiter': 20000, 'verbose': 0, 'gtol': 1e-10, 'xtol': 1e-10}
    )
    
    if res.success:
        optimized_params = res.x
        p_opt = optimized_params[:n_actions * n_outcomes].reshape(n_actions, n_outcomes)
        c_opt = optimized_params[n_actions * n_outcomes: n_actions * n_outcomes + n_actions]
    else:
        p_opt, c_opt = p0, costs_init
    
    return np.hstack([p_opt, c_opt.reshape(-1, 1)])
```
