```python
import numpy as np
from scipy.optimize import minimize, linprog
from sklearn.mixture import GaussianMixture

def agent_solver(v: np.ndarray, content: list[dict]) -> np.ndarray:
    num_outcomes = len(v)
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    if not accepted_logs and not rejected_logs:
        default_p = np.ones(num_outcomes) / num_outcomes
        default_c = 0.0
        return np.hstack([default_p.reshape(1, -1), np.array([[default_c]])])
    
    def infer_potential_actions():
        candidate_ps = []
        for log in accepted_logs:
            w = np.array(log['Contract'])
            u = log['Principal Utility']
            try:
                A_eq = np.vstack([np.ones(num_outcomes), v - w])
                b_eq = np.array([1.0, u])
                res = linprog(-w, A_eq=A_eq, b_eq=b_eq, bounds=[(0, 1)] * num_outcomes, method='highs')
                if res.success:
                    p = res.x
                    if np.all(p >= -1e-8) and abs(np.sum(p) - 1) < 1e-8:
                        candidate_ps.append(np.clip(p, 0, 1))
            except:
                continue
        return np.array(candidate_ps) if candidate_ps else np.ones((1, num_outcomes)) / num_outcomes
    
    candidate_ps = infer_potential_actions()
    
    if len(candidate_ps) > 1:
        max_components = min(10, len(candidate_ps))
        bic_scores = []
        models = []
        for n_comp in range(1, max_components + 1):
            gmm = GaussianMixture(n_components=n_comp, random_state=42, n_init=5, max_iter=200)
            gmm.fit(candidate_ps)
            bic_scores.append(gmm.bic(candidate_ps))
            models.append(gmm)
        best_n = np.argmin(bic_scores) + 1
        gmm = models[best_n - 1]
        action_centers = gmm.means_
    else:
        action_centers = candidate_ps
    
    n_actions = action_centers.shape[0]
    lower_bounds = np.zeros(n_actions)
    upper_bounds = np.full(n_actions, np.inf)
    
    for log in accepted_logs:
        w = np.array(log['Contract'])
        utilities = action_centers @ w
        best_action = np.argmax(utilities)
        lower_bounds[best_action] = max(lower_bounds[best_action], utilities[best_action])
    
    for log in rejected_logs:
        w = np.array(log['Contract'])
        utilities = action_centers @ w
        for a in range(n_actions):
            if utilities[a] > upper_bounds[a]:
                continue
            if utilities[a] >= 0:
                upper_bounds[a] = min(upper_bounds[a], utilities[a])
    
    costs = np.zeros(n_actions)
    for a in range(n_actions):
        if np.isfinite(upper_bounds[a]):
            if lower_bounds[a] <= upper_bounds[a]:
                costs[a] = (lower_bounds[a] + upper_bounds[a]) / 2
            else:
                costs[a] = lower_bounds[a]
        else:
            costs[a] = lower_bounds[a]
    
    for a in range(n_actions):
        for log in rejected_logs:
            w = np.array(log['Contract'])
            if np.dot(action_centers[a], w) - costs[a] >= 0:
                costs[a] = np.dot(action_centers[a], w) + 1e-8
    
    for a in range(n_actions):
        for log in accepted_logs:
            w = np.array(log['Contract'])
            if np.dot(action_centers[a], w) - costs[a] < 0 and np.argmax(action_centers @ w) == a:
                costs[a] = np.dot(action_centers[a], w) - 1e-8
    
    def refine_objective(params):
        p_flat = params[:n_actions * num_outcomes].reshape(n_actions, num_outcomes)
        c = params[n_actions * num_outcomes:]
        penalty = 0.0
        for log in content:
            w = np.array(log['Contract'])
            agent_utils = p_flat @ w - c
            max_u = np.max(agent_utils)
            best_action = np.argmax(agent_utils)
            if log['Agent Action'] == 1:
                if max_u < 0:
                    penalty += (max_u - 0) ** 2
                principal_util = np.dot(p_flat[best_action], v - w)
                penalty += (principal_util - log['Principal Utility']) ** 2
            else:
                if max_u >= 0:
                    penalty += (max_u - (-1e-8)) ** 2
        return penalty
    
    constraints = []
    for i in range(n_actions):
        constraints.append({'type': 'eq', 'fun': lambda x, idx=i: np.sum(x[idx*num_outcomes:(idx+1)*num_outcomes]) - 1})
    
    bounds = [(0, 1)] * (n_actions * num_outcomes) + [(0, None)] * n_actions
    x0 = np.concatenate([action_centers.flatten(), costs])
    
    res = minimize(refine_objective, x0, method='SLSQP', bounds=bounds, constraints=constraints, tol=1e-6, options={'maxiter': 200})
    
    if res.success:
        optimized = res.x
        p_opt = optimized[:n_actions * num_outcomes].reshape(n_actions, num_outcomes)
        c_opt = optimized[n_actions * num_outcomes:]
    else:
        p_opt, c_opt = action_centers, costs
    
    for i in range(n_actions):
        p_opt[i] /= np.sum(p_opt[i])
    c_opt = np.maximum(c_opt, 0)
    
    return np.hstack([p_opt, c_opt.reshape(-1, 1)])
```
