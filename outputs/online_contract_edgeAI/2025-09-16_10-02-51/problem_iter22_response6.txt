```python
import numpy as np
from scipy.optimize import linprog, minimize, Bounds
from sklearn.mixture import GaussianMixture
from sklearn.cluster import KMeans

def agent_solver(v, content):
    m_outcomes = len(v)
    
    if not content:
        return np.zeros((1, m_outcomes + 1))
    
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    accepted_contracts = np.array([log['Contract'] for log in accepted_logs])
    accepted_utils = np.array([log['Principal Utility'] for log in accepted_logs])
    
    p_list = []
    for i, w in enumerate(accepted_contracts):
        u_p = accepted_utils[i]
        if u_p <= 1e-12:
            continue
        c = -np.array(w)
        A_eq = np.vstack([np.ones(m_outcomes), v])
        b_eq = np.array([1.0, u_p])
        bounds = [(0.0, 1.0)] * m_outcomes
        res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p_list.append(res.x)
    
    if not p_list:
        p_centroids = np.ones((1, m_outcomes)) / m_outcomes
    else:
        p_array = np.array(p_list)
        if len(p_array) == 1:
            p_centroids = p_array
        else:
            inertias = []
            max_k = min(12, len(p_array))
            for k in range(1, max_k + 1):
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10).fit(p_array)
                inertias.append(kmeans.inertia_)
            if len(inertias) > 1:
                elbow_k = np.argmin(np.diff(inertias)) + 2
            else:
                elbow_k = 1
            gmm = GaussianMixture(n_components=elbow_k, covariance_type='full', random_state=42, n_init=10)
            gmm.fit(p_array)
            p_centroids = gmm.means_
    
    n_actions = len(p_centroids)
    p_centroids = np.clip(p_centroids, 0.0, 1.0)
    p_centroids = p_centroids / np.sum(p_centroids, axis=1, keepdims=True)
    
    eps = 1e-12
    cost_lower_bounds = np.zeros(n_actions)
    cost_upper_bounds = np.full(n_actions, np.inf)
    
    for a in range(n_actions):
        p_a = p_centroids[a]
        min_accepted = np.inf
        for log in accepted_logs:
            w = np.array(log['Contract'])
            agent_util = np.dot(p_a, w)
            if agent_util >= -eps:
                min_accepted = min(min_accepted, agent_util)
        if min_accepted != np.inf:
            cost_lower_bounds[a] = max(0.0, min_accepted - eps)
        
        max_rejected = -np.inf
        for log in rejected_logs:
            w = np.array(log['Contract'])
            agent_util = np.dot(p_a, w)
            if agent_util < eps:
                max_rejected = max(max_rejected, agent_util)
        if max_rejected != -np.inf:
            cost_upper_bounds[a] = max(0.0, -max_rejected + eps)
    
    def objective(costs):
        violation = 0.0
        penalty = 1e12
        for log in content:
            w = np.array(log['Contract'])
            utils = np.array([np.dot(p_centroids[a], w) - costs[a] for a in range(n_actions)])
            max_util = np.max(utils)
            best_action = np.argmax(utils)
            if log['Agent Action'] == 1:
                if max_util < -eps:
                    violation += penalty * (-max_util)
                for a in range(n_actions):
                    util_diff = utils[best_action] - utils[a]
                    if util_diff < eps:
                        violation += penalty * (eps - util_diff)
            else:
                if max_util >= -eps:
                    violation += penalty * (max_util + eps)
        return violation
    
    bounds = Bounds(cost_lower_bounds, cost_upper_bounds)
    res = minimize(objective, cost_lower_bounds, method='SLSQP', bounds=bounds, options={'maxiter': 10000, 'ftol': 1e-15})
    final_costs = res.x if res.success else cost_lower_bounds
    final_costs = np.clip(final_costs, 0.0, None)
    
    agent_setting = np.hstack([p_centroids, final_costs.reshape(-1, 1)])
    return agent_setting
```
