```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    n_outcomes = len(v)
    n_logs = len(content)
    
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    def infer_p_constraints(w, u):
        m = len(w)
        c = -np.ones(m + 1)
        c[-1] = 0
        A_ub = []
        b_ub = []
        A_eq = [np.zeros(m + 1)]
        A_eq[0][:m] = v - w
        b_eq = [u]
        A_eq.append(np.zeros(m + 1))
        A_eq[1][:m] = np.ones(m)
        b_eq.append(1.0)
        bounds = [(0, 1) if i < m else (None, None) for i in range(m + 1)]
        res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success and np.allclose(res.x[:m] @ v, res.x[:m] @ w + u):
            return res.x[:m]
        return None
    
    candidate_ps = []
    for log in accepted_logs:
        w = np.array(log['Contract'])
        u = log['Principal Utility']
        p_candidate = infer_p_constraints(w, u)
        if p_candidate is not None:
            candidate_ps.append(p_candidate)
    
    if not candidate_ps:
        n_default = 5
        p_default = np.full((n_default, n_outcomes), 1.0 / n_outcomes)
        c_default = np.zeros(n_default)
        return np.hstack([p_default, c_default[:, np.newaxis]])
    
    all_p = np.array(candidate_ps)
    
    max_clusters = min(20, len(all_p))
    bic_scores = []
    models = []
    for n_components in range(1, max_clusters + 1):
        gmm = GaussianMixture(n_components=n_components, random_state=42, max_iter=200)
        gmm.fit(all_p)
        bic_scores.append(gmm.bic(all_p))
        models.append(gmm)
    best_n = np.argmin(bic_scores) + 1
    gmm = models[best_n - 1]
    probs = gmm.weights_
    means = gmm.means_
    covariance = gmm.covariances_
    
    if best_n == 1:
        sampled_actions = [means[0]]
    else:
        samples_per_component = max(1, min(10, len(all_p) // best_n))
        sampled_actions = []
        for i in range(best_n):
            if gmm.covariance_type == 'full':
                cov = covariance[i]
            elif gmm.covariance_type == 'tied':
                cov = covariance
            elif gmm.covariance_type == 'diag':
                cov = np.diag(covariance[i])
            else:
                cov = np.eye(n_outcomes) * covariance[i]
            samples = np.random.multivariate_normal(means[i], cov, size=samples_per_component)
            samples = np.clip(samples, 0, 1)
            samples = samples / np.sum(samples, axis=1, keepdims=True)
            sampled_actions.extend(samples)
        sampled_actions = np.array(sampled_actions)
        kmeans_refine = KMeans(n_clusters=best_n, random_state=42, n_init=10).fit(sampled_actions)
        p0 = kmeans_refine.cluster_centers_
        p0 = p0 / np.sum(p0, axis=1, keepdims=True)
    p0 = p0 / np.sum(p0, axis=1, keepdims=True)
    n_actions = p0.shape[0]
    
    accepted_wages = np.array([log['Contract'] for log in accepted_logs])
    rejected_wages = np.array([log['Contract'] for log in rejected_logs]) if rejected_logs else None
    
    if rejected_wages is not None:
        rej_max_utils = p0 @ rejected_wages.T
        c_rej = np.max(rej_max_utils, axis=1)
    else:
        c_rej = np.full(n_actions, -np.inf)
    
    acc_utils = p0 @ accepted_wages.T
    best_acc_actions = np.argmax(acc_utils, axis=0)
    
    c_ir = np.zeros(n_actions)
    for a in range(n_actions):
        mask = best_acc_actions == a
        if np.any(mask):
            c_ir[a] = np.min(acc_utils[a, mask])
        else:
            c_ir[a] = 0.0
    
    c_hat = np.maximum(c_ir, c_rej)
    
    adjustment = 1e-10
    for a in range(n_actions):
        if c_rej[a] > c_ir[a] + adjustment:
            feasible = True
            for log in rejected_logs:
                w_rej = np.array(log['Contract'])
                if np.any(p0[a] @ w_rej >= c_hat[a] - adjustment):
                    feasible = False
                    break
            if not feasible:
                c_hat[a] = c_rej[a] + np.random.uniform(1e-9, 1e-8)
    
    for a in range(n_actions):
        for log in accepted_logs:
            w_acc = np.array(log['Contract'])
            action_taken = best_acc_actions[np.where(np.all(accepted_wages == w_acc, axis=1))[0][0]]
            if action_taken == a:
                if p0[a] @ w_acc < c_hat[a] - adjustment:
                    c_hat[a] = p0[a] @ w_acc - np.random.uniform(1e-9, 1e-8)
    
    c_hat = np.maximum(c_hat, 0)
    
    all_logs_utils = []
    all_logs_actions = []
    for i, log in enumerate(content):
        w = np.array(log['Contract'])
        if log['Agent Action'] == 1:
            action_i = best_acc_actions[np.where(np.all(accepted_wages == w, axis=1))[0][0]]
            all_logs_actions.append(action_i)
            all_logs_utils.append(p0[action_i] @ w - c_hat[action_i])
        else:
            utils_rej = p0 @ w - c_hat
            max_util = np.max(utils_rej)
            all_logs_utils.append(max_util)
            all_logs_actions.append(np.argmax(utils_rej))
    
    violation_count = 0
    for i, log in enumerate(content):
        if log['Agent Action'] == 1 and all_logs_utils[i] < -1e-8:
            violation_count += 1
        elif log['Agent Action'] == -1 and all_logs_utils[i] >= 1e-8:
            violation_count += 1
    
    if violation_count > 0:
        scale_factor = 1.0 + 1e-5
        c_hat = c_hat * scale_factor
        for a in range(n_actions):
            for log in accepted_logs:
                w_acc = np.array(log['Contract'])
                if best_acc_actions[np.where(np.all(accepted_wages == w_acc, axis=1))[0][0]] == a:
                    if p0[a] @ w_acc < c_hat[a]:
                        c_hat[a] = p0[a] @ w_acc - np.random.uniform(1e-10, 1e-9)
        c_hat = np.maximum(c_hat, 0)
    
    agent_setting = np.hstack([p0, c_hat[:, np.newaxis]])
    return agent_setting
```
