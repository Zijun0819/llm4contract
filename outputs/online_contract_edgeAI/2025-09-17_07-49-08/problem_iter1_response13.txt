```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import KMeans
from sklearn.preprocessing import normalize


def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    n_candidates = 5
    m_outcomes = v.shape[0]
    L = len(content)

    def mini_lp_p(w: np.ndarray, u: float) -> np.ndarray | None:
        """Solve for agent outcome distribution p given wage vector w and utility u."""
        m = len(w)
        A_eq = [np.ones(m), v - w]
        b_eq = [1.0, u]
        bounds = [(0, 1)] * m
        res = linprog(w, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        return res.x if res.success else None

    # Step 1: Filter accepted contracts and solve mini LPs
    candidate_ps = []
    candidate_costs = []
    for log in content:
        if log['Agent Action'] == 1:
            w_i = log['Contract']
            u_i = log['Principal Utility']
            p_i = mini_lp_p(w_i, u_i)
            if p_i is not None:
                candidate_ps.append(p_i)
                candidate_costs.append(np.clip(p_i @ w_i, 0, np.inf))

    if not candidate_ps:
        raise ValueError("No valid accepted logs to infer agent strategies.")

    all_p = np.array(candidate_ps)
    all_costs = np.array(candidate_costs)

    # Step 2: Combine p and cost for clustering
    combined_data = np.hstack([all_p, all_costs[:, np.newaxis]])
    kmeans = KMeans(n_clusters=n_candidates, random_state=0, n_init=10).fit(combined_data)
    cluster_centers = kmeans.cluster_centers_

    # Step 3: Extract p and costs from cluster centers
    p0 = cluster_centers[:, :m_outcomes]
    c_init = np.clip(cluster_centers[:, m_outcomes], 0, np.inf)

    # Normalize probabilities
    p0 = normalize(p0, axis=1, norm='l1')
    c_init = np.clip(c_init, 0, np.inf)

    # Step 4: Ensure rejection consistency
    rej_idx = [i for i, log in enumerate(content) if log['Agent Action'] == -1]
    if rej_idx:
        wages_rej = np.array([log['Contract'] for i, log in enumerate(content) if log['Agent Action'] == -1])
        max_utils = np.array([np.max(p0 @ wage) for wage in wages_rej])
        min_rej_cost = np.min(max_utils)
        c_init = np.maximum(c_init, min_rej_cost)

    # Step 5: Format agent setting
    agent_setting = np.hstack([p0, c_init[:, np.newaxis]])
    return agent_setting
```
