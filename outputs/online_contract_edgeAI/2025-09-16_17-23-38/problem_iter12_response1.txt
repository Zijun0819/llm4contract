```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans

def agent_solver(v: np.ndarray, content) -> np.ndarray:
    m_outcomes = len(v)
    
    if isinstance(content, pd.DataFrame):
        contracts = np.vstack(content['Contract'].values)
        principal_utils = content['Principal Utility'].values
        agent_actions = content['Agent Action'].values
    else:
        contracts = np.array([log['Contract'] for log in content])
        principal_utils = np.array([log['Principal Utility'] for log in content])
        agent_actions = np.array([log['Agent Action'] for log in content])

    candidate_ps = []
    accepted_indices = agent_actions == 1
    if not np.any(accepted_indices):
        raise ValueError("No accepted contracts to infer agent strategies.")

    accepted_contracts = contracts[accepted_indices]
    accepted_principal_utils = principal_utils[accepted_indices]

    for i in range(len(accepted_contracts)):
        w_i = accepted_contracts[i]
        u_i = accepted_principal_utils[i]
        
        A_eq = np.array([np.ones(m_outcomes), v - w_i])
        b_eq = np.array([1.0, u_i])
        bounds = [(0, 1)] * m_outcomes
        
        res = linprog(np.zeros(m_outcomes), A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            candidate_ps.append(res.x)

    if not candidate_ps:
        raise ValueError("No valid LP solutions found for accepted contracts.")
    
    candidate_ps = np.array(candidate_ps)
    
    # PCA for dimensionality reduction
    if candidate_ps.shape[0] > 2:
        pca = PCA(n_components=min(3, candidate_ps.shape[1]))
        candidate_ps_pca = pca.fit_transform(candidate_ps)
    else:
        candidate_ps_pca = candidate_ps

    # Adaptive number of clusters using elbow method
    max_k = min(15, len(candidate_ps_pca))
    if max_k < 2:
        n_candidates = 2
    else:
        distortions = []
        K_range = range(2, max_k + 1)
        for k in K_range:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10).fit(candidate_ps_pca)
            distortions.append(kmeans.inertia_)
        
        if len(distortions) > 2:
            diffs = np.diff(distortions)
            diffs2 = np.diff(diffs)
            elbow_idx = np.argmax(diffs2) + 2
            n_candidates = max(2, min(elbow_idx, max_k))
        else:
            n_candidates = min(5, max_k)

    # Use multiple restarts for better clustering
    best_kmeans = None
    best_inertia = np.inf
    for _ in range(10):
        kmeans = KMeans(n_clusters=n_candidates, random_state=None, n_init=10).fit(candidate_ps_pca)
        if kmeans.inertia_ < best_inertia:
            best_inertia = kmeans.inertia_
            best_kmeans = kmeans
            
    kmeans = best_kmeans

    if candidate_ps.shape[0] > 2:
        p0 = pca.inverse_transform(kmeans.cluster_centers_)
    else:
        p0 = kmeans.cluster_centers_

    # Normalize probabilities
    p0 = np.clip(p0, 0, 1)
    row_sums = p0.sum(axis=1, keepdims=True)
    row_sums[row_sums == 0] = 1
    p0 /= row_sums

    # Assignments for all contracts based on utility maximization
    utilities_all = p0 @ contracts.T  # Shape: (n_candidates, n_contracts)
    assignments = np.argmax(utilities_all, axis=0)

    # Compute costs from IR constraints using tighter bounds
    c_ir = np.full(n_candidates, -np.inf)
    for a in range(n_candidates):
        action_indices = np.where((assignments == a) & (agent_actions == 1))[0]
        if len(action_indices) > 0:
            wages = contracts[action_indices].T
            # Tighter bound: use max wage per outcome for IR
            max_wages = np.max(wages, axis=1)
            c_ir[a] = np.dot(p0[a], max_wages)

    # Compute costs from IC constraints for rejections
    c_rej = np.full(n_candidates, -np.inf)
    rejected_indices = agent_actions == -1
    if np.any(rejected_indices):
        rejected_wages = contracts[rejected_indices].T
        for a in range(n_candidates):
            expected_wages = p0[a] @ rejected_wages
            # For IC, agent should not prefer rejected action => cost >= max expected wage
            if len(expected_wages) > 0:
                c_rej[a] = np.max(expected_wages)

    # Compute final costs with slack
    slack = 1e-6
    c_final = np.maximum(c_ir, c_rej) + slack

    # Regularization: Ensure strictly positive cost if action is ever taken
    for a in range(n_candidates):
        action_indices = np.where(assignments == a)[0]
        if len(action_indices) > 0:
            if not np.isfinite(c_final[a]) or c_final[a] <= 0:
                avg_wage = np.mean(contracts[action_indices], axis=0)
                c_final[a] = np.dot(p0[a], avg_wage) + slack

    # Final safety check to ensure non-negative costs
    c_final = np.maximum(0, c_final)
    
    agent_setting = np.hstack([p0, c_final[:, np.newaxis]])
    
    return agent_setting
```
