```python
import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from scipy.optimize import linprog
from scipy.spatial.distance import cdist

def agent_solver(v: np.ndarray, content) -> np.ndarray:
    m_outcomes = len(v)
    
    if isinstance(content, pd.DataFrame):
        contracts = np.vstack(content['Contract'].values)
        principal_utils = content['Principal Utility'].values
        agent_actions = content['Agent Action'].values
    else:
        contracts = np.array([log['Contract'] for log in content])
        principal_utils = np.array([log['Principal Utility'] for log in content])
        agent_actions = np.array([log['Agent Action'] for log in content])

    candidate_ps = []
    accepted_indices = agent_actions == 1
    if not np.any(accepted_indices):
        raise ValueError("No accepted contracts to infer agent strategies.")

    accepted_contracts = contracts[accepted_indices]
    accepted_principal_utils = principal_utils[accepted_indices]

    for i in range(len(accepted_contracts)):
        w_i = accepted_contracts[i]
        u_i = accepted_principal_utils[i]
        
        A_eq = np.array([np.ones(m_outcomes), v - w_i])
        b_eq = np.array([1.0, u_i])
        bounds = [(0, 1)] * m_outcomes
        
        res = linprog(np.zeros(m_outcomes), A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            candidate_ps.append(res.x)

    if not candidate_ps:
        raise ValueError("No valid LP solutions found for accepted contracts.")
    
    candidate_ps = np.array(candidate_ps)
    
    # Dimensionality reduction via PCA
    n_components = min(6, candidate_ps.shape[1])
    pca = PCA(n_components=n_components)
    candidate_ps_reduced = pca.fit_transform(candidate_ps)
    
    # Adaptive number of clusters using elbow method
    max_k = min(15, len(candidate_ps_reduced))
    if max_k < 2:
        n_candidates = 2
    else:
        distortions = []
        K_range = range(2, max_k + 1)
        for k in K_range:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10).fit(candidate_ps_reduced)
            distortions.append(kmeans.inertia_)
        
        if len(distortions) > 2:
            diffs = np.diff(distortions)
            diffs2 = np.diff(diffs)
            elbow_idx = np.argmax(diffs2) + 2
            n_candidates = max(2, min(elbow_idx, max_k))
        else:
            n_candidates = min(5, max_k)

    kmeans = KMeans(n_clusters=n_candidates, random_state=42, n_init=10).fit(candidate_ps_reduced)
    centers_reduced = kmeans.cluster_centers_
    p0_recovered = pca.inverse_transform(centers_reduced)
    
    # Normalize probabilities
    p0_recovered = np.clip(p0_recovered, 0, 1)
    row_sums = p0_recovered.sum(axis=1, keepdims=True)
    row_sums[row_sums == 0] = 1
    p0 = p0_recovered / row_sums

    # Assignments for all contracts
    distances = cdist(contracts, p0, 'euclidean')
    assignments = np.argmin(distances, axis=1)
    assignments[agent_actions == -1] = -1  # Explicitly mark rejections

    # Compute costs from IR constraints for accepted contracts
    c_ir = np.zeros(n_candidates)
    for a in range(n_candidates):
        action_indices = np.where(assignments == a)[0]
        if len(action_indices) > 0:
            wages = contracts[action_indices].T
            min_wages = np.min(wages, axis=1)
            c_ir[a] = np.dot(p0[a], min_wages)

    # Compute costs from IC constraints for rejected contracts
    c_rej = np.full(n_candidates, -np.inf)
    rejected_indices = agent_actions == -1
    if np.any(rejected_indices):
        rejected_contracts = contracts[rejected_indices]
        for a in range(n_candidates):
            expected_utilities = p0[a] @ rejected_contracts.T
            c_rej[a] = np.max(expected_utilities)

    # Stabilize and finalize cost with regularization
    c_rej = np.where(c_rej == -np.inf, 0, c_rej)
    slack = 1e-6
    c_final = np.maximum(c_ir, c_rej) + slack

    # Regularization: ensure non-negative cost
    c_final = np.maximum(0, c_final)
    
    agent_setting = np.hstack([p0, c_final[:, np.newaxis]])
    
    return agent_setting
```
