```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA


def agent_solver(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    n_candidates = 10
    m_outcomes = v.shape[0]
    L = len(content)

    def mini_lp_p(w: np.ndarray, u: float) -> np.ndarray | None:
        """Solve for agent outcome distribution p given wage vector w and utility u."""
        m = len(w)
        A_eq = [np.ones(m), v - w]
        b_eq = [1.0, u]
        bounds = [(0, 1)] * m
        res = linprog(np.zeros(m), A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        return res.x if res.success else None

    # Step 1: Filter accepted contracts and solve mini LPs
    candidate_ps = []
    for _, log in content.iterrows():
        if log['Agent Action'] == 1:
            w_i = np.array(log['Contract'])
            u_i = log['Principal Utility']
            p_i = mini_lp_p(w_i, u_i)
            if p_i is not None:
                candidate_ps.append(p_i)

    if not candidate_ps:
        raise ValueError("No valid accepted logs to infer agent strategies.")

    all_p = np.array(candidate_ps)

    # Step 2: Use PCA to reduce dimensionality before clustering for better stability
    if all_p.shape[0] > 1:
        pca = PCA(n_components=min(5, all_p.shape[0], all_p.shape[1]))
        all_p_reduced = pca.fit_transform(all_p)
        kmeans = KMeans(n_clusters=n_candidates, random_state=42, n_init=15).fit(all_p_reduced)
        labels = kmeans.labels_
    else:
        labels = np.zeros(all_p.shape[0], dtype=int)

    # Step 3: Recompute cluster centers in original space
    p0 = np.array([all_p[labels == i].mean(axis=0) for i in range(n_candidates)])
    p0 = p0 / p0.sum(axis=1, keepdims=True)  # renormalize

    # Step 4: Assign each accepted log to best-fitting action (based on utility)
    assigns = np.full(L, -1, dtype=int)
    for i, (_, log) in enumerate(content.iterrows()):
        if log['Agent Action'] == 1:
            w = np.array(log['Contract'])
            assigns[i] = int(np.argmax(p0 @ w))

    # Step 5: Compute IR-consistent cost for each action (minimum wage required)
    c_ir = np.zeros(n_candidates)
    for a in range(n_candidates):
        idx = np.where(assigns == a)[0]
        if idx.size > 0:
            wages = np.array([content.iloc[i]['Contract'] for i in idx])
            c_ir[a] = np.max([p0[a] @ w for w in wages])

    # Step 6: Ensure rejection consistency for all contracts
    rej_utilities = []
    for _, log in content.iterrows():
        if log['Agent Action'] == -1:
            w = np.array(log['Contract'])
            utils = p0 @ w
            rej_utilities.append(np.max(utils))

    c_rej = np.array(rej_utilities) if rej_utilities else np.full(n_candidates, -np.inf)
    c_rej_safe = np.max(c_rej) if len(c_rej) > 0 and not np.isinf(np.max(c_rej)) else 0.0

    # Final cost: satisfy both IR and consistency with rejections
    c_final = np.maximum(c_ir, c_rej_safe)

    # Ensure non-negative costs
    c_final = np.clip(c_final, 0, None)

    # Step 7: Format final agent setting
    agent_setting = np.hstack([p0, c_final[:, np.newaxis]])
    return agent_setting
```
