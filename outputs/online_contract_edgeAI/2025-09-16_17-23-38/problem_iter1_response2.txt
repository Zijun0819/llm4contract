```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

def agent_solver_v2(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    m_outcomes = v.shape[0]
    L = len(content)
    
    def mini_lp_p(w: np.ndarray, u: float) -> np.ndarray | None:
        """Solve for agent outcome distribution p given wage vector w and utility u."""
        A_eq = np.array([np.ones(m_outcomes), v - w])
        b_eq = np.array([1.0, u])
        c = np.zeros(m_outcomes)
        bounds = [(0, 1)] * m_outcomes
        res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        return res.x if res.success else None

    # Step 1: Filter accepted contracts and solve mini LPs
    candidate_ps = []
    accepted_logs = []
    for idx, log in content.iterrows():
        action = log['Agent Action']
        w_i = np.array(log['Contract'])
        if action == 1:
            u_i = log['Principal Utility']
            p_i = mini_lp_p(w_i, u_i)
            if p_i is not None:
                candidate_ps.append(p_i)
                accepted_logs.append((w_i, idx))

    if not candidate_ps:
        raise ValueError("No valid accepted logs to infer agent strategies.")

    all_p = np.array(candidate_ps)

    # Step 2: Use PCA for dimensionality reduction before clustering
    n_components = min(6, all_p.shape[0], all_p.shape[1])
    pca = PCA(n_components=n_components)
    reduced_ps = pca.fit_transform(all_p)
    
    # Step 3: Adaptive number of clusters based on data size
    n_candidates = max(3, min(15, len(candidate_ps) // 4))
    kmeans = KMeans(n_clusters=n_candidates, random_state=42, n_init=10).fit(reduced_ps)
    labels = kmeans.labels_
    
    # Step 4: Compute centroid in original space
    p0 = np.array([all_p[labels == i].mean(axis=0) for i in range(n_candidates)])
    p0 = np.clip(p0, 0, 1)
    p0 = p0 / p0.sum(axis=1, keepdims=True)

    # Step 5: Assign each accepted log to best-fitting action
    assigns = np.full(L, -1, dtype=int)
    for i, (w, orig_idx) in enumerate(accepted_logs):
        assigns[orig_idx] = int(np.argmax(p0 @ w))

    # Step 6: Compute IR-consistent cost with robust estimation
    c_ir = np.zeros(n_candidates)
    for a in range(n_candidates):
        idx = np.where(assigns == a)[0]
        if len(idx) > 0:
            wages = np.array([content.iloc[i]['Contract'] for i in idx])
            utilities = np.dot(p0[a], wages.T)
            c_ir[a] = np.percentile(utilities, 20)  # Use 20th percentile for robustness
        else:
            c_ir[a] = 0.0

    # Step 7: Ensure rejection consistency with margin
    rej_idx = content[content['Agent Action'] == -1].index.tolist()
    if len(rej_idx) > 0:
        wages_rej = np.array([content.iloc[i]['Contract'] for i in rej_idx])
        rej_utils = np.dot(p0, wages_rej.T)
        c_rej = np.max(rej_utils, axis=1)
    else:
        c_rej = np.zeros(n_candidates)
        
    margin = 1e-6
    c_final = np.maximum(c_ir, c_rej) + margin

    # Step 8: Format agent setting
    agent_setting = np.hstack([p0, c_final[:, np.newaxis]])
    return agent_setting
```
