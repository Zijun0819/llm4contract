```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity


def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    n_candidates = 10
    m_outcomes = v.shape[0]
    L = len(content)

    def mini_lp_p(w: np.ndarray, u: float) -> np.ndarray | None:
        """Solve for agent outcome distribution p given wage vector w and utility u."""
        m = len(w)
        A_eq = [np.ones(m), v - w]
        b_eq = [1.0, u]
        bounds = [(0, 1)] * m
        res = linprog(np.zeros(m), A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        return res.x if res.success else None

    # Step 1: Filter accepted contracts and solve mini LPs
    candidate_ps = []
    accepted_logs = []
    for log in content:
        if log['Agent Action'] == 1:
            w_i = np.array(log['Contract'])
            u_i = log['Principal Utility']
            p_i = mini_lp_p(w_i, u_i)
            if p_i is not None:
                candidate_ps.append(p_i)
                accepted_logs.append(log)

    if not candidate_ps:
        raise ValueError("No valid accepted logs to infer agent strategies.")

    all_p = np.array(candidate_ps)
    n_accepted = len(accepted_logs)

    # Step 2: Clustering with refined number of clusters using elbow method heuristic
    distortions = []
    K_range = range(2, min(15, n_accepted))
    for k in K_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10).fit(all_p)
        distortions.append(kmeans.inertia_)
    
    # Heuristic elbow point detection
    if len(distortions) > 2:
        diffs = np.diff(distortions)
        diffs2 = np.diff(diffs)
        elbow_idx = np.argmax(diffs2) + 2
        n_candidates = max(2, min(elbow_idx + 2, len(K_range)))
    else:
        n_candidates = min(5, n_accepted)

    kmeans = KMeans(n_clusters=n_candidates, random_state=42, n_init=10).fit(all_p)
    p0 = kmeans.cluster_centers_

    # Step 3: Assign each accepted log to best-fitting action
    assigns = np.full(n_accepted, -1, dtype=int)
    for i, log in enumerate(accepted_logs):
        w = np.array(log['Contract'])
        expected_utils = p0 @ w
        assigns[i] = int(np.argmax(expected_utils))

    # Step 4: Compute IR-consistent cost for each action
    c_ir = np.zeros(n_candidates)
    for a in range(n_candidates):
        idx = np.where(assigns == a)[0]
        if idx.size > 0:
            wages = np.array([accepted_logs[i]['Contract'] for i in idx]).T
            c_ir[a] = p0[a] @ wages.min(axis=1)
        else:
            c_ir[a] = 0.0

    # Step 5: Ensure rejection consistency
    rejection_logs = [log for log in content if log['Agent Action'] == -1]
    if rejection_logs:
        wages_rej = np.array([log['Contract'] for log in rejection_logs]).T
        rej_utils = p0 @ wages_rej
        c_rej = rej_utils.max(axis=1)
    else:
        c_rej = np.zeros(n_candidates)

    # Step 6: Refine cost with slack margin
    slack = 1e-6
    c_final = np.maximum(c_ir, c_rej) + slack

    # Step 7: Further refine with small perturbations to avoid degeneracy
    perturbation = np.random.normal(0, 1e-8, size=c_final.shape)
    c_final = np.maximum(0, c_final + perturbation)

    # Step 8: Format agent setting
    agent_setting = np.hstack([p0, c_final[:, np.newaxis]])
    
    # Optional post-processing for probability validity
    agent_setting[:, :-1] = np.clip(agent_setting[:, :-1], 0, 1)
    row_sums = agent_setting[:, :-1].sum(axis=1, keepdims=True)
    row_sums[row_sums == 0] = 1
    agent_setting[:, :-1] /= row_sums

    return agent_setting
```
