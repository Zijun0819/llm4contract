```python
import numpy as np
from scipy.optimize import linprog
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture

def agent_solver_v2(v: np.ndarray, content: list) -> np.ndarray:
    # Extract accepted and rejected logs
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]
    
    # Handle case with no accepted contracts
    if not accepted_logs:
        return np.hstack([np.eye(len(v)), np.zeros((len(v), 1))])
    
    # Solve mini LP for each accepted contract to infer probability distribution
    def solve_mini_lp(w, u_principal):
        m = len(w)
        A_eq = np.vstack([np.ones(m), v - w])
        b_eq = np.array([1, u_principal])
        res = linprog(-w, A_eq=A_eq, b_eq=b_eq, bounds=[(0, 1)] * m, method='highs')
        if res.success:
            p = res.x
            p = np.clip(p, 0, 1)
            p_sum = np.sum(p)
            if p_sum > 0:
                p /= p_sum
            return p
        return None
    
    ps_candidates = []
    for log in accepted_logs:
        p_candidate = solve_mini_lp(np.array(log['Contract']), log['Principal Utility'])
        if p_candidate is not None:
            ps_candidates.append(p_candidate)
    
    if not ps_candidates:
        return np.hstack([np.eye(len(v)), np.zeros((len(v), 1))])
    
    # Cluster and refine using KMeans and GMM
    all_p = np.array(ps_candidates)
    n_clusters = min(10, max(2, len(all_p) // 10))
    
    # KMeans clustering for initial grouping
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10).fit(all_p)
    cluster_centers = kmeans.cluster_centers_
    cluster_centers = np.clip(cluster_centers, 0, 1)
    row_sums = np.sum(cluster_centers, axis=1, keepdims=True)
    row_sums[row_sums == 0] = 1
    cluster_centers = cluster_centers / row_sums
    
    # Estimate costs for KMeans clusters
    epsilon = 1e-8
    action_costs = np.zeros(n_clusters)
    for i in range(n_clusters):
        cluster_indices = np.where(kmeans.labels_ == i)[0]
        if cluster_indices.size > 0:
            wages = np.array([accepted_logs[j]['Contract'] for j in cluster_indices])
            utilities = np.sum(wages * cluster_centers[i], axis=1)
            action_costs[i] = np.min(utilities) - epsilon
    
    # Apply IR constraint from rejected logs to KMeans clusters
    if rejected_logs:
        rejected_wages = np.array([log['Contract'] for log in rejected_logs])
        rejected_utilities = rejected_wages @ cluster_centers.T
        max_rejected_utilities = np.max(rejected_utilities, axis=0)
        action_costs = np.maximum(action_costs, max_rejected_utilities + epsilon)
    
    action_costs = np.maximum(action_costs, 0)
    
    # Refine clusters with GMM
    gmm = GaussianMixture(n_components=max(2, n_clusters//2), random_state=42)
    gmm.fit(all_p)
    gmm_centers = gmm.means_
    gmm_centers = np.clip(gmm_centers, 0, 1)
    row_sums_gmm = np.sum(gmm_centers, axis=1, keepdims=True)
    row_sums_gmm[row_sums_gmm == 0] = 1
    gmm_centers = gmm_centers / row_sums_gmm
    
    # Estimate costs for GMM clusters
    refined_costs = np.zeros(gmm_centers.shape[0])
    gmm_assignments = gmm.predict(all_p)
    for i in range(gmm_centers.shape[0]):
        cluster_indices = np.where(gmm_assignments == i)[0]
        if cluster_indices.size > 0:
            wages = np.array([accepted_logs[j]['Contract'] for j in cluster_indices])
            utilities = np.sum(wages * gmm_centers[i], axis=1)
            refined_costs[i] = np.min(utilities) - epsilon
    
    # Apply IR constraint from rejected logs to GMM clusters
    if rejected_logs:
        rejected_utilities_gmm = rejected_wages @ gmm_centers.T
        max_rejected_utilities_gmm = np.max(rejected_utilities_gmm, axis=0)
        refined_costs = np.maximum(refined_costs, max_rejected_utilities_gmm + epsilon)
    
    refined_costs = np.maximum(refined_costs, 0)
    
    # Merge and deduplicate clusters
    unique_centers, unique_indices = np.unique(gmm_centers, axis=0, return_index=True)
    unique_costs = refined_costs[unique_indices]
    
    # Ensure non-negativity and normalization
    unique_centers = np.clip(unique_centers, 0, 1)
    row_sums_unique = np.sum(unique_centers, axis=1, keepdims=True)
    row_sums_unique[row_sums_unique == 0] = 1
    unique_centers = unique_centers / row_sums_unique
    unique_costs = np.maximum(unique_costs, 0)
    
    agent_setting = np.hstack([unique_centers, unique_costs.reshape(-1, 1)])
    return agent_setting
```
