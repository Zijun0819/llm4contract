```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog, minimize
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
from scipy.spatial.distance import cdist
import warnings
warnings.filterwarnings('ignore')

def agent_solver(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    try:
        m_outcomes = v.shape[0]
        data = []
        for _, log in content.iterrows():
            if log['Agent Action'] == 1:
                data.append(list(log['Contract']) + [log['Principal Utility']])
        data = np.array(data)
        if len(data) == 0:
            return np.hstack([np.eye(m_outcomes), np.zeros((m_outcomes, 1))])
        
        X = data[:, :-1]
        n_candidates = min(max(int(np.sqrt(len(data))/2), 2), 20)
        
        gmm = GaussianMixture(n_components=n_candidates, covariance_type='diag', random_state=0, n_init=10)
        gmm.fit(X)
        p0 = gmm.means_
        
        membership = gmm.predict(X)
        costs = np.zeros(n_candidates)
        for a in range(n_candidates):
            mask = membership == a
            if np.sum(mask) > 0:
                utilities = data[mask, -1]
                costs[a] = -np.min(utilities) if len(utilities) > 0 else 0
        
        for _, log in content.iterrows():
            if log['Agent Action'] == -1:
                w = np.array(log['Contract'])
                for a in range(n_candidates):
                    utility = p0[a] @ w - costs[a]
                    if utility > -1e-10 and not np.isclose(utility, 0, atol=1e-10):
                        costs[a] += utility + 1e-10
        
        rej_costs = np.zeros(n_candidates)
        for _, log in content.iterrows():
            if log['Agent Action'] == -1:
                w = np.array(log['Contract'])
                for a in range(n_candidates):
                    utility = p0[a] @ w - rej_costs[a]
                    if utility < 0:
                        pass
                    else:
                        rej_costs[a] = max(rej_costs[a], p0[a] @ w + 1e-10)
        
        costs = np.maximum(costs, rej_costs)
        
        agent_setting = np.hstack([p0, costs[:, np.newaxis]])
        
        step = 0
        max_iter = 1000
        while step < max_iter:
            step += 1
            violations = []
            for _, log in content.iterrows():
                w = np.array(log['Contract'])
                a_pred = -1
                max_u = -np.inf
                for a in range(n_candidates):
                    u = p0[a] @ w - costs[a]
                    if u > max_u:
                        max_u = u
                        a_pred = a
                if max_u < -1e-10 and log['Agent Action'] == 1:
                    violations.append((w, 1))
                elif max_u >= -1e-10 and log['Agent Action'] == -1:
                    violations.append((w, -1))
            
            if not violations:
                return agent_setting
            
            for w, action in violations[:10]:
                if action == 1:
                    new_p, new_c = create_new_action(w, agent_setting, m_outcomes)
                    agent_setting = np.vstack([agent_setting, np.hstack([new_p, [new_c]])])
                else:
                    adjust_rejection(w, agent_setting)
            
            if agent_setting.shape[0] > 50:
                agent_setting = agent_setting[-50:, :]
                n_candidates = 50
        
        return agent_setting
    except:
        return np.hstack([np.eye(m_outcomes), np.zeros((m_outcomes, 1))])

def create_new_action(w, agent_setting, m_outcomes):
    A = np.vstack([np.ones(m_outcomes), w])
    b = [1.0, 0.0]
    bounds = [(0, 1.0)] * m_outcomes
    res = linprog(-w, A_eq=A, b_eq=b, bounds=bounds, method='highs')
    if res.success:
        p = np.maximum(res.x, 1e-10)
        p /= np.sum(p)
        c = np.dot(p, w) + 1e-8
        return p, c
    else:
        p = np.ones(m_outcomes) / m_outcomes
        c = np.dot(p, w) + 1e-8
        return p, c

def adjust_rejection(w, agent_setting):
    for i in range(agent_setting.shape[0]):
        u = agent_setting[i, :-1] @ w - agent_setting[i, -1]
        if u > -1e-10:
            agent_setting[i, -1] = agent_setting[i, :-1] @ w + 1e-8
```
