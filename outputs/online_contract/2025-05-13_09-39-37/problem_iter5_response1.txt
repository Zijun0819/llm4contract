```python
import numpy as np
import pandas as pd
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import silhouette_score
from scipy.optimize import linprog
from sklearn.metrics.pairwise import cosine_similarity

def agent_solver(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting (probability distributions over outcomes + costs)
    explaining the historical interaction logs between principal and agent,
    by jointly clustering accepted and rejected logs' inferred outcome distributions,
    adaptively selecting number of actions, and inferring costs to satisfy IR and IC constraints.

    Args:
        v (np.ndarray): Principal's reward vector for 5 outcomes, shape (5,)
        content (list[dict]): Each dict contains:
            - 'Contract': 5-dim payment vector,
            - 'Principal Utility': principal utility under contract,
            - 'Agent Action': 1 for accept, -1 for reject.

    Returns:
        np.ndarray: n x 6 matrix: first 5 cols are outcome probabilities (sum=1),
                    last column is agent cost (â‰¥0).
    """
    m_outcomes = v.shape[0]
    logs_df = pd.DataFrame(content)
    accepted = logs_df[logs_df['Agent Action'] == 1].reset_index(drop=True)
    rejected = logs_df[logs_df['Agent Action'] == -1].reset_index(drop=True)

    # If no accepted contracts, return trivial agent with uniform dist and zero cost
    if accepted.empty:
        return np.hstack([np.ones((1, m_outcomes)) / m_outcomes, np.zeros((1, 1))])

    # Step 1: Infer p for each accepted contract by LP
    # p: distribution over outcomes for agent action that accepted contract corresponds to
    def infer_p_for_log(w, u_p):
        # Solve LP:
        # variables: p (length m_outcomes)
        # constraints:
        #   sum p = 1
        #   p @ (v - w) = u_p
        # bounds: p_i in [0,1]
        # objective: maximize p @ w (agent expected payment)
        c_obj = -np.array(w)
        A_eq = [np.ones(m_outcomes), v - np.array(w)]
        b_eq = [1.0, u_p]
        bounds = [(0, 1) for _ in range(m_outcomes)]
        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            # Numerical fix: clip and re-normalize
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m_outcomes) / m_outcomes
            return p
        else:
            # fallback: uniform distribution
            return np.ones(m_outcomes) / m_outcomes

    p_accept = [infer_p_for_log(row['Contract'], row['Principal Utility']) for _, row in accepted.iterrows()]
    p_accept = np.vstack(p_accept)  # shape (n_accept, m_outcomes)

    # Step 2: Infer p for each rejected contract by LP with negative agent utility constraint
    # For rejected contracts, agent utility < 0 => p @ (w) - c < 0 for all c >= 0,
    # so we try to find p s.t. there is no feasible cost c >= 0 making utility >= 0.
    # We infer p that minimizes max agent expected payment (p @ w), subject to sum p=1, p in [0,1].
    # This leads to minimal agent expected payment, consistent with rejection.
    def infer_p_for_reject(w):
        # Solve LP:
        # variables: p (length m_outcomes)
        # constraints:
        #   sum p = 1
        # bounds: p_i in [0,1]
        # objective: minimize p @ w
        c_obj = np.array(w)
        A_eq = [np.ones(m_outcomes)]
        b_eq = [1.0]
        bounds = [(0, 1) for _ in range(m_outcomes)]
        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m_outcomes) / m_outcomes
            return p
        else:
            return np.ones(m_outcomes) / m_outcomes

    if not rejected.empty:
        p_reject = [infer_p_for_reject(row['Contract']) for _, row in rejected.iterrows()]
        p_reject = np.vstack(p_reject)  # shape (n_reject, m_outcomes)
    else:
        p_reject = np.empty((0, m_outcomes))

    # Step 3: Combine p_accept and p_reject for joint clustering
    # Label accepted as 1, rejected as 0 for reference
    p_all = np.vstack([p_accept, p_reject])
    labels_true = np.hstack([np.ones(len(p_accept), dtype=int), np.zeros(len(p_reject), dtype=int)])

    # Step 4: Adaptive clustering with silhouette to select number of clusters (actions)
    # Use AgglomerativeClustering with cosine affinity and linkage 'average'
    # Try cluster numbers from 2 to min(10, n_samples)
    max_clusters = min(10, len(p_all))
    if max_clusters < 2:
        # Not enough samples to cluster, fallback to single cluster
        centers = np.mean(p_all, axis=0, keepdims=True)
        centers = np.clip(centers, 0, None)
        centers /= centers.sum(axis=1, keepdims=True)
        n_actions = 1
        labels = np.zeros(len(p_all), dtype=int)
    else:
        best_n_clusters = None
        best_sil = -1
        best_labels = None
        for n_clusters in range(2, max_clusters + 1):
            clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity='cosine', linkage='average')
            try:
                cluster_labels = clustering.fit_predict(p_all)
                # Silhouette score requires at least 2 clusters and no singletons
                if len(set(cluster_labels)) == n_clusters:
                    sil = silhouette_score(p_all, cluster_labels, metric='cosine')
                    if sil > best_sil:
                        best_sil = sil
                        best_n_clusters = n_clusters
                        best_labels = cluster_labels
            except Exception:
                continue
        if best_labels is None:
            # fallback single cluster
            centers = np.mean(p_all, axis=0, keepdims=True)
            centers = np.clip(centers, 0, None)
            centers /= centers.sum(axis=1, keepdims=True)
            n_actions = 1
            labels = np.zeros(len(p_all), dtype=int)
        else:
            labels = best_labels
            n_actions = best_n_clusters
            # Compute centers as mean p per cluster
            centers = np.zeros((n_actions, m_outcomes))
            for i in range(n_actions):
                cluster_points = p_all[labels == i]
                center = cluster_points.mean(axis=0)
                center = np.clip(center, 0, None)
                s = center.sum()
                if s > 0:
                    center /= s
                else:
                    center = np.ones(m_outcomes) / m_outcomes
                centers[i] = center

    # Step 5: Infer minimal costs c_a satisfying IR and IC constraints
    eps_cost = 1e-8
    contract_acc = np.array(accepted['Contract'].tolist())
    contract_rej = np.array(rejected['Contract'].tolist()) if not rejected.empty else np.empty((0, m_outcomes))

    costs = np.zeros(n_actions)

    # For each action a:
    # IR: For accepted logs assigned to cluster a: p_a @ w - c_a >= 0 => c_a <= min p_a @ w
    # IC: For rejected logs: for all a: p_a @ w - c_a < 0 => c_a > max p_a @ w among rejects
    # First assign accepted/rejected logs to clusters
    accepted_idx = np.arange(len(p_accept))
    rejected_idx = np.arange(len(p_reject)) + len(p_accept)

    # Map accepted logs to clusters
    acc_labels = labels[accepted_idx] if len(accepted_idx) > 0 else np.array([], dtype=int)
    rej_labels = labels[rejected_idx] if len(rejected_idx) > 0 else np.array([], dtype=int)

    for a in range(n_actions):
        p_a = centers[a]
        assigned_acc_idx = accepted_idx[acc_labels == a] if len(acc_labels) > 0 else np.array([], dtype=int)
        if assigned_acc_idx.size > 0:
            w_acc = contract_acc[assigned_acc_idx]
            min_acc = np.min(w_acc @ p_a)
        else:
            min_acc = 0.0

        if contract_rej.shape[0] > 0:
            # For IC, consider max p_a @ w over all rejected logs (not just those assigned to cluster a)
            rej_vals = contract_rej @ p_a
            max_rej = np.max(rej_vals)
        else:
            max_rej = -np.inf

        cost_a = max(min_acc, max_rej + eps_cost)
        costs[a] = max(cost_a, 0.0)

    # Step 6: Validate and refine costs iteratively to ensure all IR and IC hold
    max_iter = 30
    for _ in range(max_iter):
        # Accepted logs: must have some action a with p_a @ w - c_a >= 0
        accept_utils = contract_acc @ centers.T - costs  # shape (n_accept, n_actions)
        accept_feasible = (accept_utils >= -eps_cost).any(axis=1)

        # Rejected logs: must have all actions a with p_a @ w - c_a < 0
        if contract_rej.shape[0] > 0:
            reject_utils = contract_rej @ centers.T - costs  # shape (n_reject, n_actions)
            reject_feasible = (reject_utils < eps_cost).all(axis=1)
        else:
            reject_feasible = np.array([True])

        if accept_feasible.all() and reject_feasible.all():
            break

        # Increase costs slightly to enforce constraints
        costs += eps_cost * 10
        costs = np.maximum(costs, 0.0)

    # Final normalization for numerical stability
    centers = np.clip(centers, 0, None)
    centers /= centers.sum(axis=1, keepdims=True)
    costs = np.maximum(costs, 0.0)

    agent_setting = np.hstack([centers, costs[:, None]])
    return agent_setting
```
