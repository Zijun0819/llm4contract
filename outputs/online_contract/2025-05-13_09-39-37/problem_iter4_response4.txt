```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix from principal's reward vector `v` and
    historical interaction logs `content`.

    Returns:
        agent_setting: n x 6 numpy array, where each row is [p_1,...,p_5, cost].
    """
    m = len(v)  # number of outcomes (5)
    logs_df = pd.DataFrame(content)
    n_logs = len(logs_df)

    # Separate accepted and rejected logs
    accepted = logs_df[logs_df['Agent Action'] == 1]
    rejected = logs_df[logs_df['Agent Action'] == -1]

    if accepted.empty:
        # No accepted contracts to infer from: fallback uniform with zero cost
        uniform_p = np.ones(m) / m
        return np.hstack([uniform_p, np.array([0.0])])[None, :]

    # LP feasibility function to infer p for each accepted log:
    # Find p s.t sum p=1, p≥0, p·(w - v) ≥ -u
    def infer_p_for_log(w, u):
        c = np.zeros(m)
        A_eq = [np.ones(m)]
        b_eq = [1.0]
        A_ub = [-(w - v)]
        b_ub = [u]
        bounds = [(0, 1)] * m
        res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            # Numerical corrections
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m) / m
            return p
        else:
            return None

    candidate_p = []
    u_vals = []
    for _, row in accepted.iterrows():
        w = np.array(row['Contract'])
        u = row['Principal Utility']
        p_candidate = infer_p_for_log(w, u)
        if p_candidate is not None:
            candidate_p.append(p_candidate)
            u_vals.append(u)
    if len(candidate_p) == 0:
        # fallback uniform with zero cost if no feasible p found
        uniform_p = np.ones(m) / m
        return np.hstack([uniform_p, np.array([0.0])])[None, :]

    candidate_p = np.vstack(candidate_p)
    u_vals = np.array(u_vals)

    # Adaptive clustering of candidate_p to find agent actions
    max_clusters = min(10, len(candidate_p))
    if max_clusters == 1:
        n_clusters = 1
    else:
        best_score = -1
        best_k = 1
        for k in range(2, max_clusters + 1):
            try:
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10).fit(candidate_p)
                score = silhouette_score(candidate_p, kmeans.labels_)
                if score > best_score:
                    best_score = score
                    best_k = k
            except Exception:
                continue
        n_clusters = best_k

    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20).fit(candidate_p)
    centers_p = kmeans.cluster_centers_

    # Normalize centers_p to valid distributions
    centers_p = np.clip(centers_p, 0, None)
    centers_p_sum = centers_p.sum(axis=1, keepdims=True)
    zero_sum_mask = centers_p_sum <= 1e-12
    centers_p[zero_sum_mask[:, 0]] = np.ones(m) / m
    centers_p_sum = centers_p.sum(axis=1, keepdims=True)
    centers_p /= centers_p_sum

    # Estimate initial costs per cluster from assigned accepted logs
    costs = np.zeros(n_clusters)
    for a in range(n_clusters):
        assigned_idx = np.where(kmeans.labels_ == a)[0]
        cluster_p = centers_p[a]
        if len(assigned_idx) == 0:
            costs[a] = 0.0
        else:
            # agent utility = p·w - cost >= 0 => cost <= p·w
            # principal utility = (v - w)·p = u => w·p = v·p - u
            # So cost <= w·p = v·p - u
            w_assigned = np.array([accepted.iloc[i]['Contract'] for i in assigned_idx])
            u_assigned = u_vals[assigned_idx]
            w_dot_p = w_assigned @ cluster_p
            # cost <= min(w·p) over assigned accepted logs to satisfy IR
            cost_ub = np.min(w_dot_p)
            # Also cost <= min v·p - u
            cost_ub2 = np.min((v @ cluster_p) - u_assigned)
            cost_ub = min(cost_ub, cost_ub2)
            costs[a] = max(0., cost_ub)

    # Assign accepted logs to clusters by max agent utility p_a·w - cost_a
    accepted_idx = accepted.index.values
    def assign_action(w):
        utilities = centers_p @ w - costs
        return np.argmax(utilities)

    assigned_actions = np.array([assign_action(np.array(accepted.loc[i, 'Contract'])) for i in accepted_idx])

    # Adjust costs downward if any accepted log violates IR (agent utility < 0)
    # Iterate a few times to stabilize
    for _ in range(3):
        updated = False
        for idxi, a_i in zip(accepted_idx, assigned_actions):
            p_a = centers_p[a_i]
            w_i = np.array(accepted.loc[idxi, 'Contract'])
            agent_util = p_a @ w_i - costs[a_i]
            if agent_util < 0:
                new_cost = max(0., costs[a_i] + agent_util)
                if new_cost < costs[a_i]:
                    costs[a_i] = new_cost
                    updated = True
        if not updated:
            break

    # Enforce rejection constraints: for all rejected logs and all actions,
    # agent utility must be strictly < 0; increase costs if needed
    rejected_idx = rejected.index.values
    for _ in range(3):
        updated = False
        for idxr in rejected_idx:
            w_r = np.array(rejected.loc[idxr, 'Contract'])
            for a in range(n_clusters):
                util = centers_p[a] @ w_r - costs[a]
                if util >= 0:
                    new_cost = util + 1e-5  # small margin
                    if new_cost > costs[a]:
                        costs[a] = new_cost
                        updated = True
        if not updated:
            break

    # Final normalization of centers_p (fix any numerical issues)
    centers_p = np.clip(centers_p, 0, None)
    centers_p_sum = centers_p.sum(axis=1, keepdims=True)
    zero_sum_mask = centers_p_sum <= 1e-12
    centers_p[zero_sum_mask[:, 0]] = np.ones(m) / m
    centers_p_sum = centers_p.sum(axis=1, keepdims=True)
    centers_p /= centers_p_sum

    # Compose final agent setting matrix (n_actions x 6)
    agent_setting = np.hstack([centers_p, costs.reshape(-1, 1)])

    return agent_setting
```
