```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import AgglomerativeClustering
from scipy.spatial.distance import cdist

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting (prob distributions over outcomes + costs)
    explaining the historical interaction logs between principal and agent,
    robustly incorporating accepted and rejected contracts with adaptive clustering
    and iterative cost refinement enforcing IR and IC constraints.

    Args:
        v (np.ndarray): Principal's reward vector for 5 outcomes, shape (5,)
        content (list[dict]): Each dict contains
            - 'Contract': 5-dim payment vector,
            - 'Principal Utility': principal utility under contract,
            - 'Agent Action': 1 for accept, -1 for reject.

    Returns:
        np.ndarray: n x 6 matrix: first 5 cols are outcome probabilities (sum=1),
                    last column is agent cost (â‰¥0).
    """
    m_outcomes = v.shape[0]
    logs_df = pd.DataFrame(content)
    accepted = logs_df[logs_df['Agent Action'] == 1].reset_index(drop=True)
    rejected = logs_df[logs_df['Agent Action'] == -1].reset_index(drop=True)

    # If no accepted logs, return trivial agent: uniform dist + zero cost
    if accepted.empty:
        return np.hstack([np.ones((1, m_outcomes)) / m_outcomes, np.zeros((1, 1))])

    # LP to infer agent's outcome distribution p for each accepted contract
    def infer_p_for_log(w, u_p):
        # Solve LP:
        # variables: p (length m_outcomes)
        # constraints:
        #   sum p = 1
        #   p @ (v - w) = u_p
        # bounds: p_i in [0,1]
        # objective: maximize p @ w (agent expected payment)
        c_obj = -np.array(w, dtype=np.float64)
        A_eq = np.vstack([np.ones(m_outcomes), v - w])
        b_eq = np.array([1.0, u_p], dtype=np.float64)
        bounds = [(0, 1)] * m_outcomes
        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m_outcomes) / m_outcomes
            return p
        else:
            return np.ones(m_outcomes) / m_outcomes

    p_accept_list = [infer_p_for_log(row['Contract'], row['Principal Utility']) for _, row in accepted.iterrows()]
    p_accept = np.vstack(p_accept_list)  # shape (n_accept, m_outcomes)

    # Incorporate rejected contracts by inferring p that yield agent utility < 0
    # We only use accepted inferred p for clustering to avoid noise from rejection ambiguity

    # Adaptive clustering on accepted p vectors to find distinct agent actions
    # Try multiple distance_thresholds and pick the one maximizing silhouette score if possible
    from sklearn.metrics import silhouette_score

    best_score = -np.inf
    best_labels = None
    best_n_clusters = 1
    best_centers = None
    distance_thresholds = np.linspace(0.05, 0.3, 7)

    for dist_thres in distance_thresholds:
        clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=dist_thres, linkage='average')
        labels = clustering.fit_predict(p_accept)
        n_clusters = labels.max() + 1
        if n_clusters < 2:
            continue
        try:
            score = silhouette_score(p_accept, labels)
            if score > best_score:
                best_score = score
                best_labels = labels
                best_n_clusters = n_clusters
        except Exception:
            continue

    if best_labels is None:
        # fallback single cluster: mean p_accept
        center = p_accept.mean(axis=0)
        center = np.clip(center, 0, None)
        s = center.sum()
        if s > 0:
            center /= s
        else:
            center = np.ones(m_outcomes) / m_outcomes
        centers = center.reshape(1, -1)
        n_actions = 1
        labels = np.zeros(p_accept.shape[0], dtype=int)
    else:
        labels = best_labels
        n_actions = best_n_clusters
        centers = np.zeros((n_actions, m_outcomes), dtype=np.float64)
        for a in range(n_actions):
            cluster_ps = p_accept[labels == a]
            c = cluster_ps.mean(axis=0)
            c = np.clip(c, 0, None)
            s = c.sum()
            if s > 0:
                c /= s
            else:
                c = np.ones(m_outcomes) / m_outcomes
            centers[a] = c

    accepted_contracts = np.array(accepted['Contract'].tolist(), dtype=np.float64)
    rejected_contracts = np.array(rejected['Contract'].tolist(), dtype=np.float64) if not rejected.empty else np.empty((0, m_outcomes))

    eps = 1e-8
    costs = np.zeros(n_actions, dtype=np.float64)

    # Assign each accepted log to closest center to initialize cost constraints
    dist_acc = cdist(p_accept, centers, metric='euclidean')
    assigned_clusters = dist_acc.argmin(axis=1)

    # Initialize costs satisfying IR and IC constraints conservatively
    for a in range(n_actions):
        p_a = centers[a]

        # IR: agent utility >= 0 for accepted contracts assigned to cluster a
        idx_acc = np.where(assigned_clusters == a)[0]
        if idx_acc.size > 0:
            w_acc = accepted_contracts[idx_acc]
            max_acc = np.max(w_acc @ p_a)
        else:
            max_acc = 0.0

        # IC: agent utility < 0 for all rejected contracts (strict)
        if rejected_contracts.shape[0] > 0:
            rej_vals = rejected_contracts @ p_a
            max_rej = rej_vals.max()
        else:
            max_rej = -np.inf

        cost_a = max(max_acc, max_rej + eps)
        costs[a] = max(cost_a, 0.0)

    # Iterative refinement of costs to satisfy IR and IC jointly
    max_iters = 60
    for _ in range(max_iters):
        prev_costs = costs.copy()

        # Accepted utilities: shape (n_accept, n_actions)
        accept_utils = accepted_contracts @ centers.T - costs[None, :]
        # Assign each accepted log to best action (max utility)
        accept_best_util = accept_utils.max(axis=1)
        accept_best_action = accept_utils.argmax(axis=1)

        # Check IR: all accepted logs must have utility >= 0
        violated_accept_idx = np.where(accept_best_util < -eps)[0]

        # Rejected utilities: shape (n_reject, n_actions)
        if rejected_contracts.shape[0] > 0:
            reject_utils = rejected_contracts @ centers.T - costs[None, :]
            max_reject_util = reject_utils.max(axis=1)
            violated_reject_idx = np.where(max_reject_util >= -eps)[0]
        else:
            violated_reject_idx = np.array([], dtype=int)

        if violated_accept_idx.size == 0 and violated_reject_idx.size == 0:
            break  # all constraints satisfied

        # Fix IR violations: increase cost of best action for violating accepted logs
        for idx_acc in violated_accept_idx:
            a = accept_best_action[idx_acc]
            w = accepted_contracts[idx_acc]
            required_cost = centers[a] @ w
            if costs[a] < required_cost:
                costs[a] = required_cost

        # Fix IC violations: increase costs of all violating actions for rejected logs
        for idx_rej in violated_reject_idx:
            utilities = reject_utils[idx_rej]
            violating_actions = np.where(utilities >= -eps)[0]
            w = rejected_contracts[idx_rej]
            for a in violating_actions:
                required_cost = centers[a] @ w + eps
                if costs[a] < required_cost:
                    costs[a] = required_cost

        # Clamp costs to non-negative
        costs = np.maximum(costs, 0.0)

        # Early stopping if costs stabilized
        if np.allclose(costs, prev_costs, atol=eps):
            break

    # Final normalization of centers and costs
    centers = np.clip(centers, 0, None)
    s = centers.sum(axis=1, keepdims=True)
    s[s == 0] = 1.0
    centers /= s
    costs = np.maximum(costs, 0.0)

    agent_setting = np.hstack([centers, costs[:, None]])
    return agent_setting
```
