```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import DBSCAN


def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x [probabilities over 5 outcomes + cost]) that explains the
    historical interactions between principal and agent under IR (Individual Rationality) and IC (Incentive Compatibility).

    Args:
        v: np.ndarray, shape (5,) - principal's reward vector for 5 outcomes.
        content: list of dicts, each dict has keys:
            - 'Contract': list or np.ndarray, 5-dimensional payment vector for 5 outcomes
            - 'Principal Utility': float, principal's utility under contract (0 if agent rejects)
            - 'Agent Action': int, 1 if accepted (agent utility ≥ 0), -1 if rejected (agent utility < 0)

    Returns:
        np.ndarray of shape (n_actions, 6): [p_1,...,p_5,cost] with:
            - p_i: probability of ith outcome for that action (sum to 1)
            - cost: non-negative agent cost of action
    """

    # Prepare data arrays
    contracts = np.array([log['Contract'] for log in content])
    principal_utils = np.array([log['Principal Utility'] for log in content])
    agent_actions = np.array([log['Agent Action'] for log in content])

    n_logs, m_outcomes = contracts.shape
    assert m_outcomes == v.size == 5

    # Step 1: Extract accepted and rejected logs
    accepted_idx = np.where(agent_actions == 1)[0]
    rejected_idx = np.where(agent_actions == -1)[0]

    if accepted_idx.size == 0:
        # No accepted logs, return trivial agent setting (uniform distribution, zero cost)
        uniform_p = np.ones(5) / 5
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])

    # Step 2: For each accepted log, infer a plausible agent outcome distribution and cost
    # Using LP to find p s.t. p >=0, sum p=1, agent utility = p.w - cost >=0,
    # and principal utility = v.p - w.p (w is contract payment vector)
    # The agent's cost = w.p - agent utility >=0

    # We'll find for each accepted contract a plausible p vector explaining acceptance
    # The idea: agent utility >=0 => p.w >= cost, principal utility given
    # We do not know cost nor p, but can try to find p s.t. p.w - cost >=0 and principal utility = v.p - w.p

    # To find candidate p vectors, we solve LPs:
    # Variables: p_i ≥0, sum p_i=1
    # Objective: minimize ||p - uniform|| (implemented by linprog twice)

    # To get candidate p for each accepted contract, we solve:
    # p.w - cost ≥0 => agent utility ≥ 0
    # principal utility = v.p - w.p = given (observed)
    # cost unknown, but cost = w.p - agent utility ≤ w.p (since agent utility ≥0)
    #
    # So assume cost = w.p - agent utility with agent utility >=0, cost ≥0
    #
    # We try to find p s.t. agent utility >= 0 and principal utility matches observed
    # But principal utility given by v.p - w.p (w known)
    #
    # So if we fix cost=0 (lowest cost consistent with acceptance), then agent utility = p.w ≥ 0,
    # and principal utility = v.p - w.p = v.p - agent utility = given

    # We do a feasibility LP for each accepted contract:
    # Find p s.t.
    # sum p_i = 1
    # p_i ≥ 0
    # v.p - w.p = principal_utility
    # p.w ≥ 0   # agent utility ≥ 0

    candidate_p = []
    for idx in accepted_idx:
        w = contracts[idx]
        pu = principal_utils[idx]

        # Set up LP variables: p (5 variables)
        # Constraints:
        # 1) sum p_i = 1
        # 2) v.p - w.p = pu  => (v - w).p = pu  (equality)
        # 3) p.w >= 0      => w.p >= 0       (inequality)
        # 4) p_i >=0

        # linprog needs inequalities in form A_ub @ x <= b_ub, and equalities A_eq @ x = b_eq
        A_eq = np.vstack([np.ones(m_outcomes), v - w])
        b_eq = np.array([1.0, pu])

        # For p.w >=0, write as -w.p <= 0
        A_ub = -w.reshape(1, -1)
        b_ub = np.array([0.0])

        bounds = [(0, 1) for _ in range(m_outcomes)]

        # Objective: to get a "nice" p, minimize L1 distance from uniform p=1/5
        c = np.abs(np.ones(m_outcomes) / m_outcomes)

        res = linprog(c=c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq,
                      bounds=bounds, method='highs')

        if res.success:
            p_sol = res.x
            # project p to simplex numerically stable
            p_sol[p_sol < 0] = 0
            p_sol = p_sol / np.sum(p_sol)
            candidate_p.append(p_sol)
        else:
            # If no solution with agent utility >=0, relax agent utility constraint and just ignore that inequality
            A_eq_alt = A_eq
            b_eq_alt = b_eq
            bounds_alt = [(0, 1) for _ in range(m_outcomes)]

            res_alt = linprog(c=c, A_eq=A_eq_alt, b_eq=b_eq_alt,
                              bounds=bounds_alt, method='highs')
            if res_alt.success:
                p_sol_alt = res_alt.x
                p_sol_alt[p_sol_alt < 0] = 0
                p_sol_alt = p_sol_alt / np.sum(p_sol_alt)
                candidate_p.append(p_sol_alt)
            else:
                # fallback: uniform distribution for this contract
                candidate_p.append(np.ones(m_outcomes) / m_outcomes)

    candidate_p = np.array(candidate_p)

    # Step 3: Cluster candidate_p with density-based clustering (DBSCAN) to find distinct actions adaptively
    # DBSCAN can detect number of clusters automatically
    clustering = DBSCAN(eps=0.05, min_samples=2).fit(candidate_p)
    labels = clustering.labels_

    # If all points are noise (-1), fallback to single cluster
    if np.all(labels == -1):
        labels = np.zeros(candidate_p.shape[0], dtype=int)

    unique_labels = np.unique(labels)
    unique_labels = unique_labels[unique_labels != -1]  # remove noise label if any

    if len(unique_labels) == 0:
        # all noise points, treat as one cluster
        unique_labels = np.array([0])
        labels = np.zeros(candidate_p.shape[0], dtype=int)

    # For noise points (-1), assign to nearest cluster center
    noise_idx = np.where(labels == -1)[0]
    if noise_idx.size > 0 and len(unique_labels) > 0:
        centers = np.array([candidate_p[labels == ul].mean(axis=0) for ul in unique_labels])
        for ni in noise_idx:
            dists = np.linalg.norm(centers - candidate_p[ni], axis=1)
            assign_label = unique_labels[np.argmin(dists)]
            labels[ni] = assign_label

    n_actions = len(unique_labels)
    # Calculate final cluster centers as mean p of each cluster
    p_cluster = []
    for ul in unique_labels:
        p_cluster.append(candidate_p[labels == ul].mean(axis=0))
    p_cluster = np.array(p_cluster)
    # Normalize each p to sum to 1 and ensure non-negativity
    p_cluster[p_cluster < 0] = 0
    p_cluster = p_cluster / p_cluster.sum(axis=1, keepdims=True)

    # Step 4: Infer agent cost for each action by IR and IC constraints:

    # IR: For accepted logs assigned to cluster a:
    # cost_a <= p_a.w for their observed contract w (agent utility >=0)
    # So cost_a <= min over all assigned logs of p_a.w

    # IC (incentive compatibility) for rejected logs:
    # agent utility for all actions on rejected contracts < 0 => p_a.w < cost_a for all a and rejected contracts w

    cost_candidates = np.zeros(n_actions)
    # Assign each accepted log to nearest cluster by L2 distance of candidate_p
    accepted_p = candidate_p
    assigned_accepted_clusters = labels

    for a in range(n_actions):
        idx_assigned = np.where(assigned_accepted_clusters == unique_labels[a])[0]
        if idx_assigned.size == 0:
            cost_candidates[a] = 0.0  # no data, cost zero minimal
            continue
        # For each assigned accepted log, compute p_a.w
        w_assigned = contracts[accepted_idx[idx_assigned]]
        vals = w_assigned @ p_cluster[a]  # agent utility for action a on assigned contracts
        cost_candidates[a] = vals.min()  # cost must be <= min agent utility for acceptance

    # For rejected logs, agent utility < 0 => p_a.w < cost_a
    if rejected_idx.size > 0:
        w_rejected = contracts[rejected_idx]
        for a in range(n_actions):
            agent_util_rej = w_rejected @ p_cluster[a]
            # cost_a should be strictly greater than max agent_util_rej to justify rejection
            cost_candidates[a] = max(cost_candidates[a], agent_util_rej.max() + 1e-6)
    else:
        # No rejected logs, just keep IR cost
        pass

    # Enforce cost nonnegativity
    cost_candidates[cost_candidates < 0] = 0.0

    # Step 5: Final agent setting matrix
    # Each action: [p_1,...,p_5, cost]
    agent_setting = np.hstack([p_cluster, cost_candidates.reshape(-1, 1)])

    return agent_setting
```
