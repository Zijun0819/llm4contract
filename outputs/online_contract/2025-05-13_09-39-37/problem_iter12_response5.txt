```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score
from sklearn.metrics.pairwise import cosine_similarity

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting (probability distributions over outcomes + costs)
    explaining the historical interaction logs between principal and agent,
    by adaptively clustering inferred outcome distributions with cosine metric,
    assigning noise points by cosine similarity, and iteratively refining costs
    to satisfy IR and IC constraints for accepted and rejected contracts.

    Args:
        v (np.ndarray): Principal's reward vector for 5 outcomes, shape (5,)
        content (list[dict]): Each dict contains:
            - 'Contract': 5-dim payment vector,
            - 'Principal Utility': principal utility under contract,
            - 'Agent Action': 1 for accept, -1 for reject.

    Returns:
        np.ndarray: n x 6 matrix: first 5 cols are outcome probabilities (sum=1),
                    last column is agent cost (â‰¥0).
    """
    m_outcomes = v.shape[0]
    logs_df = pd.DataFrame(content)
    accepted = logs_df[logs_df['Agent Action'] == 1].reset_index(drop=True)
    rejected = logs_df[logs_df['Agent Action'] == -1].reset_index(drop=True)

    # If no accepted contracts, return trivial agent with uniform distribution and zero cost
    if accepted.empty:
        uniform_p = np.ones(m_outcomes) / m_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.zeros((1, 1))])

    # Step 1: Infer p for each accepted contract by LP with tightened feasibility and robust fallback
    def infer_p_for_log(w, u_p):
        w = np.array(w, dtype=np.float64)
        c_obj = -w
        A_eq = np.vstack([np.ones(m_outcomes), v - w])
        b_eq = np.array([1.0, u_p], dtype=np.float64)
        bounds = [(0, 1) for _ in range(m_outcomes)]

        # Primary LP: equality constraints
        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m_outcomes) / m_outcomes
            return p

        # Fallback LP: relax equality (v-w) @ p >= u_p - tol
        tol = 1e-9
        A_ub = np.array([-(v - w)])
        b_ub = np.array([-(u_p - tol)])
        res2 = linprog(c=c_obj, A_eq=[np.ones(m_outcomes)], b_eq=[1.0],
                       A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')
        if res2.success:
            p = res2.x
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m_outcomes) / m_outcomes
            return p

        # Final fallback uniform distribution
        return np.ones(m_outcomes) / m_outcomes

    p_list = [infer_p_for_log(row['Contract'], row['Principal Utility']) for _, row in accepted.iterrows()]
    p_array = np.vstack(p_list)  # shape (n_accept, m_outcomes)

    # Step 2: Adaptive DBSCAN clustering with cosine metric and silhouette checks on finer grid
    eps_candidates = np.linspace(0.025, 0.18, 15)
    best_eps = None
    best_labels = None
    best_silhouette = -1

    for eps in eps_candidates:
        clustering = DBSCAN(eps=eps, min_samples=2, metric='cosine').fit(p_array)
        labels = clustering.labels_
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        if n_clusters >= 2:
            mask = labels != -1
            if np.sum(mask) >= 5:
                try:
                    sil = silhouette_score(p_array[mask], labels[mask], metric='cosine')
                    if sil > best_silhouette:
                        best_silhouette = sil
                        best_eps = eps
                        best_labels = labels.copy()
                except Exception:
                    continue
        elif n_clusters == 1 and -1 not in labels:
            # Single cluster no noise acceptable fallback
            best_eps = eps
            best_labels = labels.copy()
            best_silhouette = 0.0

    if best_labels is None:
        # Fallback: assign all to one cluster
        best_labels = np.zeros(len(p_array), dtype=int)

    labels = best_labels
    noise_idx = np.where(labels == -1)[0]
    unique_labels = sorted(set(labels) - {-1})
    n_actions = len(unique_labels)
    if n_actions == 0:
        # All noise fallback to one cluster
        n_actions = 1
        labels[:] = 0
        unique_labels = [0]

    # Step 3: Compute cluster centers (mean p per cluster), normalize strictly
    centers = np.zeros((n_actions, m_outcomes), dtype=np.float64)
    for i, lab in enumerate(unique_labels):
        cluster_ps = p_array[labels == lab]
        c = cluster_ps.mean(axis=0)
        c = np.clip(c, 0, None)
        s = c.sum()
        if s > 0:
            c /= s
        else:
            c = np.ones(m_outcomes) / m_outcomes
        centers[i] = c

    # Step 4: Assign noise points to nearest cluster center by cosine similarity
    if noise_idx.size > 0:
        noise_p = p_array[noise_idx]
        sim = cosine_similarity(noise_p, centers)  # (noise_size, n_actions)
        assign_labels = sim.argmax(axis=1)
        for idx, assigned_cluster in zip(noise_idx, assign_labels):
            labels[idx] = unique_labels[assigned_cluster]

    # Map all labels to 0..n_actions-1
    label_map = {lab: i for i, lab in enumerate(unique_labels)}
    mapped_labels = np.array([label_map[lab] for lab in labels])

    # Prepare contract arrays
    contract_acc = np.array(accepted['Contract'].tolist(), dtype=np.float64)
    contract_rej = np.array(rejected['Contract'].tolist(), dtype=np.float64) if not rejected.empty else np.empty((0, m_outcomes), dtype=np.float64)

    eps_cost = 1e-10
    costs = np.zeros(n_actions, dtype=np.float64)

    # Step 5: Initialize minimal costs c_a satisfying IR and IC constraints conservatively
    for a in range(n_actions):
        p_a = centers[a]
        assigned_acc_idx = np.where(mapped_labels == a)[0]
        if assigned_acc_idx.size > 0:
            w_acc = contract_acc[assigned_acc_idx]
            min_acc = np.min(w_acc @ p_a)
        else:
            min_acc = 0.0

        if contract_rej.shape[0] > 0:
            max_rej = np.max(contract_rej @ p_a)
        else:
            max_rej = -np.inf

        costs[a] = max(min_acc, max_rej + eps_cost, 0.0)

    # Step 6: Iteratively refine costs to satisfy IR and IC constraints strictly
    max_iter = 60
    for _ in range(max_iter):
        prev_costs = costs.copy()

        # Accepted contracts: at least one action with utility >= 0 (agent accepts)
        accept_utils = contract_acc @ centers.T - costs  # (n_accept, n_actions)
        accept_feasible = (accept_utils >= -eps_cost).any(axis=1)

        # Rejected contracts: all actions utility < 0 (agent rejects)
        if contract_rej.shape[0] > 0:
            reject_utils = contract_rej @ centers.T - costs  # (n_reject, n_actions)
            reject_feasible = (reject_utils < eps_cost).all(axis=1)
        else:
            reject_feasible = np.array([True])

        if accept_feasible.all() and reject_feasible.all():
            break

        # Increase costs to fix IR violations on accepted contracts
        for i, feasible in enumerate(accept_feasible):
            if not feasible:
                violated_actions = np.where(accept_utils[i] < -eps_cost)[0]
                if violated_actions.size > 0:
                    costs[violated_actions] += eps_cost * 25

        # Increase costs to fix IC violations on rejected contracts
        if contract_rej.shape[0] > 0:
            for i, feasible in enumerate(reject_feasible):
                if not feasible:
                    violated_actions = np.where(reject_utils[i] >= eps_cost)[0]
                    if violated_actions.size > 0:
                        costs[violated_actions] += eps_cost * 25

        costs = np.maximum(costs, 0.0)

        # Early stop if costs stabilized
        if np.allclose(costs, prev_costs, atol=eps_cost):
            break

    # Final cleanup: normalize centers strictly and ensure costs non-negative
    centers = np.clip(centers, 0, None)
    centers_sum = centers.sum(axis=1, keepdims=True)
    centers_sum[centers_sum == 0] = 1.0
    centers /= centers_sum
    costs = np.maximum(costs, 0.0)

    agent_setting = np.hstack([centers, costs[:, None]])
    return agent_setting
```
