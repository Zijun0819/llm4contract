```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import AgglomerativeClustering

def agent_solver_v2(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    """
    Infers a valid agent setting matrix from historical logs between principal and agent.

    Parameters:
    - v: np.ndarray of shape (5,), principal's reward vector for 5 outcomes
    - content: pd.DataFrame with columns ['Contract', 'Principal Utility', 'Agent Action']
      Contract is list-like 5-dimensional payment vector,
      Principal Utility is float (0 if rejected),
      Agent Action is int {1 (accept), -1 (reject)}

    Returns:
    - agent_setting: np.ndarray with shape (n_actions, 6),
      each row: [p_1,...,p_5, cost], where p_i sum to 1 and cost >=0
    """
    m = v.shape[0]
    logs = content.copy()
    L = len(logs)
    contracts = np.array(logs['Contract'].tolist())  # shape (L,5)
    utilities = np.array(logs['Principal Utility'].tolist())  # shape (L,)
    agent_actions = np.array(logs['Agent Action'].tolist())  # shape (L,)

    # 1) Separate accepted and rejected logs
    accepted_idx = np.where(agent_actions == 1)[0]
    rejected_idx = np.where(agent_actions == -1)[0]

    if len(accepted_idx) == 0:
        # No acceptance logs, return trivial agent setting: uniform dist, zero cost
        p_uniform = np.ones(m) / m
        return np.array([np.append(p_uniform, 0.)])

    # 2) For each accepted log, infer agent outcome distribution p by solving:
    #    maximize agent expected utility >= 0 under contract W
    #    agent utility U = p @ w - cost >= 0
    # Since cost unknown, infer p that fits the contract and principal utility given v
    # We'll approximate p as the argmax p @ w s.t p sums to 1, p>=0
    # and constrain that principal utility = p @ (v - w)
    # We relax principal utility to equality constraints, then cluster p's

    # Helper: Solve LP to find p for given contract w and principal utility u
    def infer_p(w: np.ndarray, u: float) -> np.ndarray | None:
        # Constraints:
        # sum p =1
        # p >=0
        # p@(v - w) = u   (principal utility)
        # We solve LP: max p @ w (agent expected wage)
        # subject to above constraints

        A_eq = np.vstack([
            np.ones(m),        # sum p =1
            v - w              # p@(v-w) = u
        ])
        b_eq = np.array([1.0, u])
        bounds = [(0,1)] * m

        # Objective: maximize p@w --> minimize -p@w
        c = -w
        res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            # Numerical cleanup: threshold small negatives to zero
            p[p < 0] = 0
            p /= p.sum()
            return p
        else:
            return None

    p_candidates = []
    valid_accept_idx = []
    for i in accepted_idx:
        w = contracts[i]
        u = utilities[i]
        p_i = infer_p(w, u)
        if p_i is not None:
            p_candidates.append(p_i)
            valid_accept_idx.append(i)
    if len(p_candidates) == 0:
        # fallback trivial
        p_uniform = np.ones(m) / m
        return np.array([np.append(p_uniform, 0.)])

    p_candidates = np.vstack(p_candidates)  # shape (num_valid_accept, m)

    # 3) Cluster inferred p vectors adaptively by Agglomerative Clustering (distance threshold)
    # Use cosine distance to cluster p's into groups representing distinct agent actions
    clustering = AgglomerativeClustering(
        n_clusters=None,
        affinity='cosine',
        linkage='average',
        distance_threshold=0.15
    ).fit(p_candidates)
    labels = clustering.labels_
    n_actions = labels.max() + 1

    # 4) Compute centroids p_a of clusters as agent outcome distributions
    p_actions = np.zeros((n_actions, m))
    for a in range(n_actions):
        cluster_p = p_candidates[labels == a]
        centroid = cluster_p.mean(axis=0)
        centroid[centroid < 0] = 0
        centroid /= centroid.sum()
        p_actions[a] = centroid

    # 5) Estimate agent cost c_a per action to satisfy IR and IC constraints
    # IR: For accepted logs assigned to cluster a:
    #     p_a @ w_i - c_a >= 0  -> c_a <= p_a @ w_i (agent utility â‰¥0)
    # Take minimal p_a @ w_i over assigned accepted logs as upper bound for c_a.
    c_upper = np.zeros(n_actions)
    for a in range(n_actions):
        assigned_logs = [valid_accept_idx[j] for j, lab in enumerate(labels) if lab == a]
        if len(assigned_logs) == 0:
            c_upper[a] = 0.0
        else:
            p_w = np.array([p_actions[a] @ contracts[i] for i in assigned_logs])
            c_upper[a] = np.min(p_w)

    # IC: For rejected logs, ensure that agent expected utility < 0 for all actions:
    # p_a @ w_j - c_a < 0  => c_a > p_a @ w_j for rejected log j
    # So for each action a, cost c_a must > max_{rejected j} p_a @ w_j
    if len(rejected_idx) > 0:
        p_w_rej = np.array([[p_actions[a] @ contracts[j] for j in rejected_idx] for a in range(n_actions)])
        c_lower = p_w_rej.max(axis=1) + 1e-8  # small epsilon for strictness
    else:
        c_lower = np.zeros(n_actions)

    # 6) Final cost c_a must satisfy c_lower < c_a <= c_upper
    # If c_lower > c_upper for some action, relax by setting c_a = max(c_lower,0)
    c_final = np.maximum(c_lower, 0)
    for a in range(n_actions):
        if c_final[a] > c_upper[a]:
            # Conflict, pick midpoint or c_final[a] anyway
            c_final[a] = max(c_final[a], 0)

    # 7) Normalize p_actions to ensure sum=1 and nonnegative (already done)
    for a in range(n_actions):
        p_actions[a][p_actions[a] < 0] = 0
        s = p_actions[a].sum()
        if s == 0:
            p_actions[a] = np.ones(m) / m
        else:
            p_actions[a] /= s

    # 8) Return concatenated agent_setting: p_actions + c_final
    agent_setting = np.hstack([p_actions, c_final[:, None]])
    return agent_setting
```
