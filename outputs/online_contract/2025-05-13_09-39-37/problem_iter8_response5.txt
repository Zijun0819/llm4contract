```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics.pairwise import cosine_distances

def agent_solver(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting (prob distributions over outcomes + costs)
    explaining the historical interaction logs between principal and agent,
    using adaptive clustering, iterative action assignment refinement,
    and strict IR/IC cost enforcement with margin.

    Args:
        v (np.ndarray): Principal's reward vector for 5 outcomes, shape (5,)
        content (list[dict]): Each dict contains:
            - 'Contract': 5-dim payment vector,
            - 'Principal Utility': principal utility under contract,
            - 'Agent Action': 1 for accept, -1 for reject.

    Returns:
        np.ndarray: n x 6 matrix: first 5 cols are outcome probabilities (sum=1),
                    last column is agent cost (â‰¥0).
    """
    m_outcomes = v.shape[0]
    logs_df = pd.DataFrame(content)
    accepted = logs_df[logs_df['Agent Action'] == 1].reset_index(drop=True)
    rejected = logs_df[logs_df['Agent Action'] == -1].reset_index(drop=True)

    # If no accepted logs, return trivial agent: uniform dist + zero cost
    if accepted.empty:
        return np.hstack([np.ones((1, m_outcomes)) / m_outcomes, np.zeros((1, 1))])

    # LP to infer agent's outcome distribution p for each accepted contract
    def infer_p_for_log(w, u_p):
        c_obj = -np.array(w)  # maximize p @ w <=> minimize -p @ w
        A_eq = [np.ones(m_outcomes), v - w]
        b_eq = [1.0, u_p]
        bounds = [(0, 1) for _ in range(m_outcomes)]
        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m_outcomes) / m_outcomes
            return p
        else:
            return np.ones(m_outcomes) / m_outcomes

    p_list = [infer_p_for_log(row['Contract'], row['Principal Utility']) for _, row in accepted.iterrows()]
    p_array = np.vstack(p_list)

    # Adaptive clustering: try multiple distance thresholds to find stable clustering
    best_labels = None
    best_score = -np.inf
    thresholds = np.linspace(0.05, 0.3, 15)
    n_accept = p_array.shape[0]

    def silhouette_cosine(X, labels):
        from sklearn.metrics import pairwise_distances
        unique_labels = np.unique(labels)
        if len(unique_labels) == 1:
            return 0.0
        dist = pairwise_distances(X, metric='cosine')
        sil_samples = []
        for i in range(len(X)):
            own_cluster = labels[i]
            in_cluster = labels == own_cluster
            out_clusters = labels != own_cluster
            a = np.mean(dist[i, in_cluster]) if np.sum(in_cluster) > 1 else 0
            b = np.min([np.mean(dist[i, labels == l]) for l in unique_labels if l != own_cluster])
            sil_samples.append((b - a) / max(a, b) if max(a, b) > 0 else 0)
        return np.mean(sil_samples)

    for thresh in thresholds:
        clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=thresh, affinity='cosine', linkage='average')
        labels = clustering.fit_predict(p_array)
        n_clusters = labels.max() + 1
        if 1 < n_clusters <= min(10, n_accept):
            try:
                score = silhouette_cosine(p_array, labels)
                if score > best_score:
                    best_score = score
                    best_labels = labels.copy()
            except Exception:
                continue

    if best_labels is None:
        best_labels = np.zeros(n_accept, dtype=int)

    labels = best_labels
    unique_labels = np.unique(labels)
    n_actions = len(unique_labels)

    # Compute cluster centers (mean p per cluster), normalize
    centers = np.zeros((n_actions, m_outcomes))
    for i, lab in enumerate(unique_labels):
        cluster_ps = p_array[labels == lab]
        c = cluster_ps.mean(axis=0)
        c = np.clip(c, 0, None)
        s = c.sum()
        if s > 0:
            c /= s
        else:
            c = np.ones(m_outcomes) / m_outcomes
        centers[i] = c

    accepted_contracts = np.array(accepted['Contract'].tolist())
    rejected_contracts = np.array(rejected['Contract'].tolist()) if not rejected.empty else np.empty((0, m_outcomes))

    eps = 1e-8
    costs = np.zeros(n_actions)

    # Initialize costs conservatively to satisfy IR and IC
    for a in range(n_actions):
        p_a = centers[a]

        accepted_idx = np.where(labels == unique_labels[a])[0]
        if accepted_idx.size > 0:
            w_acc = accepted_contracts[accepted_idx]
            max_acc = np.max(w_acc @ p_a)
        else:
            max_acc = 0.0

        if rejected_contracts.shape[0] > 0:
            rej_vals = rejected_contracts @ p_a
            max_rej = rej_vals.max()
        else:
            max_rej = -np.inf

        cost_a = max(max_acc, max_rej + eps)
        costs[a] = max(cost_a, 0.0)

    max_iters = 40
    margin = 1e-7

    for _ in range(max_iters):
        prev_costs = costs.copy()

        # Assign each accepted log to best action (highest agent utility)
        accept_utils = accepted_contracts @ centers.T - costs  # (n_accept, n_actions)
        accept_best_util = accept_utils.max(axis=1)
        accept_best_action = accept_utils.argmax(axis=1)

        # Check IR: all accepted logs must have utility >= margin
        if np.any(accept_best_util < margin):
            # Increase costs slightly to fix IR violations
            costs += margin
            costs = np.clip(costs, 0, None)

        # Check IC: all rejected logs must have utility < margin for all actions
        if rejected_contracts.shape[0] > 0:
            reject_utils = rejected_contracts @ centers.T - costs  # (n_reject, n_actions)
            reject_max_util = reject_utils.max(axis=1)
            if np.any(reject_max_util >= margin):
                # Increase costs more aggressively to fix IC violations
                costs += margin * 10
                costs = np.clip(costs, 0, None)

        # If costs stabilized, break early
        if np.allclose(costs, prev_costs, atol=margin):
            break

        # After cost update, reassign accepted logs to closest center by cosine distance to refine labels
        dist_to_centers = cosine_distances(p_array, centers)
        labels = dist_to_centers.argmin(axis=1)
        unique_labels = np.unique(labels)
        n_actions = len(unique_labels)

        # Recompute centers with refined labels
        new_centers = np.zeros((n_actions, m_outcomes))
        for i, lab in enumerate(unique_labels):
            cluster_ps = p_array[labels == lab]
            c = cluster_ps.mean(axis=0)
            c = np.clip(c, 0, None)
            s = c.sum()
            if s > 0:
                c /= s
            else:
                c = np.ones(m_outcomes) / m_outcomes
            new_centers[i] = c
        centers = new_centers

        # Resize costs array if number of actions changed, keep old costs if possible
        if len(costs) != n_actions:
            old_costs = costs.copy()
            costs = np.zeros(n_actions)
            for i, lab in enumerate(unique_labels):
                if lab < len(old_costs):
                    costs[i] = old_costs[lab]
                else:
                    costs[i] = 0.0

    # Final normalization and cost clipping
    centers = np.clip(centers, 0, None)
    centers /= centers.sum(axis=1, keepdims=True)
    costs = np.maximum(costs, 0.0)

    agent_setting = np.hstack([centers, costs[:, None]])
    return agent_setting
```
