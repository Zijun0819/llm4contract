```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import DBSCAN


def agent_solver_v2(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    """
    Infer an agent setting (actions as outcome distributions + cost) that explains historical logs.
    Uses clustering plus LP-based feasibility checks and cost adjustments to ensure IR and IC.

    Args:
        v: Principal's reward vector, shape (5,)
        content: DataFrame with columns ['Contract', 'Principal Utility', 'Agent Action'].

    Returns:
        agent_setting: n x 6 ndarray where each row is [p1, p2, p3, p4, p5, cost].
    """
    m_outcomes = v.shape[0]
    L = len(content)

    contracts = np.vstack(content['Contract'].to_numpy())  # shape (L, 5)
    utilities = content['Principal Utility'].to_numpy()    # shape (L,)
    agent_actions = content['Agent Action'].to_numpy()     # shape (L,)

    accepted_idx = np.where(agent_actions == 1)[0]
    rejected_idx = np.where(agent_actions == -1)[0]

    # Step 1: Extract contracts accepted by agent and their contracts/utilities
    accepted_contracts = contracts[accepted_idx]
    accepted_utils = utilities[accepted_idx]

    # Step 2: Estimate empirical outcome distributions p for accepted contracts:
    # For each accepted contract w and agent utility u >=0, solve LP:
    # maximize expected payment p @ w subject to p in simplex and expected cost = p @ w - u
    # Since cost unknown, approximate p by maximizing correlation with v.

    # We exploit that agent accepts only if expected payment >= cost (cost unknown).
    # Instead, we cluster accepted contracts to identify distinct agent actions.

    # Use DBSCAN clustering of accepted contracts to find adaptive #actions,
    # as it can discover arbitrary number of clusters based on density.
    clustering = DBSCAN(eps=1.5, min_samples=3).fit(accepted_contracts)
    labels = clustering.labels_
    unique_actions = set(labels)
    if -1 in unique_actions:
        unique_actions.remove(-1)  # -1 is noise

    if not unique_actions:
        # fallback: all accepted contracts form one action
        unique_actions = {0}
        labels = np.zeros(len(accepted_contracts), dtype=int)

    n_actions = len(unique_actions)
    action_ps = np.zeros((n_actions, m_outcomes))
    action_costs = np.zeros(n_actions)

    # Step 3: For each cluster (action), estimate outcome distribution p as convex combo from contracts
    # Solve:
    # minimize ||p v - mean principal utility|| subject to sum p=1, p>=0,
    # we use contract vectors in cluster as proxies for p*v, but we want p, so we invert:
    # Since contract = payment vector w, and p unknown, we approximate p by normalized v-weighted contract.

    # We'll estimate p_a for action a as average normalized contract weighted by v:
    # p_a proportional to contracts @ v (weights), normalize to sum 1.
    # This is heuristic: agent action p should explain contract payments aligned with v.

    # For each action cluster, aggregate contracts
    for i, a in enumerate(sorted(unique_actions)):
        cluster_idx = accepted_idx[labels == a]
        cluster_contracts = contracts[cluster_idx]

        # Weighted average contract vector:
        mean_w = cluster_contracts.mean(axis=0)  # shape (5,)

        # Estimate p_a by normalizing mean_w / v elementwise (avoid divide zero)
        with np.errstate(divide='ignore', invalid='ignore'):
            ratio = np.divide(mean_w, v, out=np.zeros_like(mean_w), where=v>1e-8)

        # Since p is a distribution, project ratio onto simplex (may not sum to 1)
        # Use linear projection onto simplex
        def proj_simplex(y):
            """Projection onto probability simplex"""
            y = np.asarray(y)
            if np.all(y >= 0) and abs(y.sum() - 1) < 1e-8:
                return y
            u = np.sort(y)[::-1]
            cssv = np.cumsum(u)
            rho = np.nonzero(u * np.arange(1, len(u) + 1) > (cssv - 1))[0][-1]
            theta = (cssv[rho] - 1) / (rho + 1)
            w = np.maximum(y - theta, 0)
            return w

        p_a = proj_simplex(ratio)
        action_ps[i] = p_a

        # Step 4: Estimate cost c_a of action a as minimal expected payment across cluster contracts
        exp_payments = cluster_contracts @ p_a  # expected payments under p_a
        # Agent utility = expected payment - cost >= 0 => cost <= min(exp_payment)
        c_a = np.min(exp_payments)
        action_costs[i] = max(c_a, 0.0)

    # Step 5: Enforce IR/IC constraints for entire data:
    # Agent accepts contract w_i iff max_a (p_a @ w_i - c_a) >= 0
    # Agent rejects iff this max < 0
    # If violation, adjust costs upward minimally to satisfy constraints

    # Form constraint matrix:
    # For each contract w_i:
    # u_i = max_a (p_a @ w_i - c_a)
    # accepted if u_i >= 0 else rejected

    # We'll adjust costs upwards to fix violations:

    # Compute utility matrix U: shape (L, n_actions)
    U = contracts @ action_ps.T  # shape (L, n_actions)
    # initial utilities minus costs:
    U_shifted = U - action_costs[np.newaxis, :]  # shape (L, n_actions)
    u_max = np.max(U_shifted, axis=1)  # shape (L,)

    # Check violations:
    # Accepted but u_max < 0: increase cost of best action to fix
    # Rejected but u_max >= 0: increase cost of best action for that contract

    costs = action_costs.copy()

    # Iterate to fix violations (up to 10 times)
    for _ in range(10):
        violated = False
        for i in range(L):
            w_i = contracts[i]
            accepted = (agent_actions[i] == 1)
            utilities_i = U[i] - costs  # shape (n_actions,)
            max_u = np.max(utilities_i)
            best_a = np.argmax(utilities_i)
            if accepted and max_u < 0:
                # increase cost to fix: cost_a <= p_a @ w_i
                costs[best_a] = min(costs[best_a], U[i, best_a]) if costs[best_a] > U[i, best_a] else costs[best_a]
                costs[best_a] = max(costs[best_a], U[i, best_a])
                violated = True
            elif not accepted and max_u >= 0:
                # Increase cost to push utility negative
                costs[best_a] = max(costs[best_a], U[i, best_a] + 1e-6)
                violated = True
        if not violated:
            break

    # Finally ensure costs nonnegative
    costs = np.maximum(costs, 0)

    # Compose agent setting matrix n x 6
    agent_setting = np.hstack([action_ps, costs[:, np.newaxis]])

    return agent_setting
```
