```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import AgglomerativeClustering


def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x [probabilities over outcomes + cost])
    that explains the historical interaction logs under IR and IC constraints.

    Approach:
    - Extract contracts and acceptance/rejection labels.
    - For accepted contracts, approximate agent outcome distributions by solving LPs enforcing IR.
    - Cluster these inferred distributions with agglomerative clustering (no fixed k).
    - For each cluster (action), estimate cost to satisfy IR (utility≥0) and IC (no profitable deviations).
    - Check rejection logs to enforce costs that prevent agent acceptance of rejected contracts.
    - Output matrix with rows as [prob_vector (sum=1), cost≥0].
    """

    # Extract arrays for convenience
    contracts = np.array([log['Contract'] for log in content])  # shape (L,5)
    actions = np.array([log['Agent Action'] for log in content])  # shape (L,)
    principal_utils = np.array([log['Principal Utility'] for log in content])  # shape (L,)

    n_logs, m_outcomes = contracts.shape

    # Step 1: For accepted contracts (agent_action=1), infer agent outcome distribution p by LP:
    # max_p w.p subject to p sum=1, p≥0, and agent utility p.w - c ≥ 0 (IR).
    # We don't know c yet, so approximate p s.t. p.w = agent utility + c ≥ 0
    # Since c unknown, we approximate p by maximizing agent utility under constraints:
    # Here, approximate p by maximizing p.w subject to sum p=1 and p≥0.
    # Use each contract's payment vector as weights.

    accepted_idx = np.where(actions == 1)[0]
    if len(accepted_idx) == 0:
        raise ValueError("No accepted contracts to infer from.")

    # For each accepted contract, solve LP:
    # Maximize p.v subject to sum p=1, p≥0, and p.w >= 0 (agent utility ≥0).
    # Here, agent utility unknown but must be ≥0, so just solve for p maximizing p.w with sum p=1.
    # This is trivial: p puts all mass on argmax_w.
    # But we want diversified p's, so solve LP to find p maximizing p.w and p.v simultaneously.
    # To get diverse p, minimize variance with regularization.

    inferred_ps = []
    for i in accepted_idx:
        w = contracts[i]

        # LP: maximize p.w s.t sum p=1, p≥0
        # We solve twice shifting objectives to get candidate ps, then pick one
        c_obj = -w  # minimize negative to maximize
        A_eq = [np.ones(m_outcomes)]
        b_eq = [1.0]
        bounds = [(0, 1)] * m_outcomes

        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p_max_w = res.x
        else:
            p_max_w = np.ones(m_outcomes) / m_outcomes

        # Add a smoothed version: p proportional to w shifted positive
        w_shift = w - w.min() + 1e-3
        p_smooth = w_shift / w_shift.sum()

        # Combine to diversify: average
        p_combined = (p_max_w + p_smooth) / 2
        p_combined /= p_combined.sum()
        inferred_ps.append(p_combined)

    inferred_ps = np.vstack(inferred_ps)

    # Step 2: Cluster inferred_ps adaptively via Agglomerative clustering with distance threshold
    # to discover the number n_actions of plausible actions
    if len(inferred_ps) < 2:
        # Only one accepted contract: single action
        p_actions = inferred_ps
    else:
        clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0.15, linkage='average')
        labels = clustering.fit_predict(inferred_ps)
        n_actions = labels.max() + 1
        p_actions = np.zeros((n_actions, m_outcomes))
        for a in range(n_actions):
            cluster_members = inferred_ps[labels == a]
            mean_p = cluster_members.mean(axis=0)
            mean_p = np.clip(mean_p, 1e-8, None)
            mean_p /= mean_p.sum()
            p_actions[a] = mean_p

    # Step 3: Estimate costs c for each action to satisfy IR and IC:

    # IR: agent utility p.w - c ≥ 0 for accepted contracts assigned to that action
    # IC: agent prefers assigned action over others on all contracts

    # Assign each accepted contract to nearest action by L1 distance on p:
    assigned_actions = np.full(n_logs, -1)
    # For accepted logs:
    for i in accepted_idx:
        p_i = inferred_ps[accepted_idx == i][0] if len(accepted_idx)==1 else inferred_ps[np.where(accepted_idx == i)[0][0]]
        # But inferred_ps aligns with accepted_idx order, so compute distances to p_actions
        distances = np.linalg.norm(p_actions - inferred_ps[np.where(accepted_idx == i)[0][0]], ord=1, axis=1)
        assigned_actions[i] = distances.argmin()

    # For rejected logs, no assignment needed but used for IC constraints

    # Build LP to solve costs c ≥ 0:
    # Variables: c in R^{n_actions}
    # Constraints:

    # For each accepted contract i:
    # p_{a_i} . w_i - c_{a_i} ≥ 0      (IR)

    # For each accepted contract i and action a ≠ a_i:
    # p_{a_i} . w_i - c_{a_i} ≥ p_a . w_i - c_a   (IC)
    # Rearranged:
    # (c_a - c_{a_i}) ≥ (p_a - p_{a_i}) . w_i

    # For each rejected contract j:
    # For all a:
    # p_a . w_j - c_a < 0  => c_a > p_a . w_j
    # We enforce c_a ≥ max_j (p_a . w_j) + ε, with ε=1e-4

    from scipy.optimize import linprog

    n_var = n_actions
    c_obj = np.zeros(n_var)

    A_ub = []
    b_ub = []

    # IR constraints
    for i in accepted_idx:
        a_i = assigned_actions[i]
        w_i = contracts[i]
        lhs = np.zeros(n_var)
        lhs[a_i] = -1  # -c_{a_i}
        rhs = -p_actions[a_i] @ w_i  # - p_{a_i}.w_i
        A_ub.append(lhs)
        b_ub.append(rhs)

    # IC constraints
    for i in accepted_idx:
        a_i = assigned_actions[i]
        w_i = contracts[i]
        for a in range(n_actions):
            if a == a_i:
                continue
            lhs = np.zeros(n_var)
            lhs[a] = 1     # c_a
            lhs[a_i] = -1  # -c_{a_i}
            rhs = (p_actions[a] - p_actions[a_i]) @ w_i
            A_ub.append(lhs)
            b_ub.append(rhs)

    # Rejection constraints: c_a ≥ max_j p_a.w_j + ε for rejected j
    rejected_idx = np.where(actions == -1)[0]
    epsilon = 1e-5
    for a in range(n_actions):
        if len(rejected_idx) == 0:
            continue
        vals = [p_actions[a] @ contracts[j] for j in rejected_idx]
        rhs = max(vals) + epsilon
        lhs = np.zeros(n_var)
        lhs[a] = -1  # -c_a ≤ -rhs  => c_a ≥ rhs
        A_ub.append(lhs)
        b_ub.append(-rhs)

    # Bounds: c_a ≥ 0
    bounds = [(0, None)] * n_var

    A_ub = np.vstack(A_ub) if A_ub else None
    b_ub = np.array(b_ub) if b_ub else None

    lp_res = linprog(c=c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')

    if not lp_res.success:
        # If infeasible, fallback: costs zero and clip negative utilities
        costs = np.zeros(n_var)
    else:
        costs = lp_res.x

    # Final sanity: ensure costs ≥0
    costs = np.clip(costs, 0, None)

    # Format output: each row = [p_action (sum=1), cost]
    agent_setting = np.hstack([p_actions, costs[:, np.newaxis]])

    return agent_setting
```
