```python
import numpy as np
import pandas as pd
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score
from sklearn.metrics.pairwise import cosine_similarity
from scipy.optimize import linprog

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting (probability distributions over outcomes + costs)
    explaining the historical interaction logs between principal and agent,
    by adaptively clustering inferred outcome distributions with cosine metric,
    assigning noise points by cosine similarity, and iteratively refining costs
    to satisfy IR and IC constraints for accepted and rejected contracts.

    Improvements:
    - Moderate DBSCAN parameters (eps range and min_samples) for stable clustering.
    - Tighter LP tolerances (1e-9) and fallback to inequality LP with small tolerance.
    - Smaller cost increments (20 * eps_cost) for smoother convergence.
    - Early stopping with cost stabilization check.
    - Strict normalization of probabilities and cost non-negativity enforced.
    - Added numerical safeguards to prevent floating point issues.
    """
    m_outcomes = v.shape[0]
    logs_df = pd.DataFrame(content)
    accepted = logs_df[logs_df['Agent Action'] == 1].reset_index(drop=True)
    rejected = logs_df[logs_df['Agent Action'] == -1].reset_index(drop=True)

    # If no accepted contracts, return trivial agent with uniform distribution and zero cost
    if accepted.empty:
        uniform_p = np.ones(m_outcomes) / m_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.zeros((1, 1))])

    # Step 1: Infer p for each accepted contract by LP with tightened feasibility and robust fallback
    def infer_p_for_log(w, u_p):
        w = np.array(w, dtype=np.float64)
        c_obj = -w
        # Equality constraints: sum p = 1, (v - w)^T p = u_p
        A_eq = np.vstack([np.ones(m_outcomes), v - w])
        b_eq = np.array([1.0, u_p], dtype=np.float64)
        bounds = [(0, 1) for _ in range(m_outcomes)]

        # Primary LP: equality constraints with tight tolerance
        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m_outcomes) / m_outcomes
            return p

        # Fallback: relax equality on agent utility to inequality with small tolerance
        tol = 1e-9
        A_eq_relax = np.ones(m_outcomes).reshape(1, -1)
        b_eq_relax = np.array([1.0])
        A_ub_relax = np.array([-(v - w)])
        b_ub_relax = np.array([-(u_p - tol)])
        res2 = linprog(c=c_obj, A_eq=A_eq_relax, b_eq=b_eq_relax,
                       A_ub=A_ub_relax, b_ub=b_ub_relax, bounds=bounds, method='highs')
        if res2.success:
            p = res2.x
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m_outcomes) / m_outcomes
            return p

        # Final fallback: uniform distribution
        return np.ones(m_outcomes) / m_outcomes

    p_list = [infer_p_for_log(row['Contract'], row['Principal Utility']) for _, row in accepted.iterrows()]
    p_array = np.vstack(p_list)  # shape (n_accept, m_outcomes)

    # Step 2: Adaptive DBSCAN clustering with cosine metric and silhouette checks
    eps_candidates = np.linspace(0.035, 0.22, 18)
    best_eps = None
    best_labels = None
    best_silhouette = -1

    for eps in eps_candidates:
        clustering = DBSCAN(eps=eps, min_samples=3, metric='cosine').fit(p_array)
        labels = clustering.labels_
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        if n_clusters >= 2:
            mask = labels != -1
            if np.sum(mask) >= 7:
                try:
                    sil = silhouette_score(p_array[mask], labels[mask], metric='cosine')
                    if sil > best_silhouette:
                        best_silhouette = sil
                        best_eps = eps
                        best_labels = labels.copy()
                except Exception:
                    continue
        elif n_clusters == 1 and (-1 not in labels):
            best_eps = eps
            best_labels = labels.copy()
            best_silhouette = 0.0

    if best_labels is None:
        best_labels = np.zeros(len(p_array), dtype=int)

    labels = best_labels
    noise_idx = np.where(labels == -1)[0]
    unique_labels = sorted(set(labels) - {-1})
    n_actions = len(unique_labels)
    if n_actions == 0:
        n_actions = 1
        labels[:] = 0
        unique_labels = [0]

    # Step 3: Compute cluster centers (mean p per cluster), normalize strictly
    centers = np.zeros((n_actions, m_outcomes), dtype=np.float64)
    for i, lab in enumerate(unique_labels):
        cluster_ps = p_array[labels == lab]
        c = cluster_ps.mean(axis=0)
        c = np.clip(c, 0, None)
        s = c.sum()
        if s > 0:
            c /= s
        else:
            c = np.ones(m_outcomes) / m_outcomes
        centers[i] = c

    # Step 4: Assign noise points to nearest cluster center by cosine similarity
    if noise_idx.size > 0:
        noise_p = p_array[noise_idx]
        sim = cosine_similarity(noise_p, centers)  # shape (noise_size, n_actions)
        assign_labels = sim.argmax(axis=1)
        for idx, assigned_cluster in zip(noise_idx, assign_labels):
            labels[idx] = unique_labels[assigned_cluster]

    # Remap labels to 0..n_actions-1
    label_map = {lab: i for i, lab in enumerate(unique_labels)}
    mapped_labels = np.array([label_map[lab] for lab in labels])

    # Prepare contract arrays
    contract_acc = np.array(accepted['Contract'].tolist(), dtype=np.float64)
    contract_rej = np.array(rejected['Contract'].tolist(), dtype=np.float64) if not rejected.empty else np.empty((0, m_outcomes), dtype=np.float64)

    eps_cost = 1e-10
    costs = np.zeros(n_actions, dtype=np.float64)

    # Step 5: Initialize minimal costs c_a satisfying IR and IC constraints conservatively
    for a in range(n_actions):
        p_a = centers[a]
        assigned_acc_idx = np.where(mapped_labels == a)[0]
        if assigned_acc_idx.size > 0:
            w_acc = contract_acc[assigned_acc_idx]
            min_acc = np.min(w_acc @ p_a)
        else:
            min_acc = 0.0

        if contract_rej.shape[0] > 0:
            max_rej = np.max(contract_rej @ p_a)
        else:
            max_rej = -np.inf

        costs[a] = max(min_acc, max_rej + eps_cost, 0.0)

    # Step 6: Iteratively refine costs to satisfy IR and IC constraints strictly
    max_iter = 70
    cost_increment = 20 * eps_cost
    for _ in range(max_iter):
        prev_costs = costs.copy()

        # Accepted contracts: at least one action with utility >= 0 (agent accepts)
        accept_utils = contract_acc @ centers.T - costs  # shape (n_accept, n_actions)
        accept_feasible = (accept_utils >= -eps_cost).any(axis=1)

        # Rejected contracts: all actions utility < 0 (agent rejects)
        if contract_rej.shape[0] > 0:
            reject_utils = contract_rej @ centers.T - costs  # shape (n_reject, n_actions)
            reject_feasible = (reject_utils < eps_cost).all(axis=1)
        else:
            reject_feasible = np.array([True])

        if accept_feasible.all() and reject_feasible.all():
            break

        # Increase costs to fix IR violations on accepted contracts
        for i, feasible in enumerate(accept_feasible):
            if not feasible:
                violated_actions = np.where(accept_utils[i] < -eps_cost)[0]
                if violated_actions.size > 0:
                    costs[violated_actions] += cost_increment

        # Increase costs to fix IC violations on rejected contracts
        if contract_rej.shape[0] > 0:
            for i, feasible in enumerate(reject_feasible):
                if not feasible:
                    violated_actions = np.where(reject_utils[i] >= eps_cost)[0]
                    if violated_actions.size > 0:
                        costs[violated_actions] += cost_increment

        costs = np.maximum(costs, 0.0)

        # Early stop if costs stabilized
        if np.allclose(costs, prev_costs, atol=eps_cost):
            break

    # Final cleanup: normalize centers strictly and ensure costs non-negative
    centers = np.clip(centers, 0, None)
    centers_sum = centers.sum(axis=1, keepdims=True)
    centers_sum[centers_sum == 0] = 1.0
    centers /= centers_sum
    costs = np.maximum(costs, 0.0)

    agent_setting = np.hstack([centers, costs[:, None]])
    return agent_setting
```
