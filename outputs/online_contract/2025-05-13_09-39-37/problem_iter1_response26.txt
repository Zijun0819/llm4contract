```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import AgglomerativeClustering


def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting (actions as outcome distributions + cost)
    consistent with historical logs of contract offers, principal utility,
    and agent accept/reject decisions.

    Args:
        v: Principal's value vector over 5 outcomes (shape (5,))
        content: List of dicts with keys:
            - 'Contract': list of 5 payments (wages)
            - 'Principal Utility': float (0 if rejected)
            - 'Agent Action': 1 (accept) or -1 (reject)

    Returns:
        agent_setting: np.ndarray of shape (n_actions, 6), where each row is
            [p0, p1, p2, p3, p4, cost]. The first five sum to 1 (prob distribution),
            the last is the agent cost (non-negative).
    """
    m = len(v)
    logs_df = pd.DataFrame(content)
    n_logs = len(content)

    # Separate accepted and rejected logs
    accepted = logs_df[logs_df['Agent Action'] == 1]
    rejected = logs_df[logs_df['Agent Action'] == -1]

    # Step 1: From accepted logs, infer empirical outcome distributions
    # We assume the agent picks an action (distribution p) that satisfies:
    #  p @ wage - cost >= 0 (IR)
    # Also principal utility = p @ (v - wage)
    # We want to find p and cost per action that explain logs.

    # To infer p from each accepted log, solve:
    # max_p p @ wage, s.t. p sums to 1, p >=0, and p @ wage >= 0
    # Instead of max, here we seek any feasible p that explains the acceptance.

    # We'll collect candidate p's by solving:
    # Given wage w, find p s.t p @ wage >= 0, sum p=1, p>=0.
    # We choose p that maximizes variance over outcomes to avoid trivial corner.

    candidate_ps = []
    for idx, row in accepted.iterrows():
        w = np.array(row['Contract'])
        # Solve LP: find p s.t sum p=1, p>=0, p @ w >= 0
        # If feasible, choose p maximizing variance (encouraging non-degenerate p)
        c = -((np.arange(m) - m/2)**2)  # dummy objective favoring spread
        A_ub = np.array([-w])
        b_ub = np.array([0])
        A_eq = np.ones((1, m))
        b_eq = np.array([1])
        bounds = [(0, 1)] * m
        res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            candidate_ps.append(res.x)
        else:
            # fallback: use normalized w if all nonnegative else uniform
            p_try = np.maximum(w, 0)
            if p_try.sum() > 0:
                candidate_ps.append(p_try / p_try.sum())
            else:
                candidate_ps.append(np.ones(m) / m)

    if len(candidate_ps) == 0:
        raise ValueError("No accepted logs to infer agent strategies.")

    candidate_ps = np.array(candidate_ps)

    # Step 2: Cluster candidate p to find distinct actions
    # Use hierarchical clustering with a distance threshold to adaptively find n
    clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0.1, linkage='ward')
    cluster_labels = clustering.fit_predict(candidate_ps)
    n_actions = cluster_labels.max() + 1

    # Compute cluster centers as average of p in each cluster
    p_centers = np.zeros((n_actions, m))
    for k in range(n_actions):
        members = candidate_ps[cluster_labels == k]
        p_centers[k] = members.mean(axis=0)
        # Normalize in case of numeric issues
        p_centers[k] = np.clip(p_centers[k], 0, None)
        total = p_centers[k].sum()
        if total > 0:
            p_centers[k] /= total
        else:
            p_centers[k] = np.ones(m) / m

    # Step 3: Infer cost for each action ensuring IR for accepted logs assigned to that cluster
    # Assign accepted logs to nearest cluster by Euclidean distance between p and cluster center
    assigns = np.zeros(len(accepted), dtype=int)
    for i, p in enumerate(candidate_ps):
        dists = np.linalg.norm(p_centers - p, axis=1)
        assigns[i] = dists.argmin()

    costs = np.zeros(n_actions)
    # For each action, cost = min_p (p @ wage) over accepted logs in cluster
    # Because IR: p @ wage - cost >= 0 => cost <= p @ wage
    # So cost = min over logs of p_center @ wage
    for a in range(n_actions):
        idxs = np.where(assigns == a)[0]
        if len(idxs) == 0:
            costs[a] = 0.0
            continue
        wages = np.array([accepted.iloc[i]['Contract'] for i in idxs])
        utilities = wages @ p_centers[a]
        costs[a] = max(0.0, utilities.min())

    # Step 4: Enforce rejection consistency
    # For each rejected contract w, agent utility under every action < 0:
    # p_action @ wage - cost < 0, i.e. p_action @ wage < cost
    # If violated, increase cost minimally or add new action

    if len(rejected) > 0:
        rej_wages = np.vstack(rejected['Contract'].values)
        # Check violations: U = p @ w - cost
        # Shape: (n_actions, n_rejected)
        utils = p_centers @ rej_wages.T - costs[:, None]

        # If any utils >=0, violation occurs; we'll fix by increasing cost minimally
        violations = utils >= 0
        for a in range(n_actions):
            viol_inds = np.where(violations[a])[0]
            if len(viol_inds) > 0:
                # Increase cost to max violation + epsilon
                incr = (p_centers[a] @ rej_wages[viol_inds].T).max() + 1e-6
                costs[a] = max(costs[a], incr)

    # Step 5: Final normalization & formatting
    for a in range(n_actions):
        p_centers[a] = np.clip(p_centers[a], 0, None)
        s = p_centers[a].sum()
        if s > 0:
            p_centers[a] /= s
        else:
            p_centers[a] = np.ones(m) / m
        costs[a] = max(costs[a], 0.0)

    agent_setting = np.hstack([p_centers, costs[:, None]])
    return agent_setting
```
