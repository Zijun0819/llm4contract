```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import AgglomerativeClustering

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (rows: agent actions; cols: 5 outcome probs + cost)
    consistent with historical contracts, principal utilities, and agent actions.

    Args:
        v: principal's reward vector of length m=5.
        content: list of dicts with keys 'Contract' (list of 5 floats), 
                 'Principal Utility' (float), and 'Agent Action' (1 or -1).

    Returns:
        agent_setting: np.ndarray of shape (n_actions, 6) where each row is
                       [p_1,...,p_5, cost], p_i >=0, sum p_i=1, cost >=0.
    """
    m = v.size
    logs_df = pd.DataFrame(content)
    L = len(content)

    contracts = np.array(logs_df['Contract'].tolist())  # (L, m)
    principal_utils = np.array(logs_df['Principal Utility'].tolist())  # (L,)
    agent_actions = np.array(logs_df['Agent Action'].tolist())  # (L,)

    # Basic dimension check
    assert contracts.shape[1] == m, "Contract dimension mismatch with v"

    accept_idx = np.where(agent_actions == 1)[0]
    reject_idx = np.where(agent_actions == -1)[0]

    # If no accepted contracts, return trivial single action: uniform distribution, zero cost
    if len(accept_idx) == 0:
        p_uniform = np.ones(m) / m
        return np.hstack([p_uniform, 0.0]).reshape(1, m + 1)

    # --- Step 1: Estimate outcome distributions p_i for accepted contracts ---
    # For each accepted contract w_i with principal utility u_i,
    # solve LP for p_i:
    #   sum p_i = 1, p_i >= 0,
    #   p_i @ (v - w_i) = u_i (principal utility = p_i@(v-w_i))
    # This constrains p_i to explain principal utility exactly.
    # Agent utility unknown, so cost unknown here.

    def infer_p_for_accepted(w, u):
        # Solve feasibility LP: find p s.t sum p=1, p>=0, p@(v-w)=u
        # Objective zero (feasibility)
        c_obj = np.zeros(m)
        A_eq = np.vstack([np.ones(m), v - w])
        b_eq = np.array([1.0, u])
        bounds = [(0, 1) for _ in range(m)]
        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            # Numerical corrections
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m) / m
            return p
        else:
            # fallback: minimize squared error to constraints (soft feasibility)
            from scipy.optimize import minimize

            def obj(p):
                return np.sum((p - np.clip(p, 0, 1)) ** 2)  # penalize negative probs

            cons = (
                {'type': 'eq', 'fun': lambda p: np.sum(p) - 1},
                {'type': 'eq', 'fun': lambda p: p @ (v - w) - u},
                {'type': 'ineq', 'fun': lambda p: p}
            )
            init = np.ones(m) / m
            sol = minimize(obj, init, constraints=cons, bounds=[(0,1)]*m, method='SLSQP', options={'ftol':1e-9})
            if sol.success:
                p = sol.x
                p = np.clip(p, 0, None)
                s = p.sum()
                if s > 0:
                    p /= s
                else:
                    p = np.ones(m) / m
                return p
            else:
                # As last resort uniform
                return np.ones(m) / m

    p_candidates = np.array([infer_p_for_accepted(contracts[i], principal_utils[i]) for i in accept_idx])

    # --- Step 2: Cluster accepted p_candidates to identify distinct agent actions ---
    # Use AgglomerativeClustering with distance threshold (L2) to adaptively select number of actions.
    clusterer = AgglomerativeClustering(n_clusters=None, distance_threshold=0.12, linkage='average')
    cluster_labels = clusterer.fit_predict(p_candidates)
    n_actions = cluster_labels.max() + 1

    p_actions = np.zeros((n_actions, m))
    for a in range(n_actions):
        members = p_candidates[cluster_labels == a]
        mean_p = members.mean(axis=0)
        mean_p = np.clip(mean_p, 0, None)
        s = mean_p.sum()
        p_actions[a] = mean_p / s if s > 0 else np.ones(m) / m

    # --- Step 3: Assign all logs (accepted+rejected) to closest p_action by L1 distance ---
    # For accepted logs: assign by closest cluster label already known
    assigned_actions = np.full(L, -1, dtype=int)
    assigned_actions[accept_idx] = cluster_labels

    # For rejected logs: assign by closest p_action to contract's implied p
    # We approximate p_rej by projection onto simplex maximizing p@w (agent would accept if utility>=0)
    # But since rejected, agent utility < 0 for all actions.
    # We'll assign rejected logs to closest p_action by distance to their w (contract) vector normalized.

    # To assign rejected logs robustly, define a proxy p_rej:
    # maximize p @ w subject to p in simplex => p_rej = one-hot at max w index
    # But better to assign rejected logs by minimal L1 distance between p_actions and normalized w

    # Normalize rejected contracts to simplex for distance computation
    w_rej = contracts[reject_idx]
    w_rej_sum = w_rej.sum(axis=1, keepdims=True)
    w_rej_norm = np.divide(w_rej, w_rej_sum, out=np.ones_like(w_rej)/m, where=w_rej_sum>0)

    for idx, w_norm in zip(reject_idx, w_rej_norm):
        dists = np.linalg.norm(p_actions - w_norm, ord=1, axis=1)
        assigned_actions[idx] = dists.argmin()

    # --- Step 4: Infer cost intervals per action from IR and IC constraints ---

    # IR constraints from accepted logs assigned to action a:
    # For each accepted contract i assigned to a:
    # p_a @ w_i - c_a >= 0 => c_a <= p_a @ w_i
    # So c_a <= min_i p_a @ w_i over accepted logs assigned to a

    c_upper_bounds = np.full(n_actions, np.inf)
    for a in range(n_actions):
        idxs = np.where((assigned_actions == a) & (agent_actions == 1))[0]
        if len(idxs) > 0:
            vals = [p_actions[a] @ contracts[i] for i in idxs]
            c_upper_bounds[a] = min(vals)
        else:
            # No accepted logs assigned: no upper bound, set zero for safety
            c_upper_bounds[a] = 0.0

    # IC constraints from rejected logs assigned to action a:
    # For each rejected contract i assigned to a:
    # p_a @ w_i - c_a < 0 => c_a > p_a @ w_i
    # So c_a > max_i p_a @ w_i over rejected logs assigned to a

    c_lower_bounds = np.zeros(n_actions)
    for a in range(n_actions):
        idxs = np.where((assigned_actions == a) & (agent_actions == -1))[0]
        if len(idxs) > 0:
            vals = [p_actions[a] @ contracts[i] for i in idxs]
            c_lower_bounds[a] = max(vals)
        else:
            c_lower_bounds[a] = 0.0

    # Add small epsilon to lower bounds for strict inequality
    eps = 1e-8
    c_lower_bounds += eps

    # --- Step 5: Resolve cost conflicts and pick final costs ---
    costs = np.zeros(n_actions)
    for a in range(n_actions):
        lb = c_lower_bounds[a]
        ub = c_upper_bounds[a]
        if lb < ub:
            # feasible interval, pick midpoint for stability
            costs[a] = (lb + ub) / 2
        else:
            # no feasible cost satisfying both IR and IC exactly
            # prioritize IC (rejection consistency) by setting cost slightly above lb
            costs[a] = lb + 1e-5

        # ensure non-negative cost
        if costs[a] < 0:
            costs[a] = 0.0

    # --- Step 6: Adjust costs downward if they violate IR for accepted logs ---
    for a in range(n_actions):
        idxs = np.where((assigned_actions == a) & (agent_actions == 1))[0]
        if len(idxs) > 0:
            min_paw = min(p_actions[a] @ contracts[i] for i in idxs)
            if costs[a] > min_paw:
                costs[a] = min_paw

    # --- Step 7: Final normalization and safety ---
    p_actions = np.clip(p_actions, 0, None)
    sums = p_actions.sum(axis=1, keepdims=True)
    sums[sums == 0] = 1.0
    p_actions /= sums

    costs = np.clip(costs, 0, None)

    agent_setting = np.hstack([p_actions, costs.reshape(-1, 1)])

    return agent_setting
```
