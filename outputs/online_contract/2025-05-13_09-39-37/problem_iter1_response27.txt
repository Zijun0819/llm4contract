```python
import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from scipy.optimize import linprog

def agent_solver(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting (probability distributions over outcomes + cost)
    consistent with historical interaction logs: contracts, principal utilities, and agent actions.

    Parameters:
    - v: (5,) numpy array, principal's reward vector for 5 outcomes.
    - content: list of dicts, each with keys:
        'Contract' (list of 5 floats),
        'Principal Utility' (float),
        'Agent Action' (1 for accept, -1 for reject).

    Returns:
    - np.ndarray of shape (n_actions, 6),
      where columns 0-4 are probabilities over outcomes,
      and column 5 is nonnegative cost of that action.
    """

    m = len(v)  # number of outcomes (5)
    logs_df = pd.DataFrame(content)
    n_logs = len(logs_df)

    # Step 1: Extract accepted and rejected logs separately
    accepted = logs_df[logs_df['Agent Action'] == 1]
    rejected = logs_df[logs_df['Agent Action'] == -1]

    # Sanity checks
    if accepted.empty:
        raise ValueError("No accepted contracts in logs; cannot infer agent setting.")

    # Step 2: Infer candidate outcome distributions from accepted contracts
    # For each accepted contract, agent's expected utility ≥ 0:
    # E_p[w] - cost ≥ 0 => cost ≤ E_p[w]
    # Principal utility = v^T p - w^T p (agent cost) = v^T p - cost
    # => cost = v^T p - principal_utility

    # For each accepted contract i:
    # variables: p_i (distribution over outcomes)
    # constraints: sum p_i = 1, p_i >= 0
    # cost_i = v^T p_i - principal_utility_i >= 0

    # We don't know p_i directly, but contract w_i is known,
    # We want to find p_i s.t agent accepts: E_p[w_i] - cost_i ≥ 0
    # and principal utility = v^T p_i - cost_i

    # Let's formulate a feasibility LP per accepted log to find p_i and cost_i:
    # Variables: p_i in R^5, cost_i in R
    # Constraints:
    # sum p_i = 1
    # p_i >= 0
    # cost_i ≥ 0
    # E_p[w_i] - cost_i ≥ 0  => p_i · w_i - cost_i ≥ 0
    # cost_i = p_i · v - principal_utility_i  => cost_i = p_i·v - u_i

    # Substitute cost_i into inequality:
    # p_i·w_i - (p_i·v - u_i) ≥ 0 => p_i·(w_i - v) + u_i ≥ 0

    # So the constraints:
    # sum p_i = 1
    # p_i >= 0
    # p_i·(w_i - v) ≥ - u_i

    # We'll solve for p_i in:
    # minimize 0 subject to above constraints (feasibility problem)

    def infer_p_for_log(w, u):
        # LP: find p s.t sum p=1, p≥0, p·(w - v) ≥ -u
        # Use linprog to find feasible p (no objective)
        c = np.zeros(m)  # zero objective
        A_eq = [np.ones(m)]
        b_eq = [1.0]
        A_ub = [-(w - v)]  # -(w - v)·p ≤ u
        b_ub = [u]
        bounds = [(0,1)] * m
        res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            return res.x
        else:
            return None

    candidate_p = []
    u_vals = []  # principal utilities for accepted contracts
    for idx, row in accepted.iterrows():
        w = np.array(row['Contract'])
        u = row['Principal Utility']
        p_candidate = infer_p_for_log(w, u)
        if p_candidate is not None:
            candidate_p.append(p_candidate)
            u_vals.append(u)
    if len(candidate_p) == 0:
        raise ValueError("Failed to infer any valid agent outcome distributions from accepted logs.")

    candidate_p = np.vstack(candidate_p)
    u_vals = np.array(u_vals)

    # Step 3: Cluster candidate_p into a reasonable number of agent actions
    # Use silhouette score or elbow heuristic to select n_clusters adaptively
    # Max clusters capped to 10 or less for tractability
    max_clusters = min(10, len(candidate_p))
    if max_clusters == 1:
        n_clusters = 1
    else:
        from sklearn.metrics import silhouette_score
        best_score = -1
        best_k = 1
        for k in range(2, max_clusters+1):
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10).fit(candidate_p)
            score = silhouette_score(candidate_p, kmeans.labels_)
            if score > best_score:
                best_score = score
                best_k = k
        n_clusters = best_k

    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20).fit(candidate_p)
    centers_p = kmeans.cluster_centers_

    # Step 4: Estimate costs per cluster center
    # cost_a = min over accepted logs assigned to cluster a of (p_a·v - principal_utility_i)
    costs = np.zeros(n_clusters)
    for a in range(n_clusters):
        assigned_idx = np.where(kmeans.labels_ == a)[0]
        cluster_p = centers_p[a]
        if len(assigned_idx) == 0:
            # no accepted logs assigned, set cost low initially
            costs[a] = 0.0
        else:
            # costs must satisfy cost_a ≤ p_a·v - u_i for all assigned i (agent utility ≥ 0)
            cost_candidates = cluster_p @ v - u_vals[assigned_idx]
            # cost must be non-negative:
            costs[a] = max(0., np.min(cost_candidates))

    # Step 5: Enforce IR and IC constraints on all logs:
    # IR: for accepted logs i assigned to action a_i:
    # p_a_i·w_i - cost_a_i ≥ 0  (agent utility ≥ 0)
    # IC: for rejected logs j: for all a, p_a·w_j - cost_a < 0 (agent rejects all contracts)
    # We'll enforce rejection constraints by increasing costs if needed.

    # Assign each accepted log to closest cluster center (by expected wage):
    def assign_action(w):
        # Assign to action a maximizing agent utility p_a·w - cost_a
        utilities = centers_p @ w - costs
        return np.argmax(utilities)

    accepted_idx = accepted.index.values
    assigned_actions = np.array([assign_action(np.array(accepted.loc[i, 'Contract'])) for i in accepted_idx])
    # Correct costs if any accepted log violates IR (agent utility < 0)
    for idxi, a_i in zip(accepted_idx, assigned_actions):
        p_a = centers_p[a_i]
        w_i = np.array(accepted.loc[idxi, 'Contract'])
        agent_util = p_a @ w_i - costs[a_i]
        if agent_util < 0:
            # decrease cost to agent_util + costs[a_i], but keep cost ≥ 0
            costs[a_i] = max(0., costs[a_i] + agent_util)

    # For rejected logs, enforce agent utility < 0 for all actions
    rejected_idx = rejected.index.values
    for idxr in rejected_idx:
        w_r = np.array(rejected.loc[idxr, 'Contract'])
        for a in range(n_clusters):
            util = centers_p[a] @ w_r - costs[a]
            if util >= 0:
                # Increase cost to just above util to enforce rejection
                costs[a] = util + 1e-5  # tiny margin

    # Step 6: Normalize probability centers (fix any minor numerical deviation)
    centers_p = np.clip(centers_p, 0, 1)
    centers_p = centers_p / centers_p.sum(axis=1, keepdims=True)

    # Step 7: Compose final agent setting matrix (n_actions x 6)
    agent_setting = np.hstack([centers_p, costs.reshape(-1,1)])

    return agent_setting
```
