```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import DBSCAN

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x [probabilities over 5 outcomes + cost]) that explains the
    historical interactions between principal and agent under IR (Individual Rationality) and IC (Incentive Compatibility).

    Args:
        v: np.ndarray, shape (5,) - principal's reward vector for 5 outcomes.
        content: list of dicts, each dict has keys:
            - 'Contract': list or np.ndarray, 5-dimensional payment vector for 5 outcomes
            - 'Principal Utility': float, principal's utility under contract (0 if agent rejects)
            - 'Agent Action': int, 1 if accepted (agent utility â‰¥ 0), -1 if rejected (agent utility < 0)

    Returns:
        np.ndarray of shape (n_actions, 6): [p_1,...,p_5,cost] with:
            - p_i: probability of ith outcome for that action (sum to 1)
            - cost: non-negative agent cost of action
    """
    # Prepare data arrays
    contracts = np.array([log['Contract'] for log in content], dtype=np.float64)
    principal_utils = np.array([log['Principal Utility'] for log in content], dtype=np.float64)
    agent_actions = np.array([log['Agent Action'] for log in content], dtype=int)

    n_logs, m_outcomes = contracts.shape
    assert m_outcomes == v.size == 5

    # Separate accepted and rejected logs
    accepted_idx = np.where(agent_actions == 1)[0]
    rejected_idx = np.where(agent_actions == -1)[0]

    # If no accepted logs, return trivial agent setting: uniform distribution, zero cost
    if accepted_idx.size == 0:
        uniform_p = np.ones(m_outcomes) / m_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])

    # Step 1: For each accepted log, infer a plausible agent outcome distribution p
    candidate_p = []
    uniform_vec = np.ones(m_outcomes) / m_outcomes
    c_obj = np.abs(uniform_vec)  # objective to minimize distance from uniform p

    for idx in accepted_idx:
        w = contracts[idx]
        pu = principal_utils[idx]

        # Constraints:
        # sum p_i = 1
        # (v - w).p = pu
        # p.w >= 0  (agent utility >= 0)
        # p_i >= 0

        A_eq = np.vstack([np.ones(m_outcomes), v - w])
        b_eq = np.array([1.0, pu])

        A_ub = -w.reshape(1, -1)
        b_ub = np.array([0.0])

        bounds = [(0, 1) for _ in range(m_outcomes)]

        res = linprog(c=c_obj, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq,
                      bounds=bounds, method='highs')

        if res.success:
            p_sol = res.x
            p_sol[p_sol < 0] = 0
            s = p_sol.sum()
            if s > 0:
                p_sol /= s
            else:
                p_sol = uniform_vec.copy()
            candidate_p.append(p_sol)
        else:
            # Relax agent utility constraint (remove p.w >= 0)
            res_alt = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq,
                              bounds=bounds, method='highs')
            if res_alt.success:
                p_sol_alt = res_alt.x
                p_sol_alt[p_sol_alt < 0] = 0
                s = p_sol_alt.sum()
                if s > 0:
                    p_sol_alt /= s
                else:
                    p_sol_alt = uniform_vec.copy()
                candidate_p.append(p_sol_alt)
            else:
                # fallback uniform distribution
                candidate_p.append(uniform_vec.copy())

    candidate_p = np.array(candidate_p)

    # Step 2: Cluster candidate_p with DBSCAN to find distinct actions adaptively
    clustering = DBSCAN(eps=0.05, min_samples=2).fit(candidate_p)
    labels = clustering.labels_

    # Handle all noise case (-1)
    if np.all(labels == -1):
        labels[:] = 0

    unique_labels = np.unique(labels)
    unique_labels = unique_labels[unique_labels != -1]  # remove noise label if any

    # If no clusters after removing noise, fallback to single cluster
    if len(unique_labels) == 0:
        unique_labels = np.array([0])
        labels[:] = 0

    # Assign noise points (-1) to nearest cluster center
    noise_idx = np.where(labels == -1)[0]
    if noise_idx.size > 0 and len(unique_labels) > 0:
        centers = np.array([candidate_p[labels == ul].mean(axis=0) for ul in unique_labels])
        for ni in noise_idx:
            dists = np.linalg.norm(centers - candidate_p[ni], axis=1)
            assign_label = unique_labels[np.argmin(dists)]
            labels[ni] = assign_label

    n_actions = len(unique_labels)

    # Compute cluster centers (mean p of each cluster)
    p_cluster = np.zeros((n_actions, m_outcomes), dtype=np.float64)
    for i, ul in enumerate(unique_labels):
        cluster_members = candidate_p[labels == ul]
        mean_p = cluster_members.mean(axis=0)
        mean_p[mean_p < 0] = 0
        s = mean_p.sum()
        if s > 0:
            mean_p /= s
        else:
            mean_p = uniform_vec.copy()
        p_cluster[i] = mean_p

    # Step 3: Infer agent cost for each action by IR and IC constraints

    # IR: For accepted logs assigned to cluster a:
    # cost_a <= min_{assigned accepted logs} p_a.w
    # IC: For rejected logs:
    # cost_a > max_{rejected logs} p_a.w

    cost_candidates = np.zeros(n_actions, dtype=np.float64)

    # Map accepted logs to clusters
    assigned_accepted_clusters = labels

    for i, ul in enumerate(unique_labels):
        idx_assigned = np.where(assigned_accepted_clusters == ul)[0]
        if idx_assigned.size == 0:
            cost_candidates[i] = 0.0
            continue
        w_assigned = contracts[accepted_idx[idx_assigned]]  # shape (num_assigned, 5)
        # agent utility = p_a . w_i
        agent_utils = np.einsum('j,ij->i', p_cluster[i], w_assigned)
        cost_candidates[i] = agent_utils.min()

    # For rejected logs: cost_a > max_{rejected logs} p_a.w
    if rejected_idx.size > 0:
        w_rejected = contracts[rejected_idx]  # shape (num_rejected, 5)
        for i in range(n_actions):
            agent_utils_rej = np.einsum('j,ij->i', p_cluster[i], w_rejected)
            max_rej = agent_utils_rej.max()
            # cost should be strictly greater than max agent utility on rejected logs
            if max_rej + 1e-6 > cost_candidates[i]:
                cost_candidates[i] = max_rej + 1e-6

    # Ensure nonnegative costs
    cost_candidates = np.maximum(cost_candidates, 0.0)

    # Step 4: Compose final agent setting matrix
    agent_setting = np.hstack([p_cluster, cost_candidates.reshape(-1, 1)])

    return agent_setting
```
