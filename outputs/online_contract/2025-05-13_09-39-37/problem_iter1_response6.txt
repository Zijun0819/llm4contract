```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import AgglomerativeClustering


def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix from principal's reward vector `v` and
    historical interaction logs `content`.

    Returns:
        agent_setting: n x 6 numpy array, where each row is [p_1,...,p_5, cost].
    """
    m_outcomes = v.shape[0]
    L = len(content)

    # Extract contracts, utilities, and agent actions arrays for convenience
    contracts = np.array([log['Contract'] for log in content])  # shape (L,5)
    utilities = np.array([log['Principal Utility'] for log in content])  # shape (L,)
    actions = np.array([log['Agent Action'] for log in content])  # shape (L,)

    # --- Step 1: Candidate action inference from accepted contracts ---
    # Given accepted logs, infer agent outcome distributions and costs.
    # For each accepted contract w, agent accepts => agent utility >= 0:
    # p @ w - c >= 0 => c <= p @ w
    # Principal utility u = v @ p - w @ p = p @ (v - w)
    # So p satisfies sum(p)=1, p>=0, and principal utility = p @ (v - w)
    # We infer p that explains the observed principal utility for accepted contracts.

    def infer_p_given_w_u(w, u):
        # Solve for p: maximize p @ (v - w), subject to sum p=1, p>=0
        # Constrain p @ (v - w) == u to get candidate p.
        c_obj = np.zeros(m_outcomes)
        A_eq = [np.ones(m_outcomes), v - w]
        b_eq = [1.0, u]
        bounds = [(0, 1)] * m_outcomes
        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            return res.x
        else:
            # fallback: solve lp minimizing L2 to match utility if direct fails
            from scipy.optimize import minimize

            def obj(p):
                return np.linalg.norm(p)  # dummy, we only want feasibility

            cons = (
                {'type': 'eq', 'fun': lambda p: np.sum(p) - 1},
                {'type': 'eq', 'fun': lambda p: p @ (v - w) - u},
                {'type': 'ineq', 'fun': lambda p: p}
            )
            init = np.ones(m_outcomes) / m_outcomes
            sol = minimize(obj, init, constraints=cons, bounds=[(0,1)]*m_outcomes, method='SLSQP')
            if sol.success:
                return sol.x
            return None

    candidate_ps = []
    candidate_ws = []
    candidate_us = []
    for i in range(L):
        if actions[i] == 1:
            p_i = infer_p_given_w_u(contracts[i], utilities[i])
            if p_i is not None and np.all(p_i >= -1e-8):
                p_i = np.clip(p_i, 0, 1)
                p_i /= p_i.sum()
                candidate_ps.append(p_i)
                candidate_ws.append(contracts[i])
                candidate_us.append(utilities[i])

    if len(candidate_ps) == 0:
        # no accepted logs, fallback: one uniform action with zero cost
        uniform_p = np.ones(m_outcomes) / m_outcomes
        return np.hstack([uniform_p, np.array([0.0])])

    candidate_ps = np.array(candidate_ps)  # shape (N_acc, 5)
    candidate_ws = np.array(candidate_ws)
    candidate_us = np.array(candidate_us)

    # --- Step 2: Cluster candidate_ps into actions ---
    # Use hierarchical clustering to adaptively select #actions via threshold
    max_actions = min(10, len(candidate_ps))
    clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0.15, linkage='ward')
    labels = clustering.fit_predict(candidate_ps)
    n_actions = labels.max() + 1

    actions_p = np.zeros((n_actions, m_outcomes))
    for k in range(n_actions):
        cluster_ps = candidate_ps[labels == k]
        if len(cluster_ps) > 0:
            center = cluster_ps.mean(axis=0)
            center = np.clip(center, 0, 1)
            center /= center.sum()
            actions_p[k] = center
        else:
            actions_p[k] = np.ones(m_outcomes) / m_outcomes

    # --- Step 3: Infer costs consistent with IR and rejection logs ---
    # IR: agent utility >= 0 for accepted contracts of that action
    # So c_a <= p_a @ w for any contract w accepted under that action
    # Take minimal p_a @ w over accepted contracts assigned to that cluster as cost upper bound
    costs_upper = np.full(n_actions, np.inf)
    for a in range(n_actions):
        idxs = np.where(labels == a)[0]
        if len(idxs) > 0:
            w_accept = candidate_ws[idxs]
            costs_upper[a] = np.min(w_accept @ actions_p[a])
        else:
            costs_upper[a] = 0.0

    # For rejected contracts, agent utility < 0 for all actions:
    # p_a @ w - c_a < 0 => c_a > p_a @ w
    # So cost must be strictly above maximal p_a @ w over rejected contracts
    rej_idx = np.where(actions == -1)[0]
    if len(rej_idx) > 0:
        w_rej = contracts[rej_idx]
        p_dot_w_rej = actions_p @ w_rej.T  # shape (n_actions, n_rej)
        costs_lower = p_dot_w_rej.max(axis=1) + 1e-8  # add small epsilon for strictness
    else:
        costs_lower = np.zeros(n_actions)

    # Final cost: choose costs in [costs_lower, costs_upper]
    # If intervals don't overlap, relax by max(costs_lower,0)
    costs = np.maximum(costs_lower, 0)
    for a in range(n_actions):
        if costs[a] > costs_upper[a]:
            # conflict => set cost = costs[a] as lower bound, accept minimal violation
            costs[a] = costs[a]
        else:
            # feasible interval, pick midpoint
            costs[a] = (costs_lower[a] + costs_upper[a]) / 2

    # --- Step 4: Normalize action outcome distributions and finalize ---
    for a in range(n_actions):
        actions_p[a] = np.clip(actions_p[a], 0, None)
        s = actions_p[a].sum()
        if s > 0:
            actions_p[a] /= s
        else:
            actions_p[a] = np.ones(m_outcomes) / m_outcomes

    agent_setting = np.hstack([actions_p, costs[:, None]])
    return agent_setting
```
