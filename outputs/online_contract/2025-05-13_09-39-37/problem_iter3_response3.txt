```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting (prob distributions over outcomes + costs)
    explaining the historical interaction logs between principal and agent.

    Args:
        v (np.ndarray): Principal's reward vector for 5 outcomes, shape (5,)
        content (list[dict]): Each dict contains
            - 'Contract': 5-dim payment vector,
            - 'Principal Utility': principal utility under contract,
            - 'Agent Action': 1 for accept, -1 for reject.

    Returns:
        np.ndarray: n x 6 matrix: first 5 cols are outcome probabilities (sum=1),
                    last column is agent cost (â‰¥0).
    """
    m_outcomes = v.shape[0]
    logs_df = pd.DataFrame(content)
    accepted = logs_df[logs_df['Agent Action'] == 1].reset_index(drop=True)
    rejected = logs_df[logs_df['Agent Action'] == -1].reset_index(drop=True)

    # If no accepted contracts, return trivial agent with uniform dist and zero cost
    if accepted.empty:
        return np.hstack([np.ones((1, m_outcomes)) / m_outcomes, np.zeros((1, 1))])

    # Step 1: Infer p for each accepted contract by LP
    def infer_p_for_log(w, u_p):
        # Solve LP:
        # variables: p (length m_outcomes)
        # constraints:
        #   sum p = 1
        #   p @ (v - w) = u_p
        # bounds: p_i in [0,1]
        # objective: maximize p @ w (agent expected payment)
        c_obj = -np.array(w)
        A_eq = [np.ones(m_outcomes), v - np.array(w)]
        b_eq = [1.0, u_p]
        bounds = [(0, 1) for _ in range(m_outcomes)]
        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            # Numerical fix: clip and re-normalize
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m_outcomes) / m_outcomes
            return p
        else:
            # fallback: uniform distribution
            return np.ones(m_outcomes) / m_outcomes

    p_list = []
    for _, row in accepted.iterrows():
        p_vec = infer_p_for_log(row['Contract'], row['Principal Utility'])
        p_list.append(p_vec)
    p_array = np.vstack(p_list)

    # Step 2: Cluster p_array adaptively using DBSCAN (density based)
    # Incorporate rejected logs by adding their contracts as "negative" points
    # to help separate clusters that explain acceptance vs rejection.

    # Prepare points for clustering: accepted p_array plus rejected contracts projected
    # into probability simplex? We cannot directly cluster rejected contracts as p.
    # Instead, cluster only accepted p_array, but use rejected contracts later for IC.

    # Use DBSCAN with multiple eps candidates and select best silhouette score
    best_eps = None
    best_labels = None
    best_silhouette = -1
    eps_candidates = np.linspace(0.05, 0.3, 6)
    for eps in eps_candidates:
        clustering = DBSCAN(eps=eps, min_samples=2, metric='l1').fit(p_array)
        labels = clustering.labels_
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        # Silhouette score only valid if n_clusters >=2
        if n_clusters >= 2:
            try:
                sil = silhouette_score(p_array[labels != -1], labels[labels != -1], metric='l1')
                if sil > best_silhouette:
                    best_silhouette = sil
                    best_eps = eps
                    best_labels = labels
            except:
                pass
        elif n_clusters == 1:
            # Single cluster, silhouette undefined, accept if no noise
            if -1 not in labels:
                best_eps = eps
                best_labels = labels
                best_silhouette = 0.0

    # If no good clustering found, assign all to one cluster
    if best_labels is None:
        best_labels = np.zeros(len(p_array), dtype=int)

    # Replace noise points (-1) by nearest cluster center later
    labels = best_labels
    noise_idx = np.where(labels == -1)[0]
    assigned_idx = np.where(labels != -1)[0]
    n_actions = len(set(labels)) - (1 if -1 in labels else 0)
    if n_actions == 0:
        n_actions = 1
        labels[:] = 0

    # Step 3: Compute cluster centers (mean p per cluster)
    centers = np.zeros((n_actions, m_outcomes))
    for a in range(n_actions):
        centers[a] = p_array[labels == a].mean(axis=0)
    # Normalize centers
    centers = np.clip(centers, 0, None)
    centers /= centers.sum(axis=1, keepdims=True)

    # Assign noise points to nearest cluster center by L1 distance
    if noise_idx.size > 0:
        for idx in noise_idx:
            p_noise = p_array[idx]
            dists = np.sum(np.abs(centers - p_noise), axis=1)
            nearest = np.argmin(dists)
            labels[idx] = nearest

    # Step 4: Infer minimal agent costs c_a satisfying IR and IC constraints
    eps_cost = 1e-7
    contract_acc = np.array(accepted['Contract'].tolist())
    contract_rej = np.array(rejected['Contract'].tolist()) if not rejected.empty else np.empty((0, m_outcomes))

    costs = np.zeros(n_actions)
    # For each action, find accepted contracts assigned to it
    for a in range(n_actions):
        p_a = centers[a]
        accepted_idx = np.where(labels == a)[0]
        if accepted_idx.size > 0:
            w_acc = contract_acc[accepted_idx]
            max_acc = np.max(w_acc @ p_a)
        else:
            max_acc = 0.0

        if contract_rej.shape[0] > 0:
            rej_vals = contract_rej @ p_a
            max_rej = rej_vals.max()
        else:
            max_rej = -np.inf

        # Cost must satisfy IR: c_a <= p_a @ w for accepted contracts (agent utility >=0)
        # and IC: c_a > p_a @ w for rejected contracts (agent utility <0)
        # So cost_a >= max(max_acc, max_rej + eps_cost)
        cost_a = max(max_acc, max_rej + eps_cost)
        costs[a] = max(cost_a, 0.0)

    # Step 5: Validate and refine costs iteratively to ensure feasibility
    # Accepted logs must have some action a with p_a @ w - c_a >= 0 (accept)
    # Rejected logs must have all actions a with p_a @ w - c_a < 0 (reject)
    max_iter = 20
    for _ in range(max_iter):
        # Check accept feasibility
        accept_utils = contract_acc @ centers.T - costs  # shape (n_accept, n_actions)
        accept_best_util = accept_utils.max(axis=1)
        accept_feasible = accept_best_util >= -eps_cost

        # Check reject feasibility
        if contract_rej.shape[0] > 0:
            reject_utils = contract_rej @ centers.T - costs  # shape (n_reject, n_actions)
            reject_max_util = reject_utils.max(axis=1)
            reject_feasible = reject_max_util < eps_cost
        else:
            reject_feasible = np.array([True])

        if accept_feasible.all() and reject_feasible.all():
            break

        # Increase costs slightly for actions that violate IR or IC
        # Actions that cause accept infeasibility: increase costs to lower agent utility margins
        # Actions that cause reject infeasibility: increase costs to lower agent utility margins
        # We do a conservative increase on all costs by small step
        costs += eps_cost * 5
        costs = np.maximum(costs, 0.0)

    # Final normalization and cleanup
    centers = np.clip(centers, 0, None)
    centers /= centers.sum(axis=1, keepdims=True)
    costs = np.maximum(costs, 0.0)

    agent_setting = np.hstack([centers, costs[:, None]])
    return agent_setting
```
