```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics.pairwise import cosine_distances

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting (probability distributions over outcomes + costs)
    explaining the historical interaction logs between principal and agent,
    by hierarchical clustering with cosine similarity for stable action grouping,
    and iteratively refining costs enforcing strict IR and IC margins.

    Args:
        v (np.ndarray): Principal's reward vector for 5 outcomes, shape (5,)
        content (list[dict]): Each dict contains:
            - 'Contract': 5-dim payment vector,
            - 'Principal Utility': principal utility under contract,
            - 'Agent Action': 1 for accept, -1 for reject.

    Returns:
        np.ndarray: n x 6 matrix: first 5 cols are outcome probabilities (sum=1),
                    last column is agent cost (≥0).
    """
    m_outcomes = v.shape[0]
    logs_df = pd.DataFrame(content)
    accepted = logs_df[logs_df['Agent Action'] == 1].reset_index(drop=True)
    rejected = logs_df[logs_df['Agent Action'] == -1].reset_index(drop=True)

    # If no accepted contracts, return trivial agent with uniform dist and zero cost
    if accepted.empty:
        return np.hstack([np.ones((1, m_outcomes)) / m_outcomes, np.zeros((1, 1))])

    # Step 1: Infer p for each accepted contract by LP
    # p: distribution over outcomes for agent action that accepted contract corresponds to
    def infer_p_for_log(w, u_p):
        # Solve LP:
        # variables: p (length m_outcomes)
        # constraints:
        #   sum p = 1
        #   p @ (v - w) = u_p
        # bounds: p_i in [0,1]
        # objective: maximize p @ w (agent expected payment)
        c_obj = -np.array(w)
        A_eq = [np.ones(m_outcomes), v - np.array(w)]
        b_eq = [1.0, u_p]
        bounds = [(0, 1) for _ in range(m_outcomes)]
        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            # Numerical fix: clip and re-normalize
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m_outcomes) / m_outcomes
            return p
        else:
            # fallback: uniform distribution
            return np.ones(m_outcomes) / m_outcomes

    p_list = [infer_p_for_log(row['Contract'], row['Principal Utility']) for _, row in accepted.iterrows()]
    p_array = np.vstack(p_list)  # shape (n_accept, m_outcomes)

    # Step 2: Hierarchical clustering with cosine distance and adaptive thresholding
    # Use linkage cutoff to find stable clusters with minimum cluster size 2
    from sklearn.metrics import pairwise_distances

    # Compute cosine distance matrix
    dist_mat = cosine_distances(p_array)
    # Agglomerative clustering with distance threshold, no preset n_clusters
    # Try thresholds from 0.1 to 0.5 in steps of 0.05, pick best silhouette with min cluster size >=2
    from sklearn.metrics import silhouette_score

    best_labels = None
    best_silhouette = -1
    best_n_clusters = 0
    best_threshold = None

    thresholds = np.arange(0.1, 0.51, 0.05)
    for thresh in thresholds:
        clustering = AgglomerativeClustering(
            n_clusters=None,
            affinity='precomputed',
            linkage='average',
            distance_threshold=thresh
        )
        labels = clustering.fit_predict(dist_mat)
        unique_labels = set(labels)
        # Check min cluster size >= 2
        cluster_sizes = [np.sum(labels == lab) for lab in unique_labels]
        if min(cluster_sizes) < 2:
            continue
        n_clusters = len(unique_labels)
        if n_clusters < 1:
            continue
        # Silhouette score requires at least 2 clusters
        if n_clusters >= 2:
            try:
                sil = silhouette_score(p_array, labels, metric='cosine')
            except Exception:
                sil = -1
            if sil > best_silhouette:
                best_silhouette = sil
                best_labels = labels
                best_n_clusters = n_clusters
                best_threshold = thresh
        else:
            # single cluster, silhouette undefined, accept if no better
            if best_labels is None:
                best_labels = labels
                best_n_clusters = 1
                best_threshold = thresh
                best_silhouette = 0

    # If no suitable clustering found, fallback all in one cluster
    if best_labels is None:
        best_labels = np.zeros(len(p_array), dtype=int)
        best_n_clusters = 1

    labels = best_labels
    unique_labels = sorted(set(labels))
    n_actions = len(unique_labels)

    # Step 3: Compute cluster centers (mean p per cluster)
    centers = np.zeros((n_actions, m_outcomes))
    for i, lab in enumerate(unique_labels):
        cluster_ps = p_array[labels == lab]
        mean_p = cluster_ps.mean(axis=0)
        mean_p = np.clip(mean_p, 0, None)
        s = mean_p.sum()
        if s > 0:
            mean_p /= s
        else:
            mean_p = np.ones(m_outcomes) / m_outcomes
        centers[i] = mean_p

    # Step 4: Assign accepted logs to clusters (actions) by minimal cosine distance
    # (already assigned by clustering)

    # Step 5: Infer minimal costs c_a satisfying IR and IC constraints with strict margins
    eps_cost = 1e-7  # small positive margin to enforce strict inequalities

    contract_acc = np.array(accepted['Contract'].tolist())
    contract_rej = np.array(rejected['Contract'].tolist()) if not rejected.empty else np.empty((0, m_outcomes))

    costs = np.zeros(n_actions)

    # For each action, compute:
    # IR: c_a <= min_{accepted contracts assigned to a} p_a @ w - margin (≥0)
    # IC: c_a > max_{rejected contracts} p_a @ w + margin
    # If no accepted contracts assigned, use 0 for min_acc (agent cost ≥0)
    # If no rejected contracts, max_rej = -inf

    for a in range(n_actions):
        p_a = centers[a]
        assigned_acc_idx = np.where(labels == unique_labels[a])[0]
        if assigned_acc_idx.size > 0:
            w_acc = contract_acc[assigned_acc_idx]
            # Agent utility p_a @ w - c_a ≥ 0 => c_a ≤ p_a @ w
            min_acc = np.min(w_acc @ p_a) - eps_cost
        else:
            min_acc = 0.0  # no accepted logs assigned, cost lower bound 0

        if contract_rej.shape[0] > 0:
            rej_vals = contract_rej @ p_a
            max_rej = np.max(rej_vals) + eps_cost
        else:
            max_rej = -np.inf

        # cost must satisfy c_a ≤ min_acc and c_a > max_rej
        # So cost_a in (max_rej, min_acc], cost_a ≥ 0
        lower_bound = max(max_rej, 0.0)
        upper_bound = max(min_acc, lower_bound)  # ensure upper ≥ lower

        if upper_bound < lower_bound:
            # Infeasible, relax by setting cost = midpoint
            cost_a = (lower_bound + upper_bound) / 2
        else:
            # Choose cost slightly above lower_bound to satisfy strict IC
            cost_a = lower_bound + eps_cost

            # Ensure cost_a ≤ upper_bound (IR)
            if cost_a > upper_bound:
                cost_a = upper_bound

        costs[a] = cost_a

    # Step 6: Iteratively refine costs to ensure all IR and IC constraints hold strictly
    max_iter = 30
    for _ in range(max_iter):
        # Accepted logs: must have some action a with p_a @ w - c_a ≥ margin
        accept_utils = contract_acc @ centers.T - costs  # shape (n_accept, n_actions)
        accept_feasible = (accept_utils >= eps_cost).any(axis=1)

        # Rejected logs: must have all actions a with p_a @ w - c_a < -margin
        if contract_rej.shape[0] > 0:
            reject_utils = contract_rej @ centers.T - costs  # shape (n_reject, n_actions)
            reject_feasible = (reject_utils < -eps_cost).all(axis=1)
        else:
            reject_feasible = np.array([True])

        if accept_feasible.all() and reject_feasible.all():
            break

        # Increase costs slightly for actions violating IC or IR
        # For accepted logs failing IR: find minimal gap and reduce costs if possible
        # For rejected logs failing IC: increase costs

        # For accepted logs failing IR
        fail_accept_idx = np.where(~accept_feasible)[0]
        if fail_accept_idx.size > 0:
            # For each failed accepted log, find action with largest p_a @ w - c_a
            for idx in fail_accept_idx:
                utilities = accept_utils[idx]
                max_util_idx = np.argmax(utilities)
                # Decrease cost for that action if possible
                costs[max_util_idx] = max(costs[max_util_idx] - eps_cost * 5, 0.0)

        # For rejected logs failing IC
        if contract_rej.shape[0] > 0:
            fail_reject_idx = np.where(~reject_feasible)[0]
            if fail_reject_idx.size > 0:
                for idx in fail_reject_idx:
                    utilities = reject_utils[idx]
                    # For actions with utility ≥ -eps_cost, increase cost
                    violating = np.where(utilities >= -eps_cost)[0]
                    for a_idx in violating:
                        costs[a_idx] += eps_cost * 5

        # Ensure costs non-negative
        costs = np.maximum(costs, 0.0)

    # Step 7: Final normalization and clipping for numerical stability
    centers = np.clip(centers, 0, None)
    centers /= centers.sum(axis=1, keepdims=True)
    costs = np.maximum(costs, 0.0)

    agent_setting = np.hstack([centers, costs[:, None]])
    return agent_setting
```
