```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score
from scipy.spatial.distance import cdist

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting (prob distributions over outcomes + costs)
    explaining the historical interaction logs between principal and agent,
    incorporating both accepted and rejected logs adaptively.

    Args:
        v (np.ndarray): Principal's reward vector for 5 outcomes, shape (5,)
        content (list[dict]): Each dict contains
            - 'Contract': 5-dim payment vector,
            - 'Principal Utility': principal utility under contract,
            - 'Agent Action': 1 for accept, -1 for reject.

    Returns:
        np.ndarray: n x 6 matrix: first 5 cols are outcome probabilities (sum=1),
                    last column is agent cost (â‰¥0).
    """
    m_outcomes = v.shape[0]
    logs_df = pd.DataFrame(content)
    accepted = logs_df[logs_df['Agent Action'] == 1].reset_index(drop=True)
    rejected = logs_df[logs_df['Agent Action'] == -1].reset_index(drop=True)

    # If no accepted contracts, trivial agent: uniform dist and zero cost
    if accepted.empty:
        return np.hstack([np.ones((1, m_outcomes)) / m_outcomes, np.zeros((1, 1))])

    # Infer agent outcome distributions p for accepted contracts via LP
    def infer_p_for_log(w, u_p):
        # Solve LP:
        # variables: p (length m_outcomes)
        # constraints:
        #   sum p = 1
        #   p @ (v - w) = u_p (principal utility observed)
        # bounds: p_i in [0,1]
        # objective: maximize p @ w (agent expected payment)
        c_obj = -np.array(w)
        A_eq = [np.ones(m_outcomes), v - w]
        b_eq = [1.0, u_p]
        bounds = [(0, 1) for _ in range(m_outcomes)]
        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m_outcomes) / m_outcomes
            return p
        else:
            return np.ones(m_outcomes) / m_outcomes

    p_list = []
    for _, row in accepted.iterrows():
        p_vec = infer_p_for_log(row['Contract'], row['Principal Utility'])
        p_list.append(p_vec)
    p_array = np.vstack(p_list)  # shape (n_accept, m_outcomes)

    # Infer proxy agent outcome distributions p for rejected contracts
    def infer_p_for_reject_log(w):
        # variables: p (length m_outcomes)
        # constraints:
        #   sum p =1
        #   p @ (v - w) <= -delta (agent utility < 0)
        # bounds: p_i in [0,1]
        # objective: maximize p @ w
        delta = 1e-6
        c_obj = -np.array(w)
        A_eq = [np.ones(m_outcomes)]
        b_eq = [1.0]
        A_ub = [-(v - w)]  # -p@(v-w) >= delta => p@(v-w) <= -delta
        b_ub = [-delta]
        bounds = [(0, 1) for _ in range(m_outcomes)]
        res = linprog(c=c_obj, A_eq=A_eq, b_eq=b_eq, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m_outcomes) / m_outcomes
            return p
        else:
            return np.ones(m_outcomes) / m_outcomes

    p_rej_list = []
    for _, row in rejected.iterrows():
        p_vec = infer_p_for_reject_log(row['Contract'])
        p_rej_list.append(p_vec)
    if p_rej_list:
        p_rej_array = np.vstack(p_rej_list)
        combined_p = np.vstack([p_array, p_rej_array])
    else:
        combined_p = p_array.copy()

    # Tune DBSCAN eps by silhouette score over candidate epsilons
    best_eps = None
    best_score = -1
    eps_candidates = np.linspace(0.05, 0.3, 6)
    for eps in eps_candidates:
        clustering = DBSCAN(eps=eps, min_samples=2, metric='euclidean').fit(combined_p)
        labels = clustering.labels_
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        if n_clusters < 2:
            continue  # silhouette not defined or meaningless
        try:
            score = silhouette_score(combined_p[labels != -1], labels[labels != -1])
            if score > best_score:
                best_score = score
                best_eps = eps
        except Exception:
            continue
    if best_eps is None:
        best_eps = 0.15

    clustering = DBSCAN(eps=best_eps, min_samples=2, metric='euclidean').fit(combined_p)
    labels = clustering.labels_

    # Filter out noise points (-1)
    valid_idx = labels != -1
    filtered_p = combined_p[valid_idx]
    filtered_labels = labels[valid_idx]

    # Handle no clusters found (all noise)
    if len(set(filtered_labels)) == 0:
        centers = np.mean(p_array, axis=0, keepdims=True)
        centers = np.clip(centers, 0, None)
        s = centers.sum(axis=1, keepdims=True)
        centers /= np.where(s > 0, s, 1)
        n_actions = 1
    else:
        unique_labels = sorted(set(filtered_labels))
        n_actions = len(unique_labels)
        centers = np.zeros((n_actions, m_outcomes), dtype=np.float64)
        for i, lab in enumerate(unique_labels):
            cluster_ps = filtered_p[filtered_labels == lab]
            c = cluster_ps.mean(axis=0)
            c = np.clip(c, 0, None)
            s = c.sum()
            if s > 0:
                c /= s
            else:
                c = np.ones(m_outcomes) / m_outcomes
            centers[i] = c

    # Assign accepted logs to closest cluster center by L2 distance
    dist_acc = cdist(p_array, centers, metric='euclidean')
    assigned_clusters = dist_acc.argmin(axis=1)

    accepted_contracts = np.array(accepted['Contract'].tolist())
    rejected_contracts = np.array(rejected['Contract'].tolist()) if not rejected.empty else np.empty((0, m_outcomes))

    eps_cost = 1e-7
    costs = np.zeros(n_actions, dtype=np.float64)

    # Compute initial costs satisfying IR and IC constraints
    for a in range(n_actions):
        p_a = centers[a]

        # Accepted contracts assigned to cluster a
        acc_idx = np.where(assigned_clusters == a)[0]
        if acc_idx.size > 0:
            acc_ws = accepted_contracts[acc_idx]
            acc_vals = acc_ws @ p_a
            max_acc = acc_vals.max()
        else:
            max_acc = 0.0

        # Rejected contracts
        if rejected_contracts.shape[0] > 0:
            rej_vals = rejected_contracts @ p_a
            max_rej = rej_vals.max()
        else:
            max_rej = -np.inf

        cost_a = max(max_acc, max_rej + eps_cost)
        costs[a] = max(cost_a, 0.0)

    # Iteratively adjust costs to enforce IR and IC
    max_iters = 10
    for _ in range(max_iters):
        # Accepted logs: some action must have utility >=0
        accept_utils = accepted_contracts @ centers.T - costs  # shape (n_accept, n_actions)
        max_accept_util = accept_utils.max(axis=1)
        if np.any(max_accept_util < -eps_cost):
            violation_idx = np.where(max_accept_util < -eps_cost)[0]
            for idx in violation_idx:
                a = assigned_clusters[idx]
                costs[a] = max(costs[a] - eps_cost * 10, 0.0)
            continue

        # Rejected logs: all actions must have utility <0
        if rejected_contracts.shape[0] > 0:
            reject_utils = rejected_contracts @ centers.T - costs  # shape (n_reject, n_actions)
            max_reject_util = reject_utils.max(axis=1)
            if np.any(max_reject_util >= -eps_cost):
                costs += eps_cost * 10
                continue
        break

    # Normalize centers and ensure costs nonnegative
    centers = np.clip(centers, 0, None)
    s = centers.sum(axis=1, keepdims=True)
    s[s == 0] = 1
    centers /= s
    costs = np.maximum(costs, 0.0)

    agent_setting = np.hstack([centers, costs[:, None]])
    return agent_setting
```
