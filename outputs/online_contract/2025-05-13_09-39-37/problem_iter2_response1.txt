```python
import numpy as np
from scipy.optimize import linprog
from sklearn.cluster import KMeans

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix consistent with historical logs of contracts,
    principal utilities, and agent actions.
    
    Parameters:
    - v: np.ndarray of shape (5,), principal's value vector for outcomes.
    - content: list of dicts with keys 'Contract' (list of 5 floats),
               'Principal Utility' (float), and 'Agent Action' (1 or -1).
               
    Returns:
    - agent_setting: np.ndarray of shape (n_actions, 6),
                     each row: [p_1,...,p_5, cost],
                     where p_i form a probability distribution and cost >= 0.
    """
    m = len(v)
    L = len(content)
    contracts = np.array([log['Contract'] for log in content])  # (L, m)
    utilities = np.array([log['Principal Utility'] for log in content])  # (L,)
    agent_actions = np.array([log['Agent Action'] for log in content])  # (L,)

    accepted_idx = np.where(agent_actions == 1)[0]
    rejected_idx = np.where(agent_actions == -1)[0]

    # If no accepted contracts, return trivial single action with uniform p and zero cost
    if accepted_idx.size == 0:
        p_trivial = np.ones(m) / m
        c_trivial = 0.0
        return np.hstack([p_trivial, c_trivial])[np.newaxis, :]

    accepted_contracts = contracts[accepted_idx]  # (A, m)
    accepted_utils = utilities[accepted_idx]     # (A,)

    # Step 1: Estimate agent outcome distributions p for accepted contracts via LP
    def estimate_p(w: np.ndarray, u: float):
        # maximize w^T p s.t. sum p=1, p^T v = u, p >=0
        c_obj = -w  # maximize w^T p <=> minimize -w^T p
        A_eq = np.vstack([np.ones(m), v])
        b_eq = np.array([1.0, u])
        bounds = [(0, 1)] * m
        res = linprog(c_obj, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success and np.all(res.x >= -1e-8):
            p = res.x
            p[p < 0] = 0.0  # numerical cleanup
            p /= p.sum()  # re-normalize to simplex
            return p
        return None

    estimated_ps = []
    valid_indices = []
    for i, idx in enumerate(accepted_idx):
        p_est = estimate_p(accepted_contracts[i], accepted_utils[i])
        if p_est is not None:
            estimated_ps.append(p_est)
            valid_indices.append(idx)
    if len(estimated_ps) == 0:
        # fallback uniform + zero cost
        p_trivial = np.ones(m)/m
        c_trivial = 0.0
        return np.hstack([p_trivial, c_trivial])[np.newaxis, :]

    estimated_ps = np.array(estimated_ps)  # (A_valid, m)

    # Step 2: Adaptive clustering of estimated_ps by elbow heuristic on SSE
    max_clusters = min(10, len(estimated_ps))
    if max_clusters == 1:
        n_actions = 1
        centers = estimated_ps.mean(axis=0, keepdims=True)
    else:
        sse_list = []
        for k in range(1, max_clusters + 1):
            km = KMeans(n_clusters=k, n_init=10, random_state=42).fit(estimated_ps)
            sse_list.append(km.inertia_)
        diffs = np.diff(sse_list)
        second_diffs = np.diff(diffs)
        elbow_k = max_clusters
        for i, val in enumerate(second_diffs):
            if val > -1e-3:
                elbow_k = i + 2
                break
        n_actions = elbow_k
        kmeans = KMeans(n_clusters=n_actions, n_init=15, random_state=42).fit(estimated_ps)
        centers = kmeans.cluster_centers_

    # Step 3: Project centers to simplex (probability distributions)
    def proj_simplex(y):
        u = np.sort(y)[::-1]
        cssv = np.cumsum(u)
        rho = np.where(u + (1 - cssv) / (np.arange(len(u)) + 1) > 0)[0]
        if len(rho) == 0:
            # fallback uniform
            return np.ones(len(y)) / len(y)
        rho = rho[-1]
        theta = (cssv[rho] - 1) / (rho + 1)
        return np.maximum(y - theta, 0)
    centers = np.array([proj_simplex(c) for c in centers])

    # Step 4: Assign accepted logs to closest cluster center by L1 norm
    dist_matrix = np.abs(estimated_ps[:, None, :] - centers[None, :, :]).sum(axis=2)  # (A_valid, n_actions)
    assigns = dist_matrix.argmin(axis=1)

    # Step 5: Infer costs c for each action via LP bounds from IR and rejection constraints
    payoffs = centers @ contracts.T  # (n_actions, L)

    INF = 1e9
    epsilon = 1e-5

    # Upper bounds from IR: c[a] <= min_{i assigned to a} p_a^T w_i
    c_upper_bounds = np.full(n_actions, INF)
    for a in range(n_actions):
        assigned_idxs = [valid_indices[i] for i, aa in enumerate(assigns) if aa == a]
        if len(assigned_idxs) > 0:
            pays = payoffs[a, assigned_idxs]
            c_upper_bounds[a] = pays.min()
        else:
            c_upper_bounds[a] = INF

    # Lower bounds from rejection: c[a] >= max_{j rejected} p_a^T w_j + epsilon
    if rejected_idx.size > 0:
        pays_rej = payoffs[:, rejected_idx]  # (n_actions, R)
        c_lower_bounds = pays_rej.max(axis=1) + epsilon
    else:
        c_lower_bounds = np.zeros(n_actions)

    # Enforce c >= 0 as well
    c_lower_bounds = np.maximum(c_lower_bounds, 0.0)

    # Fix infeasible bounds by shifting upper bounds if needed
    for i in range(n_actions):
        if c_upper_bounds[i] < c_lower_bounds[i]:
            c_upper_bounds[i] = c_lower_bounds[i] + 1e-3

    # Step 6: Solve LP to minimize sum costs subject to bounds
    c_obj = np.ones(n_actions)
    bounds = [(c_lower_bounds[i], c_upper_bounds[i]) for i in range(n_actions)]
    res = linprog(c_obj, bounds=bounds, method='highs')

    if res.success:
        costs = res.x
    else:
        # fallback: midpoint of bounds
        costs = (c_lower_bounds + c_upper_bounds) / 2

    # Step 7: Return agent setting matrix: [p_1,...,p_5, cost]
    agent_setting = np.hstack([centers, costs[:, np.newaxis]])
    return agent_setting
```
