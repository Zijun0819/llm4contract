```python
import numpy as np
from sklearn.cluster import KMeans
from scipy.optimize import linprog

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer agent actions as distributions over 5 outcomes and nonnegative costs
    that rationalize observed accept / reject logs under IR and IC constraints.

    Args:
        v (np.ndarray): principal's value vector, shape (5,)
        content (list[dict]): logs, each with keys:
            - 'Contract': payment vector of length 5
            - 'Principal Utility': scalar utility for principal (0 if rejected)
            - 'Agent Action': 1 (accept) or -1 (reject)

    Returns:
        np.ndarray: agent setting matrix n x 6 (5 probs + 1 cost)
    """
    m = v.size
    L = len(content)
    contracts = np.array([log['Contract'] for log in content])  # L x 5
    agent_actions = np.array([log['Agent Action'] for log in content])
    principal_utilities = np.array([log['Principal Utility'] for log in content])

    # Candidate number of agent actions: try adaptive range [3..10]
    # We'll pick smallest n that yields consistent IR/IC
    for n_candidates in range(3, 11):
        # Step 1: Use only accepted contracts to infer outcome distributions p
        accepted_idx = np.where(agent_actions == 1)[0]
        if len(accepted_idx) < n_candidates:
            # Not enough accepts for that many clusters
            continue
        accepted_contracts = contracts[accepted_idx]

        # Use KMeans clustering on accepted contracts weighted by principal util to capture clusters
        # Weight contracts by principal utility: accepted logs have positive principal utility
        weights = np.maximum(principal_utilities[accepted_idx], 1e-3)
        # KMeans on weighted contracts to differentiate payment structures
        km = KMeans(n_clusters=n_candidates, n_init=15, random_state=42)
        km.fit(accepted_contracts, sample_weight=weights)
        centers = km.cluster_centers_  # n_candidates x 5
        
        # Step 2: Infer agent outcome distributions p for each candidate from cluster centers:
        # Solve LP for each center c to find p maximizing p @ v s.t p @ w = c @ w for all w?
        # Actually, what we want is: find p in simplex s.t p @ wages = acceptance utility for given contract.
        # Since agent utility = p@w - cost >= 0 for accepted; cost unknown. 
        # Instead, set p = distribution proportional to center payments (assume rational agent expectation aligned)
        # We solve LP to find p maximizing sum(p)=1 and certain linear constraints:
        def infer_p_from_w(wvec):
            # Solve for p: maximize p¡¤v (agent expects v), s.t p¡¤w = wvec¡¤w (p unknown, wvec known)
            # But unknown how to do exactly -> Use LP:
            # Constraints: sum p_i = 1; p >= 0;
            # This may be underdetermined; choose p maximizing agent utility for cluster
            c_lp = -v  # minimize negative expectation = maximize expectation
            A_eq = [np.ones(m)]
            b_eq = [1]
            bounds = [(0, 1)] * m
            # Try to force p@wvec close to mean payment of cluster center ~ wvec itself
            # Instead, just solve max expected value p@v s.t sum p=1
            res = linprog(c_lp, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
            return res.x if res.success else np.ones(m) / m
        
        p_candidates = np.array([infer_p_from_w(center) for center in centers])

        # Step 3: Compute agent cost c for each candidate action
        # For accepted logs assigned to each cluster, minimal cost to justify acceptance:
        # cost_a <= max over i in cluster of p_a ¡¤ w_i (agent utility >= 0 => cost ¡Ü p_a¡¤w_i)
        cluster_labels = km.labels_
        c_candidates = np.zeros(n_candidates)
        feasible = True
        for a in range(n_candidates):
            idx_a = accepted_idx[cluster_labels == a]
            if len(idx_a) == 0:
                # No accepted logs assigned here, set cost to zero conservatively
                c_candidates[a] = 0.0
                continue
            # For action a, agent utility on each accepted contract i:
            # u_i = p_a¡¤w_i - c_a ¡Ý 0 => c_a ¡Ü p_a¡¤w_i for all i
            # So cost candidate action ¡Ü min_i p_a¡¤w_i
            p = p_candidates[a]
            payoffs = contracts[idx_a] @ p
            c_candidates[a] = np.min(payoffs)
            if c_candidates[a] < 0:
                # Cost cannot be negative, inconsistent
                feasible = False
                break
        if not feasible:
            # Try next n_candidates
            continue

        # Step 4: Check that all accepted contracts must yield nonnegative utility for some action
        # and all rejected contracts have <0 utility for all actions
        # This verifies incentive compatibility and rationality
        accepted_checks = []
        for i in range(len(accepted_idx)):
            utilities = p_candidates[cluster_labels[i]] @ contracts[accepted_idx[i]] - c_candidates[cluster_labels[i]]
            if utilities < 0:
                feasible = False
                break
        if not feasible:
            continue

        # Verify rejected contracts
        rejected_idx = np.where(agent_actions == -1)[0]
        if len(rejected_idx) > 0:
            # For rejection, agent utility must be < 0 for all actions
            rej_utilities = (contracts[rejected_idx] @ p_candidates.T) - c_candidates
            if np.any(rej_utilities >= -1e-8):  # allow numeric tolerance
                # Some rejection not rationalized: continue search
                continue

        # Step 5: Normalize p candidates to ensure each is a probability distribution exactly
        p_candidates = np.clip(p_candidates, 0, None)
        p_candidates /= p_candidates.sum(axis=1, keepdims=True)

        # Costs nonnegative check again
        if np.any(c_candidates < 0):
            continue

        # Successfully found valid agent setting
        agent_setting = np.hstack([p_candidates, c_candidates[:, None]])
        return agent_setting

    # Fallback: trivial agent behavior (all outcomes uniform, zero cost)
    fallback_p = np.ones((1, m)) / m
    fallback_c = np.array([0.0])
    return np.hstack([fallback_p, fallback_c[:, None]])
```
