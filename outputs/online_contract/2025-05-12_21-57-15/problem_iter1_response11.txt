```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog, minimize
from sklearn.cluster import DBSCAN

def agent_solver_v2(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    """
    Infers a valid agent setting matrix (n x 6) given principal's reward v and interaction logs.
    Each row corresponds to an agent action with:
      - first 5 columns: outcome probabilities (sum to 1)
      - last column: cost (¡Ý 0)
    The inferred actions explain both accepted (Agent Action = 1) and rejected (Agent Action = -1) observations.

    Args:
        v (np.ndarray): Vector of length 5 representing principal's reward per outcome.
        content (pd.DataFrame): DataFrame with columns ['Contract', 'Principal Utility', 'Agent Action'].

    Returns:
        np.ndarray: n x 6 matrix representing agent actions and costs.
    """
    m_outcomes = v.size
    L = len(content)

    contracts = np.array(content['Contract'].tolist())  # shape (L,5)
    utilities = np.array(content['Principal Utility'].tolist())  # shape (L,)
    actions = np.array(content['Agent Action'].tolist())  # shape (L,)

    # Separate accepted and rejected logs
    acc_idx = np.where(actions == 1)[0]
    rej_idx = np.where(actions == -1)[0]

    # ----------------------------------------------------------------------
    # Step 1: For accepted logs, estimate expected outcome distribution p and cost c such that:
    #   p @ w - c = agent utility >= 0 (accepted)
    # For rejected logs:
    #   maximal expected utility < 0 for all candidate (p,c)
    #
    # We use a heuristic: use accepted contracts/outcomes to estimate candidate p distributions,
    # then solve for feasible costs, ensuring IR and IC constraints over all data.
    # ----------------------------------------------------------------------

    # Step 1a: Estimate empirical outcome distributions using non-negative least squares
    # Since we don't observe realized outcomes, only contracts and utilities, 
    # try to infer p via LP that enforces p sums to 1, p >=0, and for each accepted log:
    # p @ Contract - cost >= 0; cost unknown, solve later.

    # Idea:
    # Extract a set of plausible p vectors:
    # For each accepted contract w and supposed utility u >= 0, solve for p:
    # We minimize ||p - c0|| (for some prior c0 uniform) ... but actually simply find feasible p s.t p @ w >= cost.
    # However, cost unknown and we have multiple constraints.

    # We'll implement an iterative procedure:

    # ----------------------
    # Step 1b: Cluster accepted contracts to obtain representative p candidates:
    # The heuristic: contract payment tends to induce specific p distributions,
    # cluster accepted contracts and for each cluster, solve feasibility LP for p.
    # ----------------------

    if len(acc_idx) == 0:
        # No accepted logs: infer trivial agent action with uniform distribution and 0 cost
        p_uniform = np.ones(m_outcomes) / m_outcomes
        return np.hstack([p_uniform, 0.0])[np.newaxis]

    accepted_contracts = contracts[acc_idx]  # (num_acc,5)

    # Cluster accepted contracts with DBSCAN to adaptively choose number of clusters
    clustering = DBSCAN(eps=1.2, min_samples=5).fit(accepted_contracts)
    labels = clustering.labels_

    unique_labels = [l for l in set(labels) if l != -1]
    if len(unique_labels) == 0:
        # fallback: all one cluster
        unique_labels = [0]
        labels = np.zeros(len(acc_idx), dtype=int)

    # Prepare to store candidate p vectors
    candidate_ps = []

    for ul in unique_labels:
        cluster_c_inds = np.where(labels == ul)[0]
        cluster_contracts = accepted_contracts[cluster_c_inds]  # (size, 5)
        cluster_utilities = utilities[acc_idx][cluster_c_inds]  # (size,)

        # Define LP to get p: solve for p vector:
        # p >= 0, sum p =1
        # For each contract w_i in cluster: p @ w_i >= cost_i
        # Because cost unknown, we approximate p by minimizing (min) sum ||p*w_i - u_i||
        # Or more simply, minimize sum over l2 norms of (p @ w_i - max(0,u_i))=0 for accept
        # Instead, formulate as quadratic program: minimize sum_i (p @ w_i - u_i)^2
        # But we keep it simple:
        # We try to find p s.t min(max_i |p @ w_i - u_i|) is minimized.

        # We'll solve quadratic problem:
        # min_{p} sum_i (p w_i - u_i)^2
        # s.t p >=0; sum p =1

        # Setup matrices:
        W = cluster_contracts  # (n_i,5)
        u_vals = np.maximum(cluster_utilities, 0.0)  # (n_i,)

        # Objective: (W p - u)^T (W p - u) = p^T (W^T W) p - 2 u^T W p + u^T u
        Q = 2 * (W.T @ W)  # shape (5,5)
        c = -2 * (u_vals @ W)  # shape (5,)

        # Constraints: p >=0, sum p = 1
        bounds = [(0,1)]*m_outcomes
        cons = ({
            'type': 'eq',
            'fun': lambda p: np.sum(p) - 1
        })

        def obj(p):
            return p @ Q @ p + c @ p

        # Initialization as uniform p
        p0 = np.ones(m_outcomes) / m_outcomes

        res = minimize(obj, p0, bounds=bounds, constraints=cons, method='SLSQP', options={'ftol':1e-9,'disp':False,'maxiter':500})
        if res.success:
            p_cand = res.x
        else:
            p_cand = p0
        candidate_ps.append(p_cand)

    candidate_ps = np.array(candidate_ps)  # (n_cand, 5)

    n_cand = candidate_ps.shape[0]

    # STEP 2: For each candidate p_cand, determine minimum cost c to rationalize accepted logs assigned to that p:
    # Assign accepted logs to the candidate p that best explains the data:
    # score = expected agent utility = p @ contract - cost >= 0, so initially cost unknown.
    # We assign each accepted log to closest candidate p in L1 norm (or max residual)

    assigns = np.zeros(len(acc_idx), dtype=int)
    for i, idx_i in enumerate(acc_idx):
        w = contracts[idx_i]
        scores = candidate_ps @ w  # expected utility without cost (cost to subtract later)
        assigns[i] = np.argmax(scores)

    # Compute cost per candidate p:
    # For accepted logs assigned to candidate a:
    # cost_a <= min_{i in a} p_a @ w_i  because agent utility = p_a @ w_i - cost_a >= 0
    # So cost_a = min_i p_a @ w_i over assigned i, ensures IR <= 0 utility

    costs = np.zeros(n_cand)
    for a in range(n_cand):
        inds = np.where(assigns == a)[0]
        if inds.size == 0:
            # no accepted logs assigned, set cost 0
            costs[a] = 0.0
        else:
            expected_utils = []
            for j in inds:
                i = acc_idx[j]
                expected_utils.append(candidate_ps[a] @ contracts[i])
            costs[a] = max(0., np.min(expected_utils))

    # STEP 3: Verify rejection consistency:
    # For rejected logs, max_{a} (p_a @ w_i - c_a) < 0, otherwise rejection violated IR or IC.

    if len(rej_idx) > 0:
        rejected_contracts = contracts[rej_idx]  # (num_rej, 5)

        # Compute expected utilities for each candidate and each rejected contract
        expected_utils_rej = candidate_ps @ rejected_contracts.T  # shape (n_cand, num_rej)
        utils_minus_cost = expected_utils_rej - costs[:, np.newaxis]  # (n_cand, num_rej)

        viol = np.any(utils_minus_cost >= 0.0)
        if viol:
            # Adjust costs upwards to fix violation: for each violating candidate,
            # set cost_a = max_{rej_i} p_a @ w_i
            max_rej_util = np.max(expected_utils_rej, axis=1)  # shape n_cand
            new_costs = np.maximum(costs, max_rej_util + 1e-6)
            costs = new_costs

    # STEP 4: Normalize probabilities and clip costs
    candidate_ps = np.clip(candidate_ps, 1e-8, None)
    candidate_ps /= candidate_ps.sum(axis=1, keepdims=True)
    costs = np.clip(costs, 0, None)

    agent_setting = np.hstack([candidate_ps, costs[:, np.newaxis]])

    return agent_setting
```
