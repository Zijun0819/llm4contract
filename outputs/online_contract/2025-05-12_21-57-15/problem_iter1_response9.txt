```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import DBSCAN

def agent_solver(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    """
    Infer a valid agent setting matrix n x (5+1):
    - first 5 columns: outcome distributions p (sum=1),
    - last column: cost (>=0).
    The agent setting explains all historical accepted/rejected contract logs.

    Params:
    v: 1-D np.ndarray of length 5, principal value of outcomes.
    content: pd.DataFrame with columns ['Contract', 'Principal Utility', 'Agent Action'],
             Contract: list or array of length 5,
             Agent Action: 1 (accept) or -1 (reject).

    Returns:
    agent_setting: np.ndarray shape (n_actions, 6)
    """
    contracts = np.vstack(content['Contract'].values)  # shape (L,5)
    agent_actions = content['Agent Action'].values
    principal_utils = content['Principal Utility'].values
    L, m = contracts.shape

    # 1) Separate accepted and rejected logs
    accepted_idx = np.where(agent_actions == 1)[0]
    rejected_idx = np.where(agent_actions == -1)[0]

    accepted_contracts = contracts[accepted_idx]
    accepted_utilities = principal_utils[accepted_idx]

    # 2) For each accepted log, try to infer a valid p distribution and agent cost c
    # where p @ contract - c >= 0 (IR satisfied)
    # and also principal utility = p @ (v - contract) OR close

    # mini LP: given contract w and principal utility u, find distribution p:
    # sum p_i =1, p_i >=0
    # p @ v - p @ w = u  => p @ w = p @ v - u

    # So constraints:
    # 1) sum p_i =1
    # 2) p @ w = p @ v - u
    # Simplify: p @ (w - v) = -u

    inferred_p_list = []
    inferred_c_list = []

    for i, idx_i in enumerate(accepted_idx):
        w = contracts[idx_i]
        ui = principal_utils[idx_i]
        # Constraints:
        # sum p_i = 1
        # p @ (w - v) = -ui
        # p_i >=0
        A_eq = np.vstack([np.ones(m), w - v])
        b_eq = np.array([1.0, -ui])
        bounds = [(0, 1) for _ in range(m)]

        # We want feasible p minimizing agent cost c = p @ w - 0 (but cost unknown)
        # For now just find feasible p by minimizing 0 objective (just feasibility LP)
        res = linprog(c=np.zeros(m), A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            c = p @ w  # agent cost consistent with IR: p@w - c >= 0 => c<= p@w. Set c = p@w (lowest)
            inferred_p_list.append(p)
            inferred_c_list.append(c)
        else:
            # If no feasible solution, try a relaxed version (allow small epsilon)
            # adding a small tolerance to equality constraints via bounds on second constraint
            A_ub = np.vstack([-(w - v), (w - v)])
            b_ub = np.array([ui + 1e-5, -ui + 1e-5])

            res_relax = linprog(
                c=np.zeros(m),
                A_eq=[np.ones(m)],
                b_eq=[1.0],
                A_ub=A_ub,
                b_ub=b_ub,
                bounds=bounds,
                method='highs'
            )
            if res_relax.success:
                p = res_relax.x
                c = p @ w
                inferred_p_list.append(p)
                inferred_c_list.append(c)
            else:
                # fallback: uniform p, cost = p @ w
                p = np.ones(m) / m
                c = p @ w
                inferred_p_list.append(p)
                inferred_c_list.append(c)

    if not inferred_p_list:
        # No accepted contract feasible, trivially create one uniform action with zero cost
        return np.hstack([np.ones((1, m)) / m, np.zeros((1, 1))])

    inferred_p = np.array(inferred_p_list)
    inferred_c = np.array(inferred_c_list)

    # 3) Cluster inferred p distributions to find compact set of actions
    # Using DBSCAN to determine number of clusters adaptively
    clustering = DBSCAN(eps=0.12, min_samples=3).fit(inferred_p)
    labels = clustering.labels_

    unique_labels = set(labels)
    if -1 in unique_labels:
        # Noise points, assign them as separate clusters one by one
        noise_indices = np.where(labels == -1)[0]
        next_label = max(unique_labels) + 1
        for i, noise_idx in enumerate(noise_indices):
            labels[noise_idx] = next_label + i
        unique_labels = set(labels)

    n_actions = len(unique_labels)

    # Aggregate by cluster: mean p and minimum cost (agent cost consistent with IR)
    p_actions = np.zeros((n_actions, m))
    c_actions = np.zeros(n_actions)
    label_list = sorted(unique_labels)

    for i, lbl in enumerate(label_list):
        cluster_idx = np.where(labels == lbl)[0]
        p_actions[i] = inferred_p[cluster_idx].mean(axis=0)
        # normalize p_actions[i] to sum to 1 (cluster mean might break equality slightly)
        p_actions[i] = np.maximum(p_actions[i], 0)
        s = p_actions[i].sum()
        if s > 0:
            p_actions[i] /= s
        else:
            p_actions[i] = np.ones(m) / m
        c_actions[i] = inferred_c[cluster_idx].min()  # minimal cost consistent with IR among cluster

    # 4) Check rejected contracts consistency: for every rejected contract w,
    # we want max_a p_a @ w - c_a < 0 (agent rejects => agent utility < 0)
    if len(rejected_idx) > 0:
        rejected_contracts = contracts[rejected_idx]
        for w_rej in rejected_contracts:
            utilities = (p_actions @ w_rej) - c_actions
            max_utility = utilities.max()
            if max_utility >= 0:
                # Violation: must increase c for offending actions
                violating = np.where(utilities >= 0)[0]
                # Increase the cost marginally by (utility + small margin)
                margins = utilities[violating] + 1e-4
                c_actions[violating] += margins

    # 5) Ensure costs nonnegative
    c_actions = np.clip(c_actions, 0, None)

    # 6) Return agent setting matrix: [p | c]
    return np.hstack([p_actions, c_actions[:, None]])
```
