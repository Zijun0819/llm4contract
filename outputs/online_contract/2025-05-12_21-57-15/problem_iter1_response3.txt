```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog, minimize
from sklearn.cluster import DBSCAN


def agent_solver_v2(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    """
    Infer a valid agent setting from historical logs (content) and principal reward vector v.
    
    Args:
        v (np.ndarray): Principal value vector of length 5.
        content (pd.DataFrame): DataFrame with columns 'Contract' (list of 5 payments),
                                'Principal Utility' (float), 'Agent Action' (1 or -1).
    
    Returns:
        np.ndarray: Agent setting matrix of shape (n_actions, 6) with each row:
                     - first 5 entries: probabilities over outcomes summing to 1,
                     - last entry: non-negative cost >=0.
    """
    # Extract data columns
    contracts = np.vstack(content['Contract'].values)  # L x 5
    putils = content['Principal Utility'].values       # L
    agent_actions = content['Agent Action'].values      # L (1 or -1)
    
    L, m = contracts.shape  # number of logs, 5 outcomes
    
    # Step 1: Identify accepted and rejected contracts
    accepted_idx = np.where(agent_actions == 1)[0]
    rejected_idx = np.where(agent_actions == -1)[0]
    
    if len(accepted_idx) == 0:
        # No accepted contracts means agent always rejects,
        # so single action row: uniform distribution, large cost to ensure reject all contracts
        p = np.ones(m) / m
        c = max(np.dot(p, contracts.T).max(), 1.0) + 1.0  # cost bigger than highest expected payoff
        return np.array([np.append(p, c)])
    
    # Step 2: Use accepted contracts to estimate candidate outcome distributions p_i
    
    # Function to solve LP to find a valid p given contract w and agent utility u >= 0:
    # We want p s.t. p@w - cost >= 0 and p sums to 1 with p >=0.
    # cost is unknown, but evaluated later. So starting from just observing feasible p satisfying:
    # assign u_i = max expected utility under that contract from agent utility definition >= 0.
    # We'll infer p that match contract payoffs at logs with Agent Action == 1.
    
    # For each accepted contract i:
    # linear feasibility: p_i^T contract_i >= cost_i >= 0, p_i \in simplex.
    # The cost_i varies, so for inference, we find a p_i that can rationalize it.

    # Instead of fitting p_i individually, let's cluster accepted contracts' wage vectors,
    # assuming the agent has finitely many actions with distinct outcome distributions.

    # Step 3: Cluster contracts of accepted logs by their payment vectors to reveal group structure of actions
    
    # Using DBSCAN to find clusters adaptively based on density (no fixed k)
    clustering = DBSCAN(eps=1.2, min_samples=3).fit(contracts[accepted_idx])

    labels = clustering.labels_
    unique_labels = set(labels)
    if -1 in unique_labels:
        unique_labels.remove(-1)  # -1 means noise points

    if len(unique_labels) == 0:
        # fallback all accepted contracts as one cluster (one action)
        n_actions = 1
        clusters = [accepted_idx]
    else:
        clusters = [accepted_idx[labels == lbl] for lbl in unique_labels]
        n_actions = len(clusters)

    # Step 4: Infer outcome distributions p and costs c for each action cluster
    
    p_list = []
    c_list = []
    
    # Build constraints per cluster: p in simplex, costs c >= 0,
    # For each accepted contract assigned to cluster:
    # u_i = p@w_i - c >= 0  (IR)
    # For rejected contracts:
    # p@w_j - c < 0 must hold for all j
    # We'll solve optimization to find p,c satisfying all IR & IC constraints
    
    # Compile data indices for rejected contracts once (array form)
    w_rej = contracts[rejected_idx] if len(rejected_idx) > 0 else np.empty((0, m))
    
    for cluster_idx in range(n_actions):
        inds = clusters[cluster_idx]
        w_acc = contracts[inds]          # accepted contracts in cluster
        p_dim = m

        # Variables: p (size m), scalar cost c
        # We formulate as a constrained nonlinear optimization problem:
        # Constraints:
        # 1) p_i >=0, sum(p)=1
        # 2) For accepted contract i: p @ w_acc[i] >= c
        # 3) For rejected contracts j: p @ w_rej[j] <= c - delta  (strict below c)
        #    Use a margin delta=1e-4 to ensure strictness

        delta = 1e-4
        
        def obj(x):
            # Objective: minimize negative expected principal utility on accepted contracts
            # to have meaningful p: max_p sum_i p@w_acc[i]*v vector (maximize principal expected utility)
            # But principal utility uses v not payouts.
            # Instead, minimize negative minimal margin between accepted util and cost
            # To encourage meaningful p and cost that rationalize data
            p = x[:p_dim]
            c = x[p_dim]
            margin_acc = np.min(p @ w_acc.T - c)
            # maximize margin acc, so minimize negative margin
            return -margin_acc

        # Initial guess: p uniform, c = min expected payout on accepted contract minus small positive
        p0 = np.ones(p_dim) / p_dim
        c0 = np.min(p0 @ w_acc.T) - 0.1
        if c0 < 0:
            c0 = 0.0
        x0 = np.append(p0, c0)

        bounds = [(0, 1)] * p_dim + [(0, None)]  # costs >=0

        constraints = []

        # sum of p_i = 1
        constraints.append({'type': 'eq', 'fun': lambda x: np.sum(x[:p_dim]) - 1})

        # For accepted contracts: p @ w_acc[i] - c >= 0, rewritten as c - p @ w_acc[i] <= 0 nonlinear constraints
        for i in range(len(w_acc)):
            def con_acc(x, w=w_acc[i]):
                p = x[:p_dim]
                c = x[p_dim]
                return p @ w - c  # >= 0
            constraints.append({'type': 'ineq', 'fun': con_acc})

        # For rejected contracts: p @ w_rej[j] - c <= -delta, or c - p @ w_rej[j] >= delta
        # i.e. p @ w_rej[j] - c <= -delta -> c - p @ w_rej[j] >= delta
        for j in range(w_rej.shape[0]):
            def con_rej(x, w=w_rej[j]):
                p = x[:p_dim]
                c = x[p_dim]
                return c - p @ w - delta  # >= 0
            constraints.append({'type': 'ineq', 'fun': con_rej})

        # Solve
        result = minimize(obj, x0, method='SLSQP', bounds=bounds, constraints=constraints,
                          options={'ftol':1e-9, 'maxiter':1000})

        if not result.success:
            # fallback: Use mean payout distribution of accepted contracts in that cluster as p,
            # and cost c = min expected agent payoff among accepted contracts minus small epsilon
            p = np.mean(w_acc, axis=0)
            p = np.clip(p, 1e-8, None)
            p = p / p.sum()
            c = np.min(p @ w_acc.T)
            if c < 0:
                c = 0.
        else:
            p = result.x[:p_dim]
            c = result.x[p_dim]

        # Normalize p to simplex if small numerical infeasibility
        p = np.maximum(p, 0)
        p = p / np.sum(p)

        c = max(c, 0)
        p_list.append(p)
        c_list.append(c)
    
    # Convert lists to numpy arrays
    P_arr = np.vstack(p_list)            # n_actions x 5
    C_arr = np.array(c_list).reshape(-1,1)  # n_actions x 1

    # Final vigilance: 
    # Ensure for every accepted log there is at least one action (p,c) pair with agent utility >= 0.
    # If not, slightly relax with slack:
    for i in accepted_idx:
        w_i = contracts[i]
        utilities = P_arr @ w_i - C_arr.flatten()
        if np.all(utilities < -1e-6):
            # Modify the closest action's cost downward to ensure acceptance
            b_idx = np.argmax(utilities)
            C_arr[b_idx] = max(P_arr[b_idx] @ w_i, 0)

    # Return agent setting matrix [p_1 ... p_5 cost]
    agent_setting = np.hstack([P_arr, C_arr])

    return agent_setting
```
