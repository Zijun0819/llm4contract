```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import KMeans


def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix from historical contract interactions.

    Parameters:
    - v: Principal reward vector of shape (5,)
    - content: List of dicts, each with keys 'Contract' (list of 5 floats),
               'Principal Utility' (float), 'Agent Action' (1 or -1)

    Returns:
    - agent_setting: n x 6 numpy array where each row represents an action:
        first 5 elements are outcome probabilities (sum to 1),
        last element is agent's cost (>=0) for performing the action.
    """
    m_outcomes = v.shape[0]
    L = len(content)

    # Parse logs into arrays for convenience
    contracts = np.array([entry['Contract'] for entry in content])  # shape (L,5)
    p_utils = np.array([entry['Principal Utility'] for entry in content])  # shape (L,)
    agent_actions = np.array([entry['Agent Action'] for entry in content])  # shape (L,)

    # Step 1: Use accepted contracts to infer agent action outcome distributions and costs.
    # Accepted contracts (agent_action==1) must satisfy: expected agent utility >=0
    # Agent utility = p @ w - cost >= 0
    # We want to infer (p, cost) triples for n actions explaining all accepted logs under IC and IR constraints.
    # Allow adaptive n based on acceptance log diversity.

    # Heuristic n_candidates: min(10, unique acceptance contracts / 2, at least 2)
    unique_accept = np.unique([tuple(c) for c,a in zip(contracts, agent_actions) if a==1], axis=0)
    n_candidates = min(max(2, len(unique_accept)//2), 10)

    # Step 2: Infer outcome distributions p for accepted contracts by solving constrained LPS.
    # For each accepted contract and its principal utility p_util:
    # We want to find p (distribution over 5 outcomes) satisfying:
    # sum(p) = 1
    # p >= 0
    # principal utility = p @ v - contract payment = p_util
    # from this we can write p @ v = contract payment + p_util
    # Use linprog to find a feasible p maximizing entropy or minimizing variance

    acceptance_indices = np.where(agent_actions == 1)[0]
    p_candidates = []
    cost_candidates = []

    for idx in acceptance_indices:
        w = contracts[idx]
        util_p = p_utils[idx]
        # total agent payment + agent utility = expected agent value
        rhs = util_p + w @ np.ones(m_outcomes)  # but contract payment vector and p unknown
        # Instead, the constraints: p @ v - w @ p = p_util + w @ p ?? Not direct.
        # Alternate interpretation:
        # Agent expected utility = p @ w - cost >=0
        # But principal utility = p @ v - p @ w = p_util (given)
        # So p @ v - p @ w = p_util => p@(v-w) = p_util
        # Hence, p must satisfy sum(p)=1, p>=0, p@(v-w) = p_util

        c = np.zeros(m_outcomes)  # no objective, want feasible p
        A_eq = np.vstack((np.ones(m_outcomes), v - w))
        b_eq = np.array([1.0, util_p])

        bounds = [(0, 1)] * m_outcomes

        res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            # cost inferred from agent utility: cost = p @ w - agent utility (>=0)
            agent_util = p @ w
            cost = agent_util  # cost = p@w - agent utility, but we don't know agent utility here exactly
            # But from agent action acceptance, agent utility must be >=0; minimal is 0
            cost_candidates.append(0)  # minimal cost that fits acceptance
            p_candidates.append(p)
        else:
            # If infeasible skip
            pass

    if len(p_candidates) == 0:
        # fallback trivial agent choosing uniform with zero cost
        uniform_p = np.ones(m_outcomes) / m_outcomes
        return np.hstack([uniform_p, np.array([0])]).reshape(1, -1)

    p_candidates = np.array(p_candidates)

    # Step 3: Cluster the inferred p vectors to form n candidate agent actions
    kmeans = KMeans(n_clusters=n_candidates, random_state=42, n_init=10)
    p_clusters = kmeans.fit(p_candidates).cluster_centers_

    # Normalize cluster centers to be distributions strictly
    p_clusters = np.maximum(p_clusters, 0)
    p_clusters /= p_clusters.sum(axis=1, keepdims=True)

    # Step 4: For each cluster (action), infer minimal cost consistent with logs
    # Agent IR: for accepted logs assigned to the cluster, cost <= p @ w
    # Agent IC: agent chooses action with maximal utility p @ w - cost
    # Rejection: for rejected logs, max over actions p @ w - cost < 0

    # Assign each accepted log to closest clustered action (highest p@w)
    assigns = -np.ones(L, dtype=int)
    for i in acceptance_indices:
        w = contracts[i]
        utilities = p_clusters @ w  # expected payment for each action on contract w
        assigns[i] = int(np.argmax(utilities))

    cost_vector = np.zeros(n_candidates)
    # Compute cost lower bounds to satisfy IR from accepted logs assigned to each action
    for a in range(n_candidates):
        idx_a = np.where(assigns == a)[0]
        if len(idx_a) == 0:
            # no accepted log assigned; cost set to zero to not violate rejection
            cost_vector[a] = 0
            continue
        candidate_costs = []
        for i in idx_a:
            w = contracts[i]
            u = agent_actions[i]
            # cost <= p[a] @ w , as agent utility = p[a]@w - cost >=0
            candidate_costs.append(p_clusters[a] @ w)
        cost_vector[a] = min(candidate_costs)

    cost_vector = np.clip(cost_vector, 0, None)  # non-negative costs

    # Step 5: Ensure rejection constraints
    reject_idx = np.where(agent_actions == -1)[0]
    if len(reject_idx):
        # For each rejected contract w, max_{a}(p[a] @ w - cost[a]) < 0 holds
        for i in reject_idx:
            w = contracts[i]
            util_rej = p_clusters @ w - cost_vector
            max_util = util_rej.max()
            if max_util >= 0:
                # To enforce max_util < 0:
                # Increase cost_vector of actions with max_util(s)
                idxs = np.where(util_rej >= max_util - 1e-7)[0]
                increase = max_util + 1e-4
                for idx_a in idxs:
                    cost_vector[idx_a] = max(cost_vector[idx_a], p_clusters[idx_a] @ w + increase)

    # Step 6: Verify IC for accepted logs - each must prefer assigned action among all
    for i in acceptance_indices:
        w = contracts[i]
        assigned_a = assigns[i]
        utilities = p_clusters @ w - cost_vector
        # Fix cost to maintain assigned action utility >= others
        for a in range(n_candidates):
            if a == assigned_a:
                continue
            diff = utilities[a] - utilities[assigned_a]
            if diff > 0:
                # reduce costs of assigned action or increase competitor costs
                adjust = diff + 1e-4
                cost_vector[assigned_a] = max(cost_vector[assigned_a] - adjust, 0)
                cost_vector[a] = max(cost_vector[a], p_clusters[a] @ w + 1e-4)

    # Final round clip costs >=0
    cost_vector = np.clip(cost_vector, 0, None)

    agent_setting = np.hstack([p_clusters, cost_vector[:, None]])

    return agent_setting
```
