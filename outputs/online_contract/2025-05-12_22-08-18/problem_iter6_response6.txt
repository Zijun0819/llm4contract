```python
import numpy as np
from sklearn.cluster import AgglomerativeClustering

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions = outcome distributions + costs)
    that rationalizes all historical contract-agent interaction logs under IC and IR,
    using weighted clustering on accepted contracts and careful cost lower bounds.

    Parameters:
    - v (np.ndarray): Principal's value vector of length 5
    - content (list[dict]): each dict has keys:
        'Contract' (list of 5 floats),
        'Principal Utility' (float),
        'Agent Action' (1 or -1)

    Returns:
    - agent_setting (np.ndarray): n_actions x 6 matrix; each row:
        first 5 elements: outcome probabilities summing to 1,
        last element: nonnegative agent cost
    """
    m_outcomes = v.shape[0]
    L = len(content)

    # Extract arrays from logs
    contracts = np.array([log['Contract'] for log in content], dtype=np.float64)  # (L,5)
    agent_actions = np.array([log['Agent Action'] for log in content], dtype=int)  # (L,)
    p_util = np.array([log['Principal Utility'] for log in content], dtype=np.float64)  # (L,)

    accepted_ix = np.where(agent_actions == 1)[0]
    rejected_ix = np.where(agent_actions == -1)[0]

    # If no accepted contracts, return trivial uniform distribution with zero cost
    if accepted_ix.size == 0:
        p_uniform = np.ones(m_outcomes) / m_outcomes
        return np.hstack([p_uniform.reshape(1, -1), np.array([[0.0]])])

    accepted_contracts = contracts[accepted_ix]
    accepted_utilities = p_util[accepted_ix]

    # Normalize accepted contracts for clustering (avoid zero-sum)
    norm_accepted = accepted_contracts / (accepted_contracts.sum(axis=1, keepdims=True) + 1e-12)

    # Determine number of clusters: min(10, number accepted, floor(sqrt(number accepted))) at least 1
    n_clusters = max(1, min(10, accepted_ix.size, int(np.sqrt(accepted_ix.size))))
    if n_clusters > 1:
        clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='average')
        cluster_labels = clustering.fit_predict(norm_accepted)
    else:
        cluster_labels = np.zeros(accepted_ix.size, dtype=int)

    p_candidates = []
    cost_lower_bounds = []

    for cluster_id in range(n_clusters):
        cluster_mask = (cluster_labels == cluster_id)
        cluster_indices = accepted_ix[cluster_mask]
        if cluster_indices.size == 0:
            continue

        cluster_w = contracts[cluster_indices]
        cluster_util = accepted_utilities[cluster_mask]

        # Compute weights emphasizing better contracts: (util - min_util + 1)
        min_util = cluster_util.min()
        weights = cluster_util - min_util + 1.0
        if weights.sum() < 1e-12:
            weights = np.ones_like(weights)
        weights /= weights.sum()

        # Weighted average contract vector (may not sum to 1)
        avg_w = np.average(cluster_w, axis=0, weights=weights)

        # Project avg_w onto probability simplex: clip negatives and normalize
        p = np.clip(avg_w, 0, None)
        s = p.sum()
        if s < 1e-12:
            p = np.ones(m_outcomes) / m_outcomes
        else:
            p = p / s

        # Lower bound on cost from IR: minimum p @ w_i over cluster contracts
        vals = np.array([p @ contracts[i] for i in cluster_indices])
        cost_lb = vals.min()

        p_candidates.append(p)
        cost_lower_bounds.append(cost_lb)

    p_candidates = np.array(p_candidates)  # shape (n_clusters, 5)
    cost_lower_bounds = np.array(cost_lower_bounds)  # shape (n_clusters,)

    # For rejected contracts, cost must be > p @ w_j to guarantee rejection
    if rejected_ix.size > 0:
        rejected_w = contracts[rejected_ix]  # (#rej,5)
        # Matrix of p_a @ w_j, shape (n_actions, #rej)
        p_w_rej = p_candidates @ rejected_w.T  # (n_clusters, #rej)
        c_rej_min = p_w_rej.max(axis=1) + 1e-7
    else:
        c_rej_min = np.zeros_like(cost_lower_bounds)

    # Costs must satisfy both accepted IR and rejected constraints
    costs = np.maximum(cost_lower_bounds, c_rej_min)
    costs = np.maximum(costs, 0.0)

    def action_explains_contract(w_i):
        utilities = p_candidates @ w_i - costs
        valid = np.where(utilities >= -1e-9)[0]
        return valid[0] if valid.size > 0 else None

    # Add new actions to explain any accepted contract not rationalized yet
    for idx in accepted_ix:
        w_i = contracts[idx]
        if action_explains_contract(w_i) is None:
            # New action with p = normalized w_i clipped at 0
            p_new = np.clip(w_i, 0, None)
            s = p_new.sum()
            if s < 1e-12:
                p_new = np.ones(m_outcomes) / m_outcomes
            else:
                p_new = p_new / s
            c_new = p_new @ w_i  # exact cost consistent with IR
            p_candidates = np.vstack([p_candidates, p_new])
            costs = np.append(costs, c_new)

    # Re-validate rejection constraints for new actions and adjust costs if needed
    if rejected_ix.size > 0:
        rejected_w = contracts[rejected_ix]
        p_w_rej = p_candidates @ rejected_w.T  # (n_actions, #rej)
        for a_idx in range(len(costs)):
            max_rej_util = p_w_rej[a_idx].max()
            if costs[a_idx] < max_rej_util + 1e-9:
                costs[a_idx] = max_rej_util + 1e-4  # safety margin

    # Final normalization of probability distributions
    p_candidates = np.clip(p_candidates, 0, None)
    row_sums = p_candidates.sum(axis=1, keepdims=True)
    row_sums[row_sums < 1e-12] = 1.0
    p_candidates /= row_sums

    costs = np.maximum(costs, 0.0)

    agent_setting = np.hstack([p_candidates, costs[:, None]])
    return agent_setting
```
