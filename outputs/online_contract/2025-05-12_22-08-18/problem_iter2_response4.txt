```python
import numpy as np
from sklearn.cluster import KMeans
from scipy.optimize import linprog

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix from historical contract interactions.

    Parameters:
    - v: Principal reward vector of shape (5,)
    - content: List of dicts, each with keys 'Contract' (list of 5 floats),
               'Principal Utility' (float), 'Agent Action' (1 or -1)

    Returns:
    - agent_setting: n x 6 numpy array where each row represents an action:
        first 5 elements are outcome probabilities (sum to 1),
        last element is agent's cost (>=0) for performing the action.
    """
    m_outcomes = v.shape[0]
    L = len(content)

    # Parse logs into arrays
    contracts = np.array([entry['Contract'] for entry in content])  # (L,5)
    p_utils = np.array([entry['Principal Utility'] for entry in content])  # (L,)
    agent_actions = np.array([entry['Agent Action'] for entry in content])  # (L,)

    accepted_idx = np.where(agent_actions == 1)[0]
    rejected_idx = np.where(agent_actions == -1)[0]

    # If no accepted logs, return trivial uniform action with zero cost
    if len(accepted_idx) == 0:
        p_uniform = np.ones(m_outcomes) / m_outcomes
        return np.hstack([p_uniform, [0.0]]).reshape(1, -1)

    # --- Step 1: Cluster accepted contracts to identify candidate actions ---
    # Use contracts as features for clustering (payments)
    # Choose candidate actions count based on accepted logs diversity
    unique_accept_contracts = np.unique(contracts[accepted_idx], axis=0)
    n_candidates = min(max(2, len(unique_accept_contracts) // 2), 10)
    if n_candidates > len(accepted_idx):
        n_candidates = len(accepted_idx)

    kmeans = KMeans(n_clusters=n_candidates, random_state=42, n_init=15)
    cluster_labels = kmeans.fit_predict(contracts[accepted_idx])
    
    # --- Step 2: For each cluster, solve convex program to find (p,c) ---
    # Variables: p in R^5 (distribution), c >= 0 (cost)
    # Constraints:
    #   sum(p) = 1, p >=0
    #   For all accepted contracts in cluster: agent utility >= 0
    #     i.e. p @ w >= c  =>  -p @ w + c <= 0
    # Objective: minimize c (cost)
    actions = []
    c_var_idx = m_outcomes
    n_vars = m_outcomes + 1  # p (5) + c (1)

    for a in range(n_candidates):
        idxs = accepted_idx[cluster_labels == a]
        W = contracts[idxs]  # (cluster_size, 5)

        # Build LP matrices
        # Equality: sum p_i = 1
        A_eq = np.zeros((1, n_vars))
        A_eq[0, :m_outcomes] = 1
        b_eq = np.array([1.0])

        # Inequality: for each contract i in cluster:
        #   -p @ w_i + c <= 0
        A_ub = np.zeros((len(W), n_vars))
        b_ub = np.zeros(len(W))
        for i, w_i in enumerate(W):
            A_ub[i, :m_outcomes] = -w_i
            A_ub[i, c_var_idx] = 1

        bounds = [(0, 1)] * m_outcomes + [(0, None)]

        c_obj = np.zeros(n_vars)
        c_obj[c_var_idx] = 1  # minimize cost c

        res = linprog(c=c_obj, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq,
                      bounds=bounds, method='highs')

        if res.success:
            p_candidate = res.x[:m_outcomes]
            cost_candidate = res.x[c_var_idx]
        else:
            # fallback: uniform distribution, zero cost (valid but may not explain cluster fully)
            p_candidate = np.ones(m_outcomes) / m_outcomes
            cost_candidate = 0.0

        # Normalize p to sum=1 (numerical safety)
        p_candidate = np.maximum(p_candidate, 0)
        p_candidate /= p_candidate.sum()
        cost_candidate = max(cost_candidate, 0.0)

        actions.append((p_candidate, cost_candidate))

    p_matrix = np.array([p for p, c in actions])  # (n_candidates,5)
    c_vec = np.array([c for p, c in actions])     # (n_candidates,)

    # --- Step 3: Enforce rejection constraints ---
    # For rejected contracts w_j, for all actions a:
    #   p[a] @ w_j - c[a] < 0
    # If violation, increase costs accordingly
    if len(rejected_idx) > 0:
        rej_wages = contracts[rejected_idx]  # (#rej,5)
        utils = p_matrix @ rej_wages.T       # (n_candidates, #rej)

        violations = utils >= c_vec[:, None] - 1e-12  # consider numerical tolerance

        for j in range(violations.shape[1]):
            viol_actions = np.where(violations[:, j])[0]
            if len(viol_actions) == 0:
                continue
            for a_idx in viol_actions:
                required_cost = utils[a_idx, j] + 1e-6  # small margin
                if required_cost > c_vec[a_idx]:
                    c_vec[a_idx] = required_cost

        # Re-check violations after update
        utils_post = p_matrix @ rej_wages.T
        if np.any(utils_post >= c_vec[:, None] - 1e-9):
            # Still violations: add dummy action that rejects all rejected contracts strictly
            p_dummy = np.ones(m_outcomes) / m_outcomes
            # Set cost high enough to ensure negative utility on all rejected contracts
            max_rej_util = (p_dummy @ rej_wages.T).max()
            cost_dummy = max_rej_util + 1e3
            p_matrix = np.vstack([p_matrix, p_dummy])
            c_vec = np.concatenate([c_vec, [cost_dummy]])

    # --- Step 4: Enforce IC and IR for accepted contracts ---
    # Each accepted contract must have at least one action with agent utility >= 0
    # and that action's utility must be >= utilities of other actions to explain choice.

    for i in accepted_idx:
        w_i = contracts[i]
        utilities = p_matrix @ w_i - c_vec  # (n_actions,)
        # Actions with maximal utility
        max_util = np.max(utilities)
        if max_util < -1e-9:
            # No action explains acceptance, add new action exactly explaining it
            # p = normalize w_i (payments) to get distribution over outcomes
            p_new = np.maximum(w_i, 0)
            if p_new.sum() == 0:
                p_new = np.ones(m_outcomes) / m_outcomes
            else:
                p_new /= p_new.sum()
            cost_new = p_new @ w_i  # agent utility = p@w - cost >= 0 => cost <= p@w; minimal cost = p@w
            cost_new = max(cost_new, 0)
            p_matrix = np.vstack([p_matrix, p_new])
            c_vec = np.concatenate([c_vec, [cost_new]])
            utilities = np.append(utilities, max_util)  # for completeness

        # Identify chosen action(s) as those with utilities near max_util
        chosen_actions = np.where(utilities >= max_util - 1e-9)[0]
        # For each chosen action, enforce IC: no other action has greater utility
        for chosen_a in chosen_actions:
            for other_a in range(len(c_vec)):
                if other_a == chosen_a:
                    continue
                diff = utilities[other_a] - utilities[chosen_a]
                if diff > 0:
                    # Increase cost of other_a or decrease cost of chosen_a to fix violation
                    # We'll increase cost of other_a minimally
                    increment = diff + 1e-6
                    c_vec[other_a] = max(c_vec[other_a], p_matrix[other_a] @ w_i + increment)
                    # Recompute utilities after update
                    utilities = p_matrix @ w_i - c_vec

    # Final normalization and clipping
    p_matrix = np.maximum(p_matrix, 0)
    p_matrix /= p_matrix.sum(axis=1, keepdims=True)
    c_vec = np.clip(c_vec, 0, None)

    agent_setting = np.hstack([p_matrix, c_vec[:, None]])

    return agent_setting
```
