```python
import numpy as np
from sklearn.cluster import KMeans
from scipy.optimize import linprog

def agent_solver(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x (5 outcomes + cost)) consistent
    with all historical contracts, utilities, and accept/reject decisions.
    
    Args:
        v: np.ndarray shape (5,), principal's value over 5 outcomes.
        content: List of dicts with keys 'Contract' (list of 5 floats),
                'Principal Utility' (float), and 'Agent Action' (1 or -1).
    
    Returns:
        np.ndarray shape (n_actions, 6) where first 5 cols are outcome
        distributions (sum to 1), last col is cost >= 0 making IR/IC true.
    """
    outcomes = v.shape[0]
    logs = content
    L = len(logs)

    contracts = np.array([log['Contract'] for log in logs])   # shape (L,5)
    p_actions_accept_indices = [i for i, log in enumerate(logs) if log['Agent Action'] == 1]
    p_actions_reject_indices = [i for i, log in enumerate(logs) if log['Agent Action'] == -1]

    # Step 0: Sanity checks, if no rejection logs, still must find an explanation
    # Step 1: Cluster accepted logs' empirical outcome distributions:
    # We must estimate the agent's outcome distribution vectors (p) 
    # For accepted contracts: agent expected utility >= 0,
    # but we don't observe agent utilities directly, only principal utility.
    # 
    # We do know:
    # agent utility = E_p(w) - cost >= 0 if accepted
    # principal utility = E_v[w] - agent cost (0 if rejected)
    #
    # Assume agent chooses actions correlated to contracts, and contracts per action
    # correspond to expected outcomes p @ w = agent expected wage.
    # We try to fit a small set of latent agent actions explaining the data.

    # To handle complexity adaptively we try several candidate action counts:
    max_actions = min(8, len(p_actions_accept_indices)) if p_actions_accept_indices else 1
    if max_actions < 1:
        max_actions = 1

    # Each accepted contract corresponds to a latent action's offering (for agent utility >=0)
    # We'll cluster contract "wage" vectors weighted by principal utility to guess distinct actions
    # Lemon heuristic: cluster contracts weighted by principal utility to guess actions:
    contract_weights = np.array([logs[i]['Principal Utility'] for i in p_actions_accept_indices])
    if np.all(contract_weights == 0):
        contract_weights = np.ones_like(contract_weights)
    contract_feats = contracts[p_actions_accept_indices] * contract_weights[:, None]
    
    if len(contract_feats) < max_actions:
        n_clusters = len(contract_feats)
    else:
        n_clusters = max_actions
    
    if n_clusters < 1:
        n_clusters = 1

    # Cluster contracts by weighted payment vectors to infer latent agent strategies
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20, max_iter=200)
    cluster_ids = kmeans.fit_predict(contract_feats)
    cluster_centers = kmeans.cluster_centers_  # shape (n_clusters, 5)

    # Step 2: Infer outcome distributions p for each latent action
    # For each cluster center wage vector w̄, try to find p (prob dist over 5 outcomes)
    # with constraints:
    #    p >= 0, sum p = 1 (valid pmf)
    # We're trying to relate wage vector w and agent outcome distribution p so that:
    #     p @ v approximates some latent expected value, and 
    #     agent's cost c approx p@w minus agent expected utility >= 0

    # However, from principal utility:
    # principal_utility = p @ v - c >= 0 if contract accepted, 0 else
    # agent utility = p @ w - c >= 0 if accepted, <0 if rejected

    # We estimate p by solving an optimization to fit distribution p s.t. cluster_centers ≈ wage vector
    # because wages ≈ p scaled by agent utility and/or seen payments
    # We'll find p that reconstructs wage vector via non-negative LP with sum(p)=1 minimizing ||p @ v - principal_utility||,
    # but best done with linprog over p:

    # To do this more precisely, for each cluster center wage vector wc:
    #   Find p s.t. wc ≈ p@w_i for payments w_i within cluster or simply treat wc as p*wage average
    # However, wc is sum of payments vector weighted by principal utility; reduce scale by avg principal-utility

    # To avoid overfitting, we adopt direct heuristic: normalize cluster centers into distributions:
    # We impose p ~ cluster_center / sum(cluster_center) if positive, else uniform.
    p_res = []
    for cind in range(n_clusters):
        center = cluster_centers[cind]
        # Normalize nonnegative weights to sum 1
        cpos = np.clip(center, 0, None)
        if cpos.sum() <= 1e-9:
            p_res.append(np.ones(outcomes) / outcomes)
            continue
        p_est = cpos / cpos.sum()
        p_res.append(p_est)
    p_res = np.array(p_res)

    # Step 3: Compute minimal costs c per latent action using all logs for IR and IC
    # IR: agent utility for accepted contracts ≥ 0, so:
    #    c <= p @ w_i for contracts i assigned to that action (choose assignments)
    # IC: for all rejected contracts:
    #    p @ w_j - c < 0  ⇒  c > p @ w_j

    # First: assign accepted logs to closest p action via max expected agent utility
    assigns = np.full(L, -1, dtype=int)
    assigned_contracts_idx = []
    for i in p_actions_accept_indices:
        w = contracts[i]  # wage
        # compute p @ w for each action
        agent_uexp = p_res @ w  # shape (n_clusters,)
        # assign to cluster action with max (agent utility >= 0)
        best_a = np.argmax(agent_uexp)
        # agent utility must be >=0 (accepted)
        if agent_uexp[best_a] < 0:
            # If no cluster explains acceptance, assign to best positive or fallback 0
            pos_candidates = np.where(agent_uexp >= 0)[0]
            if len(pos_candidates) > 0:
                best_a = pos_candidates[np.argmax(agent_uexp[pos_candidates])]
            else:
                best_a = 0
        assigns[i] = best_a
        assigned_contracts_idx.append(i)

    # Next: for each cluster, collect contracts assigned to it:
    costs = np.zeros(n_clusters)
    eps = 1e-7
    for a in range(n_clusters):
        assigned_idx = [i for i, aa in enumerate(assigns) if aa == a]
        if len(assigned_idx) == 0:
            # no data, cost zero (agent cost nonnegative)
            costs[a] = 0.
            continue
        # c <= min_i p @ w_i, agent utility ≥ 0 means cost ≤ expected wage
        p = p_res[a]
        w_assigned = contracts[assigned_idx]  # shape (len,5)
        utils = w_assigned @ p
        costs[a] = max(0., utils.min())  # minimal agent cost consistent with IR

    # Enforce rejection consistency constraints:
    # agent rejects iff max_a [p_a @ w_j - c_a] < 0 for rejected contract j
    for rj in p_actions_reject_indices:
        wrej = contracts[rj]
        rej_util_diff = (p_res @ wrej) - costs
        # Must have max <0 for rejection:
        if rej_util_diff.max() >= 0:
            # To fix, increase costs for violating actions just beyond utilities of rej contract
            violating_actions = np.where(rej_util_diff >= 0)[0]
            for a in violating_actions:
                costs[a] = max(costs[a], (p_res[a] @ wrej) + eps)

    # After fixing costs for rejection, re-check IR for accepted contracts:
    # If any accepted log violates p @ w_i < cost (agent utility < 0), increase cost down to minimal violation
    for i in assigned_contracts_idx:
        a = assigns[i]
        w = contracts[i]
        agent_u = (p_res[a] @ w) - costs[a]
        if agent_u < -eps:
            costs[a] = (p_res[a] @ w)  # push cost down to agent expected wage to fix IR

    # Clip all costs to nonnegative (numerical tolerance)
    costs = np.clip(costs, 0, None) 

    # Normalize p rows to ensure sum to 1 (numerical error)
    p_res = np.clip(p_res, 0, None)
    p_res = p_res / (p_res.sum(axis=1, keepdims=True) + 1e-12)

    agent_setting = np.hstack([p_res, costs[:, None]])
    return agent_setting
```
