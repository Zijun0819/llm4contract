```python
import numpy as np
from sklearn.cluster import AgglomerativeClustering

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix from historical contract interactions,
    tightly fitting accepted contracts via adaptive clustering with weighted centroids,
    iteratively refining costs to enforce IR, IC, and rejection constraints,
    adding dummy actions for unexplained accepted contracts,
    and ensuring proper probability normalization and non-negative costs.

    Parameters:
    - v: Principal reward vector of shape (5,)
    - content: List of dicts, each with keys 'Contract' (list of 5 floats),
               'Principal Utility' (float), 'Agent Action' (1 or -1)

    Returns:
    - agent_setting: n x 6 numpy array where each row represents an action:
        first 5 elements are outcome probabilities (sum to 1),
        last element is agent's cost (>=0) for performing the action.
    """
    m_outcomes = v.size
    L = len(content)
    if L == 0:
        # No data: return trivial uniform action with zero cost
        p_uniform = np.ones(m_outcomes) / m_outcomes
        return np.hstack([p_uniform, [0.0]]).reshape(1, -1)

    contracts = np.array([log['Contract'] for log in content], dtype=np.float64)  # (L,5)
    ag_actions = np.array([log['Agent Action'] for log in content], dtype=int)    # (L,)
    p_utils = np.array([log['Principal Utility'] for log in content], dtype=np.float64)  # (L,)

    accepted_ix = np.where(ag_actions == 1)[0]
    rejected_ix = np.where(ag_actions == -1)[0]

    # If no accepted contracts, return trivial uniform action with zero cost
    if accepted_ix.size == 0:
        p_uniform = np.ones(m_outcomes) / m_outcomes
        return np.hstack([p_uniform, [0.0]]).reshape(1, -1)

    accepted_w = contracts[accepted_ix]  # (num_accept, 5)
    accepted_pu = p_utils[accepted_ix]   # (num_accept,)

    # Normalize accepted contracts for clustering to avoid scale issues
    row_sums = accepted_w.sum(axis=1, keepdims=True)
    row_sums[row_sums < 1e-12] = 1.0
    norm_w = accepted_w / row_sums  # (num_accept,5)

    # Adaptive maximum clusters: min(10, #accepted, max(1, int(sqrt(#accepted))))
    max_clusters = min(10, len(accepted_ix), max(1, int(np.sqrt(len(accepted_ix)))))

    def cluster_and_get_centroids(n_clusters: int) -> np.ndarray:
        # Cluster normalized contracts and return weighted centroids (prob vectors)
        if n_clusters == 1:
            # Single cluster: weighted average of all accepted contracts
            weights = accepted_pu - accepted_pu.min() + 1  # positive weights
            avg_w = np.average(accepted_w, axis=0, weights=weights)
            p = np.clip(avg_w, 0, None)
            s = p.sum()
            if s < 1e-12:
                p = np.ones(m_outcomes) / m_outcomes
            else:
                p /= s
            return p.reshape(1, -1)

        clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='average')
        labels = clustering.fit_predict(norm_w)
        p_list = []
        for c in range(n_clusters):
            cluster_idx = np.where(labels == c)[0]
            if cluster_idx.size == 0:
                continue
            cluster_w = accepted_w[cluster_idx]
            cluster_pu = accepted_pu[cluster_idx]
            weights = cluster_pu - cluster_pu.min() + 1  # positive
            avg_w = np.average(cluster_w, axis=0, weights=weights)
            p = np.clip(avg_w, 0, None)
            s = p.sum()
            if s < 1e-12:
                p = np.ones(m_outcomes) / m_outcomes
            else:
                p /= s
            p_list.append(p)
        if len(p_list) == 0:
            # fallback uniform
            p_list = [np.ones(m_outcomes) / m_outcomes]
        return np.array(p_list)

    # Try clusters from max_clusters down to 1 to find stable parsimonious model
    prev_p_candidates = None
    chosen_p_candidates = None
    for nc in reversed(range(1, max_clusters + 1)):
        p_candidates = cluster_and_get_centroids(nc)
        if prev_p_candidates is not None and p_candidates.shape[0] == prev_p_candidates.shape[0]:
            # Measure average min distance between old and new clusters (for stability)
            dists = []
            for p_old in prev_p_candidates:
                dists.append(np.min(np.linalg.norm(p_candidates - p_old, axis=1)))
            avg_dist = np.mean(dists)
            if avg_dist < 1e-2:  # threshold for stability
                chosen_p_candidates = p_candidates
                break
        prev_p_candidates = p_candidates
    if chosen_p_candidates is None:
        chosen_p_candidates = prev_p_candidates
    p_candidates = chosen_p_candidates
    n_actions = p_candidates.shape[0]

    # Compute costs lower bounds from accepted contracts:
    # For each action p: cost <= min_i p @ w_i where w_i accepted contracts rationalized by p
    # Approximate by min p @ w_i over all accepted contracts to ensure IR
    costs_lower_bound = np.full(n_actions, np.inf)
    for a_idx, p in enumerate(p_candidates):
        p_dot_w = accepted_w @ p
        # Use contracts with p @ w >= costs_lower_bound[a_idx] as rationalized by this action
        # To be conservative, take min over all accepted contracts
        costs_lower_bound[a_idx] = np.min(p @ accepted_w.T)

    # Handle rejected contracts: costs must be > p @ w for all rejected contracts
    if rejected_ix.size > 0:
        rejected_w = contracts[rejected_ix]  # (#rej, 5)
        p_w_rej = p_candidates @ rejected_w.T  # (n_actions, #rej)
        c_rej_min = p_w_rej.max(axis=1) + 1e-6  # small margin
    else:
        c_rej_min = np.zeros(n_actions, dtype=np.float64)

    # Initial costs: max of lower bounds and rejection requirements, and non-negative
    costs = np.maximum(costs_lower_bound, c_rej_min)
    costs = np.maximum(costs, 0.0)

    # Check if accepted contracts are rationalized by some action (IR)
    def is_rationalized(w_i: np.ndarray, eps=1e-8) -> bool:
        for p, c in zip(p_candidates, costs):
            if (p @ w_i) - c >= -eps:
                return True
        return False

    unexplained_accepts_ix = [i for i in accepted_ix if not is_rationalized(contracts[i])]

    # Add dummy actions for unexplained accepted contracts
    for i in unexplained_accepts_ix:
        w_i = contracts[i]
        p_new = np.clip(w_i, 0, None)
        s = p_new.sum()
        if s < 1e-12:
            p_new = np.ones(m_outcomes) / m_outcomes
        else:
            p_new /= s
        cost_new = p_new @ w_i  # cost = expected payment, so utility zero
        p_candidates = np.vstack([p_candidates, p_new])
        costs = np.append(costs, cost_new)

    # Iteratively refine costs to enforce rejection constraints strictly
    max_iter = 30
    tol = 1e-8
    rejected_w = contracts[rejected_ix] if rejected_ix.size > 0 else None

    for _ in range(max_iter):
        prev_costs = costs.copy()
        if rejected_w is not None and costs.size > 0:
            p_w_rej = p_candidates @ rejected_w.T  # (n_actions, #rej)
            for a in range(len(costs)):
                max_rej_util = p_w_rej[a].max()
                if costs[a] < max_rej_util + 1e-7:
                    costs[a] = max_rej_util + 1e-5  # push cost above max rejection utility margin

        # Enforce costs >= costs_lower_bound (IR)
        costs = np.maximum(costs, 0)
        # Since costs_lower_bound was computed before dummy actions added, recompute for all actions:
        for a_idx, p in enumerate(p_candidates):
            # minimal cost to explain at least one accepted contract >=0
            accepted_utils = accepted_w @ p
            costs[a_idx] = max(costs[a_idx], accepted_utils.min())

        # Check convergence
        max_diff = np.max(np.abs(costs - prev_costs))
        if max_diff < tol:
            break

    # IC enforcement: For each accepted contract, ensure no other action yields strictly higher agent utility
    accepted_w = contracts[accepted_ix]  # reaffirm
    for idx in accepted_ix:
        w_i = contracts[idx]
        utilities = p_candidates @ w_i - costs  # (n_actions,)
        max_util = np.max(utilities)
        chosen_actions = np.where(utilities >= max_util - 1e-9)[0]

        for chosen_a in chosen_actions:
            for other_a in range(len(costs)):
                if other_a == chosen_a:
                    continue
                diff = utilities[other_a] - utilities[chosen_a]
                if diff > 0:  # violation of IC
                    # Increase cost of other action minimally to fix IC
                    required_cost = p_candidates[other_a] @ w_i + diff + 1e-6
                    if required_cost > costs[other_a]:
                        costs[other_a] = required_cost
                        # Update utility of other action
                        utilities[other_a] = p_candidates[other_a] @ w_i - costs[other_a]

    # Ensure all probability vectors are valid distributions
    p_candidates = np.clip(p_candidates, 0, None)
    row_sums = p_candidates.sum(axis=1, keepdims=True)
    row_sums[row_sums < 1e-12] = 1.0
    p_candidates /= row_sums

    costs = np.clip(costs, 0, None)

    agent_setting = np.hstack([p_candidates, costs[:, None]])
    return agent_setting
```
