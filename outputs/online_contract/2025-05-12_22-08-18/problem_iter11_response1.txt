```python
import numpy as np
from sklearn.cluster import AgglomerativeClustering
from scipy.optimize import linprog

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Enhanced agent setting inference consistent with historical logs,
    enforcing global IR/IC constraints via LP, adaptive clustering weighted 
    by principal utility variance, minimal dummy actions for unexplained accepts,
    iterative cost refinement, and strict probability normalization.

    Params:
        v (np.ndarray): Principal's value vector (length 5)
        content (list[dict]): each dict has keys: 'Contract' (list of 5),
                              'Principal Utility' (float),
                              'Agent Action' (1 or -1)

    Returns:
        np.ndarray: n_actions x 6 (5 probabilities + 1 cost)
    """
    m_outcomes = v.size
    L = len(content)

    # Extract arrays
    contracts = np.array([log['Contract'] for log in content])  # (L,5)
    ag_actions = np.array([log['Agent Action'] for log in content])  # (L,)
    p_util = np.array([log['Principal Utility'] for log in content])  # (L,)

    accepted_ix = np.where(ag_actions == 1)[0]
    rejected_ix = np.where(ag_actions == -1)[0]

    # Return trivial uniform action with zero cost if no accepted contracts
    if accepted_ix.size == 0:
        uniform_p = np.ones(m_outcomes) / m_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.zeros((1, 1))])

    accepted_w = contracts[accepted_ix]

    # Normalize contracts to probability simplex for clustering (avoid zero-sum issues)
    norm_w = accepted_w / (accepted_w.sum(axis=1, keepdims=True) + 1e-12)

    # Adaptive number of clusters: min(10, #accepted, max(1, sqrt(#accepted)))
    n_max_actions = max(1, min(10, int(np.sqrt(len(accepted_ix))), len(accepted_ix)))

    # Weight clustering by inverse variance of principal utilities in clusters to focus on consistent contracts:
    # First cluster with uniform weights to get initial labels
    clustering_init = AgglomerativeClustering(n_clusters=n_max_actions, linkage='average')
    init_labels = clustering_init.fit_predict(norm_w)

    # Compute variance per cluster and define refined weights as inverse variance + 1
    cluster_vars = []
    for c in range(n_max_actions):
        cluster_idx = accepted_ix[init_labels == c]
        if cluster_idx.size == 0:
            cluster_vars.append(1.0)
            continue
        var = np.var(p_util[cluster_idx])
        cluster_vars.append(var)
    cluster_vars = np.array(cluster_vars)
    inv_var_weights = 1.0 / (cluster_vars + 1e-4)  # avoid div zero
    inv_var_weights = inv_var_weights / inv_var_weights.sum()

    # Compute weighted centroids per cluster weighted by principal utilities and inverse variance weight
    p_candidates = []
    costs_lb = []

    for c in range(n_max_actions):
        cluster_idx = accepted_ix[init_labels == c]
        if cluster_idx.size == 0:
            continue
        cluster_w = contracts[cluster_idx]

        # Weight accepted contracts by (p_util - min) + 1 to keep positivity and multiply by inverse variance weight
        util_weights = p_util[cluster_idx] - p_util[cluster_idx].min() + 1
        util_weights = util_weights * inv_var_weights[c]
        # Normalize util_weights to sum to 1 for weighted average
        util_weights_sum = util_weights.sum()
        if util_weights_sum < 1e-12:
            util_weights = np.ones_like(util_weights) / len(util_weights)
        else:
            util_weights = util_weights / util_weights_sum

        avg_w = np.average(cluster_w, axis=0, weights=util_weights)

        # Project to simplex (clip negatives and renormalize)
        p = np.clip(avg_w, 0, None)
        if p.sum() < 1e-12:
            p = np.ones(m_outcomes) / m_outcomes
        else:
            p = p / p.sum()
        p_candidates.append(p)

        # Cost lower bound from accepted contracts: cost <= p@w_i (utility >=0)
        costs_cluster = np.array([p @ contracts[i] for i in cluster_idx])
        min_cost = costs_cluster.min()
        costs_lb.append(min_cost)

    p_candidates = np.array(p_candidates)
    costs_lb = np.array(costs_lb)

    # Handle rejected contracts constraints: cost > max_r p@w_r for all actions a
    if rejected_ix.size > 0:
        reject_contracts = contracts[rejected_ix]
        p_w_rej = p_candidates @ reject_contracts.T  # shape (n_actions, n_rejected)
        c_rej_min = p_w_rej.max(axis=1) + 1e-6
    else:
        c_rej_min = np.zeros(len(p_candidates))

    # Initial costs satisfying both accepted and rejected constraints
    costs = np.maximum(costs_lb, c_rej_min)
    costs = np.maximum(costs, 0)

    # Define helper to check if an action rationalizes an accepted contract (utility >=0)
    def valid_action_for_contract(w_i):
        for a, (p, c) in enumerate(zip(p_candidates, costs)):
            util = p @ w_i - c
            if util >= -1e-8:
                return a
        return None

    # Add minimal dummy actions exactly matching unexplained accepted contracts
    for i in accepted_ix:
        w_i = contracts[i]
        if valid_action_for_contract(w_i) is None:
            p_new = np.clip(w_i, 0, None)
            if p_new.sum() < 1e-12:
                p_new = np.ones(m_outcomes) / m_outcomes
            else:
                p_new = p_new / p_new.sum()
            c_new = p_new @ w_i
            p_candidates = np.vstack([p_candidates, p_new])
            costs = np.append(costs, c_new)

    # Re-check rejection constraints after adding new actions and adjust costs if needed
    if rejected_ix.size > 0:
        reject_contracts = contracts[rejected_ix]
        p_w_rej = p_candidates @ reject_contracts.T  # shape (n_actions, n_rejected)
        for a in range(len(p_candidates)):
            max_rej_util = p_w_rej[a].max()
            # Add strict margin to separate rejections
            if costs[a] < max_rej_util + 1e-8:
                costs[a] = max_rej_util + 1e-4

    # Global IR/IC constraints enforcement via LP formulation:
    # Variables: costs vector c_a (costs per action)
    # Constraints:
    # - For each rejected contract r and action a: c_a >= p_a @ w_r + epsilon
    # - costs >= 0
    # We rely on previously added dummy actions to cover acceptance constraints.

    n_actions = len(p_candidates)
    c_obj = np.zeros(n_actions)  # minimize zero objective: feasibility problem

    epsilon = 1e-5
    A_ub = []
    b_ub = []

    # Construct inequalities for rejected contracts: -c_a <= - (p_a @ w_r + epsilon)
    if rejected_ix.size > 0:
        for a in range(n_actions):
            for r in rejected_ix:
                val = p_candidates[a] @ contracts[r] + epsilon
                row = np.zeros(n_actions)
                row[a] = -1
                A_ub.append(row)
                b_ub.append(-val)
    if len(A_ub) > 0:
        A_ub = np.vstack(A_ub)
        b_ub = np.array(b_ub)
    else:
        A_ub, b_ub = None, None

    bounds = [(0, None)] * n_actions  # costs >= 0

    # Solve LP to find feasible costs respecting rejection constraints
    if A_ub is not None:
        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')
        if res.success:
            costs = res.x
        # else fallback to previous costs; hopefully feasible due to adjustments

    # Final probability normalization ensuring strict simplex constraints
    p_candidates = np.clip(p_candidates, 0, None)
    p_sums = p_candidates.sum(axis=1, keepdims=True)
    p_sums[p_sums < 1e-12] = 1.0
    p_candidates /= p_sums

    # Compose final agent setting matrix n_actions x (5 + 1)
    agent_setting = np.hstack([p_candidates, costs[:, None]])

    return agent_setting
```
