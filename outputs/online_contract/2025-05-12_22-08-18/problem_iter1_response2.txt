```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import KMeans


def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer an agent's setting matrix (actions) that rationalizes all historical interactions.
    Each action: a distribution over 5 outcomes + cost >= 0.
    Constraints:
        - Accepted contracts yield agent utility >= 0 for some action.
        - Rejected contracts yield agent utility < 0 for all actions.
    Strategy:
        1) Extract accepted logs, cluster contract-outcome mappings by estimated best action.
        2) For each cluster, solve an LP to find a feasible p (outcome distribution) and minimal cost satisfying accepted logs assigned there.
        3) Add candidate actions (clusters).
        4) Adjust costs to enforce rejection constraints: for rejected logs, no action yields utility >= 0.
        5) If necessary, add "dummy" actions to cover rejections.
    """
    m_outcomes = v.shape[0]
    L = len(content)

    # Extract contracts, utilities, and actions arrays for convenience
    contracts = np.array([log['Contract'] for log in content])  # shape (L,5)
    p_utils = np.array([log['Principal Utility'] for log in content])  # shape (L,)
    agent_actions = np.array([log['Agent Action'] for log in content])  # shape (L,)

    # 1) Use accepted logs to estimate number of behaviors (actions)
    accepted_idx = np.where(agent_actions == 1)[0]
    rejected_idx = np.where(agent_actions == -1)[0]

    if len(accepted_idx) == 0:
        # No acceptance data: return a trivial action (uniform dist, zero cost)
        p_uniform = np.ones(m_outcomes) / m_outcomes
        return np.hstack([p_uniform, [0.0]]).reshape(1, -1)

    accepted_contracts = contracts[accepted_idx]  # (acc_count, 5)

    # 2) Cluster contracts weighted by outcomes (to group similar agent choices)
    # Intuition: agent chooses actions that maximize expected wage - cost,
    # so cluster accepted contracts by their payout patterns to identify underlying actions.
    n_candidates = min(7, len(accepted_idx))  # do not exceed accepted logs count
    kmeans = KMeans(n_clusters=n_candidates, random_state=0, n_init=20)
    cluster_labels = kmeans.fit_predict(accepted_contracts)

    # 3) For each cluster, solve LP to find feasible (p, cost):
    # Variables: p_i for i=1..5, cost c
    # Constraints:
    #  - sum p_i = 1
    #  - p_i >= 0
    #  - For all accepted contracts in cluster: p @ wage >= cost (agent utility >= 0)
    # Objective: minimize cost (agent cost >= 0)
    actions = []
    for a in range(n_candidates):
        idxs = accepted_idx[cluster_labels == a]
        W = contracts[idxs]  # wages matrix (n_cluster, 5)

        # LP: minimize c s.t
        # sum p_i =1, p_i≥0
        # For each accepted contract: p @ w_i ≥ c
        # Variable vector x = [p_0, p_1, ..., p_4, c]
        # Constraints:
        #   Equality: sum_{i=0}^4 p_i = 1
        #   Inequality: for each i, p·w_i - c ≥ 0  => -p·w_i + c ≤ 0

        c_var_idx = 5
        n_vars = 6

        # Build constraint matrices
        A_eq = np.zeros((1, n_vars))
        A_eq[0, :5] = 1  # sum p_i =1
        b_eq = np.array([1.])

        A_ub = np.zeros((len(W), n_vars))
        b_ub = np.zeros(len(W))

        for j, w_i in enumerate(W):
            A_ub[j, :5] = -w_i   # -p·w_i
            A_ub[j, c_var_idx] = 1  # +c
            b_ub[j] = 0            # ≤0

        bounds = [(0, 1)]*5 + [(0, None)]  # p_i in [0,1], c≥0

        # Objective: minimize c == minimize x[5]
        c_obj = np.zeros(n_vars)
        c_obj[c_var_idx] = 1

        # Run linprog
        res = linprog(c=c_obj, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq,
                      bounds=bounds, method='highs')

        if not res.success:
            # fallback: uniform p and cost zero - doesn't rationalize cluster fully,
            # but still a valid action
            p_candidate = np.ones(m_outcomes)/m_outcomes
            cost_candidate = 0.0
        else:
            p_candidate, cost_candidate = res.x[:5], res.x[5]

        # normalize p to avoid numerical issues (very close to 1 from linprog)
        p_candidate /= p_candidate.sum()
        cost_candidate = max(cost_candidate, 0.0)  # ensure non-neg cost

        actions.append((p_candidate, cost_candidate))

    # Convert to arrays
    p_matrix = np.array([p for p, c in actions])  # (n_candidates,5)
    c_vec = np.array([c for p, c in actions])     # (n_candidates,)

    # 4) Check reject logs: no action should give agent utility >=0 on rejected contracts
    # i.e. for each rejected contract j and action a:
    #    p[a] @ wage_j < c[a]
    if len(rejected_idx) > 0:
        rej_wages = contracts[rejected_idx]  # (#rej,5)
        # Calculate utilities: (n_candidates, #rej)
        utils = p_matrix @ rej_wages.T  # shape (n_candidates, #rej)

        # We require: utils[:,j] < c_vec for all j
        # Check violations:
        violations = utils >= c_vec[:, None]  # bool matrix shape (n_candidates, #rej)

        for j in range(violations.shape[1]):
            viol_actions = np.where(violations[:, j])[0]
            if len(viol_actions) == 0:
                # no violation for this rejected contract, ok
                continue

            # For each violating action, need to increase cost (strictly)
            # Let's increase slightly over utility for rejected contract to make them strictly negative utility
            for a_idx in viol_actions:
                required_cost = utils[a_idx, j] + 1e-6  # small margin
                if required_cost > c_vec[a_idx]:
                    c_vec[a_idx] = required_cost

        # Now re-check no violation remains; if still violation, it could be numerical
        utils_post = p_matrix @ rej_wages.T
        if np.any(utils_post >= c_vec[:, None] - 1e-9):
            # If still violation occurs, add one dummy action that rejects all rejected contracts strictly
            # Its p can be any distribution; just pick uniform.
            # Cost set high to make agent utility negative on rejected contracts.
            p_dummy = np.ones(m_outcomes)/m_outcomes
            cost_dummy = 1e9
            p_matrix = np.vstack([p_matrix, p_dummy])
            c_vec = np.concatenate([c_vec, [cost_dummy]])

    # 5) Final: Ensure that for each accepted contract, there is at least one action with agent utility ≥0, else fix minimal cost for acceptance
    for i in accepted_idx:
        wage_i = contracts[i]
        u_i = agent_actions[i]
        if u_i != 1:
            continue  # skip non-accepted

        utils_i = p_matrix @ wage_i  # shape (n_actions,)
        # Agent utility = utils_i - cost_vec

        utilities = utils_i - c_vec
        if (utilities >= -1e-9).any():
            # ok, accepted contract is explained
            continue
        else:
            # no action explains acceptance: add a new action to explain it exactly
            p_new = wage_i / wage_i.sum()
            c_new = np.min(utils_i)
            # but ensure c_new ≤ corresponding utility
            c_new = min(c_new, np.min(utils_i))  # just pick min of utils_i (often equals it)
            if c_new < 0:
                c_new = 0  # cost can't be negative

            p_matrix = np.vstack([p_matrix, p_new])
            c_vec = np.concatenate([c_vec, [c_new]])

    # Assemble final matrix shape (n_actions, 6)
    agent_setting = np.hstack([p_matrix, c_vec[:, None]])

    # Normalize p rows in case of minor numeric issues
    agent_setting[:, :m_outcomes] /= agent_setting[:, :m_outcomes].sum(axis=1, keepdims=True)

    # Clip costs to nonnegative
    agent_setting[:, -1] = np.clip(agent_setting[:, -1], 0, None)

    return agent_setting
```
