```python
import numpy as np
from sklearn.cluster import AgglomerativeClustering

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting (actions = distributions + cost)
    consistent with historical contract logs (IR, IC, rejection constraints),
    improving clustering adaptivity, cost bounds, and minimal dummy actions.

    Params:
        v (np.ndarray): Principal's value vector (length 5)
        content (list[dict]): each dict has keys: 'Contract' (list of 5),
                              'Principal Utility' (float),
                              'Agent Action' (1 or -1)
    Returns:
        np.ndarray: n_actions x 6 (5 probabilities + 1 cost)
    """
    m_outcomes = v.size
    L = len(content)

    # Extract arrays
    contracts = np.array([log['Contract'] for log in content])  # (L,5)
    ag_actions = np.array([log['Agent Action'] for log in content])  # (L,)
    p_util = np.array([log['Principal Utility'] for log in content])  # (L,)

    accepted_ix = np.where(ag_actions == 1)[0]
    rejected_ix = np.where(ag_actions == -1)[0]

    # If no accepted contracts, return trivial uniform action with zero cost
    if accepted_ix.size == 0:
        p_uniform = np.ones(m_outcomes) / m_outcomes
        return np.hstack([p_uniform.reshape(1, -1), np.array([[0.0]])])

    accepted_w = contracts[accepted_ix]
    accepted_util = p_util[accepted_ix]

    # Normalize accepted contracts for clustering (avoid zero-sum issues)
    norm_w = accepted_w / (accepted_w.sum(axis=1, keepdims=True) + 1e-12)

    n_accepted = len(accepted_ix)
    # Adaptive cluster count: min(10, sqrt(#accepted), #accepted), at least 1
    n_clusters = max(1, min(10, int(np.sqrt(n_accepted)), n_accepted))

    if n_clusters > 1:
        clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='average')
        labels = clustering.fit_predict(norm_w)
    else:
        labels = np.zeros(n_accepted, dtype=int)

    p_candidates = []
    costs_lower_bound = []

    # For each cluster, compute robust p and tighten cost lower bound
    for c in range(n_clusters):
        cluster_idx = accepted_ix[labels == c]
        if cluster_idx.size == 0:
            continue
        cluster_w = contracts[cluster_idx]
        cluster_util = accepted_util[labels == c]

        # Weight by shifted utilities to favor better contracts
        min_util = cluster_util.min()
        weights = cluster_util - min_util + 1.0
        weights_sum = weights.sum()
        if weights_sum < 1e-12:
            weights = np.ones_like(weights)
            weights_sum = weights.sum()
        weights = weights / weights_sum

        # Weighted average contract vector (not necessarily sum=1)
        avg_w = np.average(cluster_w, axis=0, weights=weights)

        # Project average to simplex: clip negatives and re-normalize
        p = np.clip(avg_w, 0, None)
        p_sum = p.sum()
        if p_sum < 1e-12:
            p = np.ones(m_outcomes) / m_outcomes
        else:
            p /= p_sum
        p_candidates.append(p)

        # Cost lower bound = min_{accepted contracts in cluster} p @ w_i
        costs_cluster = np.array([p @ w_i for w_i in cluster_w])
        cost_lb = costs_cluster.min()
        costs_lower_bound.append(cost_lb)

    p_candidates = np.array(p_candidates)
    costs_lower_bound = np.array(costs_lower_bound)

    # Handle rejected contracts: agent utility < 0 for all actions
    if rejected_ix.size > 0:
        reject_w = contracts[rejected_ix]  # (#rej,5)
        # Compute (p_a @ w_r) for all actions a and rejected contracts r: (n_actions, #rej)
        p_w_rej = p_candidates @ reject_w.T
        # Cost must be strictly > max rejected p_a @ w_r to guarantee rejection
        c_rej_min = p_w_rej.max(axis=1) + 1e-7  # small margin
    else:
        c_rej_min = np.zeros(len(p_candidates))

    # Final cost lower bound = max(accepted IR lower bound, rejection lower bound), clipped at 0
    costs = np.maximum(costs_lower_bound, c_rej_min)
    costs = np.maximum(costs, 0)

    # Check if contract w_i is rationalized by some (p, cost) action
    def valid_action_for_contract(w_i):
        utilities = p_candidates @ w_i - costs
        valid = np.where(utilities >= -1e-9)[0]
        return valid[0] if valid.size > 0 else None

    # Add minimal dummy actions for any accepted contracts unexplained
    # Collect unexplained indices first
    unexplained_ix = []
    for i in accepted_ix:
        if valid_action_for_contract(contracts[i]) is None:
            unexplained_ix.append(i)

    if unexplained_ix:
        unexplained_w = contracts[unexplained_ix]
        n_unexplained = len(unexplained_ix)
        # Cluster unexplained contracts to at most 3 clusters or fewer if less samples
        n_dummy = min(3, n_unexplained)
        if n_dummy > 1:
            norm_unexplained = unexplained_w / (unexplained_w.sum(axis=1, keepdims=True) + 1e-12)
            dummy_labels = AgglomerativeClustering(n_clusters=n_dummy, linkage='average').fit_predict(norm_unexplained)
        else:
            dummy_labels = np.zeros(n_unexplained, dtype=int)

        for c in range(n_dummy):
            cluster_w = unexplained_w[dummy_labels == c]
            if cluster_w.shape[0] == 0:
                continue
            # Average contract vector for dummy action
            p_new = np.clip(cluster_w.mean(axis=0), 0, None)
            s = p_new.sum()
            if s < 1e-12:
                p_new = np.ones(m_outcomes) / m_outcomes
            else:
                p_new /= s
            # Cost: minimal p_new @ w_i over cluster (IR)
            costs_candidate = np.array([p_new @ w_i for w_i in cluster_w])
            c_new = costs_candidate.min()
            p_candidates = np.vstack([p_candidates, p_new])
            costs = np.append(costs, c_new)

    # Re-validate rejection constraints and increase costs if needed
    if rejected_ix.size > 0:
        reject_w = contracts[rejected_ix]
        p_w_rej = p_candidates @ reject_w.T
        for a in range(len(p_candidates)):
            max_rej_util = p_w_rej[a].max()
            if costs[a] < max_rej_util + 1e-9:
                costs[a] = max_rej_util + 1e-4  # safety margin

    # Final normalization on p_candidates to ensure proper probabilities
    p_candidates = np.clip(p_candidates, 0, None)
    psums = p_candidates.sum(axis=1, keepdims=True)
    psums[psums < 1e-12] = 1.0
    p_candidates /= psums

    # Ensure nonnegative costs
    costs = np.maximum(costs, 0)

    # Assemble final agent setting matrix: probabilities + cost column
    agent_setting = np.hstack([p_candidates, costs[:, None]])

    return agent_setting
```
