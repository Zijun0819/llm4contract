```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import AgglomerativeClustering

def agent_solver_v2(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    """
    Infer a valid agent setting from historical data logs.
    This version adaptively selects the number of actions (clusters) 
    and explicitly enforces both IR and IC constraints via LP.

    Returns:
        agent_setting: n_actions x 6 array, where columns 0-4 are outcome probabilities,
                       column 5 is action cost.
    """
    m_outcomes = v.shape[0]
    logs = content.copy()

    # Extract contracts, utilities, agent actions as arrays for vectorization
    contracts = np.vstack(logs['Contract'].values)  # shape=(N,5)
    principal_utils = np.array(logs['Principal Utility'])
    agent_actions = np.array(logs['Agent Action'])

    # Separate indices by acceptance and rejection
    accept_idx = np.where(agent_actions == 1)[0]
    reject_idx = np.where(agent_actions == -1)[0]

    # Step 1: Generate candidate outcome distributions from accepted logs by LP fitting p
    # For accepted contracts, solve for p: p @ w = agent utility + cost, unknown cost
    # The idea: p has sum=1 and nonnegative. We initially guess cost=0 and get rough p.
    candidate_ps = []
    for i in accept_idx:
        w = contracts[i]
        # Try to find p such that p @ w ~= agent utility + cost, cost unknown nonnegative
        # Since cost unknown, relax p @ w >= cost => p @ w arbitrary,
        # Instead, find p matching principal utility scaled proxy:
        # Use p @ w ~ principal utility + offset to approximate outcome prob
        # Here approximate p by maximizing w-values since p unknown; simpler: use w normalized
        # Alternatively fit closest p to w profile:
        # We do an LP: min ||p - w/||w||_1|| but easier to just normalize w as proxy:
        p = np.clip(w, 0, None)
        if p.sum() == 0:
            p = np.ones(m_outcomes) / m_outcomes
        else:
            p = p / p.sum()
        candidate_ps.append(p)
    candidate_ps = np.array(candidate_ps)

    if candidate_ps.shape[0] == 0:
        # No accepted contracts to infer; fallback to uniform distribution, zero cost
        return np.hstack([np.ones((1, m_outcomes))/m_outcomes, np.zeros((1,1))])

    # Step 2: Adaptive clustering of candidate_ps to find distinct actions
    # Use hierarchical clustering, cut by max distance or max 10 clusters
    max_clusters = min(10, len(candidate_ps))
    # Using Agglomerative clustering to generate clusters
    def cluster_and_get_centers(k):
        clusterer = AgglomerativeClustering(n_clusters=k)
        labels = clusterer.fit_predict(candidate_ps)
        centers = np.array([candidate_ps[labels == i].mean(axis=0) for i in range(k)])
        centers = np.clip(centers, 1e-8, None)
        centers = (centers.T / centers.sum(axis=1)).T
        return labels, centers

    # Evaluate Silhouette-like heuristic for k=2 to max_clusters (skip 1 because too trivial)
    def cluster_quality(k):
        try:
            labels, centers = cluster_and_get_centers(k)
            intra_dists = np.zeros(k)
            counts = np.zeros(k)
            for i in range(len(candidate_ps)):
                c = centers[labels[i]]
                intra_dists[labels[i]] += np.linalg.norm(candidate_ps[i] - c)
                counts[labels[i]] += 1
            avg_dists = intra_dists / np.maximum(1, counts)
            score = -avg_dists.mean()  # more negative means closer tight clusters
            return score
        except Exception:
            return -np.inf

    scores = [cluster_quality(k) for k in range(2, max_clusters+1)]
    best_k = np.argmax(scores) + 2
    labels, p_actions = cluster_and_get_centers(best_k)

    n_actions = best_k

    # Step 3: Associate accepted logs to best action by maximal expected wage
    assigns = -np.ones(len(logs), dtype=int)
    for i in accept_idx:
        w = contracts[i]
        # Choose action a maximizing p_actions[a] @ w
        ev = p_actions @ w
        assigns[i] = int(np.argmax(ev))

    # Step 4: Infer minimal nonnegative costs c for each action satisfying IR and IC constraints:
    #
    # Let c = costs vector shape(n_actions,)
    # Constraints:
    #   For accepted logs i:
    #       p_actions[assigns[i]] @ contracts[i] - c[assigns[i]] >= 0  (IR)
    #
    #   For all logs j and all actions a:
    #       p_actions[a] @ contracts[j] - c[a] <= p_actions[assigns[j]] @ contracts[j] - c[assigns[j]]   (IC)
    #
    #   with c >= 0

    # Build constraints matrix for LP
    # Variables: c (n_actions,), shape=(n_actions,)
    # For IR: p_action[a_i] @ contract_i - c[a_i] >= 0  => -c[a_i] >= -p_action[a_i]@contract_i
    #   Transformed: (-1 at c[a_i], 0 elsewhere) <= -p@contract_i
    # For IC: p@contract_j - c[a] <= p@[assigned action at j]@contract_j - c[assigned[j]]
    #         => c[a] - c[assigned[j]] >= p_actions[a]@contract_j - p_actions[assigned[j]]@contract_j
    #   Constraint per j,a: (coefficients all 0 except c[a]=1, c[assigned[j]] = -1) >= RHS

    # Construct IR constraints
    IR_A = np.zeros((len(accept_idx), n_actions))
    IR_b = np.zeros(len(accept_idx))
    for rowidx, i in enumerate(accept_idx):
        a_i = assigns[i]
        IR_A[rowidx, a_i] = -1
        IR_b[rowidx] = - (p_actions[a_i] @ contracts[i])

    # Construct IC constraints
    IC_A = []
    IC_b = []

    for j in range(len(logs)):
        a_j = assigns[j]
        if a_j == -1:
            # Non-accepted logs: set a_j to None means rejection: IR utility < 0, assigned action invalid acting as rejection
            # Model rejection as action with cost large, but here let's skip IC constraints involving unassigned.
            continue
        p_aj = p_actions[a_j]
        wj = contracts[j]
        for a in range(n_actions):
            lhs = np.zeros(n_actions)
            lhs[a] = 1
            lhs[a_j] = -1
            rhs = (p_actions[a].dot(wj) - p_aj.dot(wj))
            IC_A.append(lhs)
            IC_b.append(rhs)
    IC_A = np.array(IC_A)
    IC_b = np.array(IC_b)

    # Bounds for costs: c>=0
    bounds = [(0, None)] * n_actions

    # Solve LP: maximize sum of costs to avoid trivial zero solution (or just feasibility)
    c_obj = -np.ones(n_actions)  # negative for linprog minimization -> maximize sum costs (encourage bigger cost)
    A_ub = np.vstack([IR_A, -IC_A])
    b_ub = np.hstack([IR_b, -IC_b])

    # Fix small numerical tolerance with a tiny slack by using method='highs'
    res = linprog(c=c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method="highs")

    if res.success:
        costs = res.x
    else:
        # If no feasible solution, fallback: set zero costs (will break IR or IC, but fallback anyway)
        costs = np.zeros(n_actions)

    # Step 5: Add artificially one rejection action if needed, to explain rejections
    # If any log j with agent_action=-1 such that for all actions p @ w_j - cost >=0,
    # we add a "rej" action with degenerate distribution and cost large enough to enforce rejection.

    if len(reject_idx) > 0:
        rej_failed = False
        for j in reject_idx:
            wj = contracts[j]
            rej_values = p_actions @ wj - costs
            if np.any(rej_values >= 0):
                rej_failed = True
                break
        if rej_failed:
            # Add one degenerate rejection action with outcome all zeros, cost large
            rej_outcome = np.zeros((1, m_outcomes))
            # Set cost bigger than max achievable utility on reject contracts + margin
            max_util = max([(p_actions @ contracts[i] - costs).max() for i in reject_idx])
            rej_cost = max_util + 10.0
            costs = np.append(costs, rej_cost)
            p_actions = np.vstack([p_actions, rej_outcome])
            n_actions += 1

    agent_setting = np.hstack([p_actions, costs.reshape(-1, 1)])

    # Normalize p rows again in case numerical issues
    agent_setting[:, :m_outcomes] = np.clip(agent_setting[:, :m_outcomes], 0, None)
    row_sums = agent_setting[:, :m_outcomes].sum(axis=1)
    zero_rows = (row_sums == 0)
    agent_setting[~zero_rows, :m_outcomes] /= row_sums[~zero_rows, np.newaxis]
    # For zero sum rows (e.g. rejection), set uniform to avoid NaN if any
    if zero_rows.any():
        agent_setting[zero_rows, :m_outcomes] = 1.0 / m_outcomes

    # Ensure costs nonnegative
    agent_setting[:, -1] = np.clip(agent_setting[:, -1], 0, None)

    return agent_setting
```
