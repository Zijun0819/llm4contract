```python
import numpy as np
from sklearn.cluster import AgglomerativeClustering

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Improved inference of a valid agent setting consistent with historical contract logs,
    enforcing strict global IR/IC constraints via LP-like cost adjustments, adaptive clustering,
    and iterative refinement with rejection slack.

    Params:
        v (np.ndarray): Principal's value vector (length 5)
        content (list[dict]): each dict with keys: 'Contract' (list of 5),
                              'Principal Utility' (float),
                              'Agent Action' (1 or -1)
    Returns:
        np.ndarray: n_actions x 6 matrix (5 probabilities + 1 cost)
    """

    m_outcomes = v.size
    L = len(content)

    # Prepare arrays from logs
    contracts = np.array([log['Contract'] for log in content], dtype=np.float64)  # (L,5)
    ag_actions = np.array([log['Agent Action'] for log in content], dtype=int)    # (L,)
    p_util = np.array([log['Principal Utility'] for log in content], dtype=np.float64) # (L,)

    accepted_ix = np.where(ag_actions == 1)[0]
    rejected_ix = np.where(ag_actions == -1)[0]

    # If no accepted contracts, trivial uniform action with zero cost suffices
    if accepted_ix.size == 0:
        return np.hstack([np.ones((1, m_outcomes)) / m_outcomes, np.array([[0.0]])])

    accepted_w = contracts[accepted_ix]

    # Normalize contracts for clustering to avoid magnitude bias
    norm_w = accepted_w / (accepted_w.sum(axis=1, keepdims=True) + 1e-12)

    # Adaptive cluster count: min(10, #accepted, sqrt(#accepted)) but at least 1
    n_candidates = max(1, min(10, int(np.sqrt(len(accepted_ix))), len(accepted_ix)))

    # Cluster accepted contracts with average linkage to capture similarities
    clustering = AgglomerativeClustering(n_clusters=n_candidates, linkage='average')
    labels = clustering.fit_predict(norm_w)

    p_candidates = []
    costs_lower_bound = []

    # For each cluster compute weighted centroid and a robust cost lower bound
    for c in range(n_candidates):
        cluster_idx = accepted_ix[labels == c]
        if cluster_idx.size == 0:
            continue
        cluster_w = contracts[cluster_idx]
        cluster_util = p_util[cluster_idx]

        # Weight by (principal utility - min + 1) to emphasize better contracts within cluster
        weights = cluster_util - cluster_util.min() + 1.0
        avg_w = np.average(cluster_w, axis=0, weights=weights)

        # Project avg_w to probability simplex
        p = np.clip(avg_w, 0.0, None)
        psum = p.sum()
        if psum < 1e-12:
            p = np.ones(m_outcomes) / m_outcomes
        else:
            p /= psum

        p_candidates.append(p)

        # Cost lower bound from accepted contracts in cluster:
        # agent utility >=0 => cost <= p @ w_i
        costs_cluster = np.array([p @ contracts[i] for i in cluster_idx])
        min_cost = costs_cluster.min()
        costs_lower_bound.append(min_cost)

    p_candidates = np.array(p_candidates)
    costs_lower_bound = np.array(costs_lower_bound)

    # Handle rejected contracts: agent utility < 0 for all inferred actions
    if rejected_ix.size > 0:
        reject_contracts = contracts[rejected_ix]  # (#rej,5)
        p_w_rej = p_candidates @ reject_contracts.T  # shape (n_actions, n_rej)
        # For rejection, cost must be strictly > max p @ w_r for all rejected contracts
        c_rej_min = p_w_rej.max(axis=1) + 1e-6
    else:
        c_rej_min = np.zeros(len(p_candidates))

    # Initial costs: max of accepted lower bounds and rejection minimums
    costs = np.maximum(costs_lower_bound, c_rej_min)
    costs = np.maximum(costs, 0.0)

    # Validate accepted contracts and iteratively add missing actions with slack refinement
    def valid_action_for_contract(w_i):
        for a, (p, c) in enumerate(zip(p_candidates, costs)):
            util = p @ w_i - c
            if util >= -1e-10:
                return a
        return None

    # Add actions for accepted contracts not explained by current candidates
    for i in accepted_ix:
        w_i = contracts[i]
        if valid_action_for_contract(w_i) is None:
            # New action: normalize contract vector as probability
            p_new = w_i.copy()
            psum = p_new.sum()
            if psum < 1e-12:
                p_new = np.ones(m_outcomes) / m_outcomes
            else:
                p_new /= psum
            c_new = p_new @ w_i
            p_candidates = np.vstack([p_candidates, p_new])
            costs = np.append(costs, c_new)

    # Refine costs to strictly satisfy rejection constraints with small margin
    if rejected_ix.size > 0:
        reject_contracts = contracts[rejected_ix]
        p_w_rej = p_candidates @ reject_contracts.T
        for a in range(len(p_candidates)):
            max_rej_util = p_w_rej[a].max()
            if costs[a] < max_rej_util + 1e-8:
                costs[a] = max_rej_util + 1e-4  # small margin for strict inequality

    # Final normalization and projection of probabilities (enforce simplex)
    p_candidates = np.clip(p_candidates, 0.0, None)
    p_sums = p_candidates.sum(axis=1, keepdims=True)
    small_sums = p_sums < 1e-12
    p_sums[small_sums] = 1.0
    p_candidates /= p_sums

    # Assemble final agent setting matrix (n_actions x 6)
    agent_setting = np.hstack([p_candidates, costs[:, None]])

    return agent_setting
```
