```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog, minimize
from sklearn.cluster import AgglomerativeClustering


def agent_solver_v2(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    """
    Infer a valid agent setting consistent with historical contract logs.

    Args:
        v (np.ndarray): Principal's reward vector (length 5).
        content (pd.DataFrame): Historical logs with columns ['Contract', 'Principal Utility', 'Agent Action'].

    Returns:
        np.ndarray: n x 6 matrix where each row = [p_1,...,p_5,cost], with p as outcome probabilities and cost ≥ 0.
    """
    contracts = np.vstack(content['Contract'].values)  # shape (L,5)
    agent_actions = content['Agent Action'].to_numpy()
    utilities = content['Principal Utility'].to_numpy()
    L, m = contracts.shape  # L logs, m=5 outcomes
    
    # Step 1: Prepare datasets indexed by acceptance and rejection
    accept_idx = np.where(agent_actions == 1)[0]
    reject_idx = np.where(agent_actions == -1)[0]

    # Step 2: Infer outcome distributions from accepted contracts by fitting outcome probabilities
    # For each accepted contract: find agent outcome distribution that rationalizes the log
    def infer_p(w, util, v):
        """
        Solve LP to find p s.t.
          sum p_j =1,
          sum p_j*(v_j - w_j) = util  (agent's expected net utility)
          p_j >=0
        """
        c = np.zeros(m)
        A_eq = np.vstack([np.ones(m), v - w])
        b_eq = np.array([1.0, util])
        bounds = [(0, 1)] * m
        res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            return res.x
        else:
            # fallback: allow small negative tolerance on expected utility
            eps = 1e-7
            A_ub = np.array([-(v - w)])
            b_ub = np.array([-util - eps])
            res2 = linprog(c, A_eq=[np.ones(m)], b_eq=[1.0], A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')
            if res2.success:
                return res2.x
        return None

    inferred_ps = []
    valid_idx = []
    for i in accept_idx:
        p_i = infer_p(contracts[i], utilities[i], v)
        if p_i is not None:
            inferred_ps.append(p_i)
            valid_idx.append(i)
    inferred_ps = np.array(inferred_ps)
    if len(inferred_ps) == 0:
        # No acceptable inferred p, fallback to uniform dist and zero cost one action
        p_single = np.ones(m) / m
        c_single = 0.0
        return np.hstack([p_single.reshape(1, -1), np.array([[c_single]])])

    # Step 3: Cluster inferred distributions to get candidate actions
    # Use Agglomerative clustering—robust to number of clusters, we choose adaptive cluster number
    cluster_range = range(2, min(10, len(inferred_ps)) + 1)
    best_labels = None
    best_inertia = np.inf
    best_n_clusters = 2
    for k in cluster_range:
        clusterer = AgglomerativeClustering(n_clusters=k)
        labels = clusterer.fit_predict(inferred_ps)
        # Compute a simple inertia (sum of within-cluster squared distances)
        inertia = 0
        for c in range(k):
            cluster_points = inferred_ps[labels == c]
            centroid = cluster_points.mean(axis=0)
            inertia += ((cluster_points - centroid) ** 2).sum()
        if inertia < best_inertia:
            best_inertia = inertia
            best_labels = labels
            best_n_clusters = k

    n = best_n_clusters
    centroids = np.array([inferred_ps[best_labels == i].mean(axis=0) for i in range(n)])

    # Step 4: Optimize cost vector c (agents' action costs), c >= 0,
    # IR constraint: for every accepted log assigned to action a: p_a · w_i - c_a >= 0
    # IC constraint relaxed here by checking revealed preference of assigned action vs others on accepted logs
    # Reject logs must have max_a (p_a · w - c_a) < 0

    # Assign each accepted log to the closest centroid in L1 distance of p·w (approximate best response)
    assignments = np.full(L, -1, dtype=int)
    # Precompute action utilities over accepted contracts
    p_dot_w = centroids @ contracts.T  # (n,L)
    for i in accept_idx:
        # assigned to action with max expected wage because utility >=0, must explain acceptance
        expected_utilities = p_dot_w[:, i]
        assignments[i] = expected_utilities.argmax()

    # Cost vector initialization: min c_a so that IR constraints hold with margin 0
    c0 = np.zeros(n)
    for a in range(n):
        idxs = np.where(assignments == a)[0]
        if len(idxs) > 0:
            # For all accepted logs assigned a: c_a <= p_a·w_i (worst case agent utility zero)
            c0[a] = np.min(p_dot_w[a, idxs])
        else:
            c0[a] = 0.0

    # Define constraints: For accepted logs i assigned to a_i:
    # p_{a_i}·w_i - c_{a_i} ≥ 0  (IR)
    # For rejected logs i:
    # max_a p_a·w_i - c_a < 0

    # Prepare matrices for constraints: Number of constraints = |accept_idx| + |reject_idx| x n
    # We'll formulate as linear inequalities on c:

    # IR constraints: c_{a_i} ≤ p_{a_i}·w_i  for i in accepted assigned to a_i
    A_ir = np.zeros((len(accept_idx), n))
    b_ir = np.zeros(len(accept_idx))
    accept_order = []
    idx2pos = {}
    for pos, i in enumerate(accept_idx):
        a_i = assignments[i]
        A_ir[pos, a_i] = 1
        b_ir[pos] = p_dot_w[a_i, i]
        accept_order.append(i)
        idx2pos[i] = pos

    # IC or rejection constraints on reject_idx: For each rejected contract i and action a:
    # p_a · w_i - c_a < 0 --> p_a · w_i ≤ c_a - epsilon (slightly strict)
    eps = 1e-5
    A_rej = np.zeros((len(reject_idx) * n, n))
    b_rej = np.zeros(len(reject_idx) * n)
    for ridx, ci in enumerate(reject_idx):
        for a in range(n):
            A_rej[ridx * n + a, a] = -1  # move c_a to lhs
            b_rej[ridx * n + a] = -p_dot_w[a, ci] - eps

    # Bound costs c ≥ 0
    bounds_c = [(0, None)] * n

    # Objective: minimize sum of costs + penalty for violation to pick simplest explanation
    # Or maximize minimal margin to rejection constraints (make consistent)
    # We'll just minimize sum(c) for simplicity

    # Combine constraints: inequality constraints A_ub c ≤ b_ub
    A_ub = np.vstack([A_ir * (-1), A_rej])  # IR flipped: -c_a ≤ -p·w_i
    b_ub = np.hstack([-b_ir, b_rej])

    # Linear program: minimize 1^T c s.t. A_ub c ≤ b_ub and c ≥ 0
    res = linprog(np.ones(n), A_ub=A_ub, b_ub=b_ub, bounds=bounds_c, method='highs')

    if res.success:
        c_opt = res.x
    else:
        # fallback: use initial costs but clipped nonnegative
        c_opt = np.maximum(c0, 0)

    # Step 5: Validate costs on rejection logs:
    rej_util_max = (p_dot_w[:, reject_idx] - c_opt[:, None]).max(axis=0) if len(reject_idx) > 0 else np.array([])
    if np.any(rej_util_max >= 0):
        # Correction: penalize such violation by pushing costs up minimally via constrained optimization
        def penalty(c):
            margin = p_dot_w[:, reject_idx] - c[:, None]  # (n, len(reject_idx))
            viol = np.maximum(margin, 0)
            return np.sum(viol) + 1e-3 * np.sum(c)

        res2 = minimize(penalty, c_opt, bounds=bounds_c, method='L-BFGS-B')
        if res2.success:
            c_opt = res2.x

    # Step 6: Normalize centroids to be valid probabilities
    centroids = np.clip(centroids, 0, 1)
    centroids /= centroids.sum(axis=1, keepdims=True) + 1e-12

    agent_setting = np.hstack([centroids, c_opt.reshape(-1, 1)])

    # Enforce numeric stability: cost >= 0, p sum to 1, probabilities >= 0
    agent_setting[:, :-1] = np.clip(agent_setting[:, :-1], 0, 1)
    sums = agent_setting[:, :-1].sum(axis=1, keepdims=True)
    agent_setting[:, :-1] /= sums + 1e-12
    agent_setting[:, -1] = np.clip(agent_setting[:, -1], 0, None)

    return agent_setting
```
