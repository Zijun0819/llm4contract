```python
import numpy as np
from sklearn.cluster import AgglomerativeClustering

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions = outcome distributions + costs)
    that rationalizes all historical contract-agent interaction logs under IC and IR,
    using adaptive clustering with weighted centroids, strict cost margins,
    iterative addition of unexplained contracts, and robust normalization.

    Parameters:
    - v (np.ndarray): Principal's value vector of length 5
    - content (list[dict]): each dict has keys:
        'Contract' (list of 5 floats),
        'Principal Utility' (float),
        'Agent Action' (1 or -1)

    Returns:
    - agent_setting (np.ndarray): n_actions x 6 matrix; each row:
        first 5 elements: outcome probabilities summing to 1,
        last element: nonnegative agent cost
    """
    m_outcomes = v.size
    L = len(content)

    # Extract data arrays
    contracts = np.array([log['Contract'] for log in content], dtype=np.float64)  # (L,5)
    ag_actions = np.array([log['Agent Action'] for log in content], dtype=int)    # (L,)
    p_util = np.array([log['Principal Utility'] for log in content], dtype=np.float64)  # (L,)

    accepted_ix = np.where(ag_actions == 1)[0]
    rejected_ix = np.where(ag_actions == -1)[0]

    # Handle no accepted contracts: trivial uniform action with zero cost suffices
    if accepted_ix.size == 0:
        uniform_p = np.ones(m_outcomes) / m_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])

    accepted_w = contracts[accepted_ix]

    # Normalize accepted contracts for clustering (avoid scale bias)
    norm_w = accepted_w / (accepted_w.sum(axis=1, keepdims=True) + 1e-12)

    # Adaptive number of clusters: min(10, #accepted, floor(sqrt(#accepted))) at least 1
    n_clusters = max(1, min(10, accepted_ix.size, int(np.sqrt(accepted_ix.size))))

    # Cluster accepted normalized contracts with average linkage
    if n_clusters > 1:
        clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='average')
        cluster_labels = clustering.fit_predict(norm_w)
    else:
        cluster_labels = np.zeros(accepted_ix.size, dtype=int)

    p_candidates = []
    cost_lower_bounds = []

    # For each cluster, compute weighted centroid and cost lower bound
    for c in range(n_clusters):
        cluster_mask = (cluster_labels == c)
        cluster_indices = accepted_ix[cluster_mask]
        if cluster_indices.size == 0:
            continue

        cluster_w = contracts[cluster_indices]
        cluster_util = p_util[cluster_indices]

        # Weights emphasizing better contracts: (util - min + 1), fallback uniform if degenerate
        weights = cluster_util - cluster_util.min() + 1.0
        if np.sum(weights) < 1e-12:
            weights = np.ones_like(weights)
        weights /= weights.sum()

        # Weighted average contract vector (not guaranteed to sum to 1)
        avg_w = np.average(cluster_w, axis=0, weights=weights)

        # Project avg_w onto simplex (clip negatives, normalize)
        p = np.clip(avg_w, 0.0, None)
        s = p.sum()
        if s < 1e-12:
            p = np.ones(m_outcomes) / m_outcomes
        else:
            p /= s

        p_candidates.append(p)

        # Cost lower bound from IR constraints: cost <= min p @ w_i for cluster contracts
        costs_cluster = np.array([p @ contracts[i] for i in cluster_indices])
        cost_lb = costs_cluster.min()
        cost_lower_bounds.append(cost_lb)

    p_candidates = np.array(p_candidates)
    cost_lower_bounds = np.array(cost_lower_bounds)

    # For rejected contracts: cost must be > max p @ w_j for all rejected contracts
    if rejected_ix.size > 0:
        rejected_w = contracts[rejected_ix]
        p_w_rejected = p_candidates @ rejected_w.T  # shape (n_actions, #rejected)
        cost_rejected_min = p_w_rejected.max(axis=1) + 1e-8
    else:
        cost_rejected_min = np.zeros_like(cost_lower_bounds)

    # Initial costs: max of IR lower bounds and rejection strict lower bounds
    costs = np.maximum(cost_lower_bounds, cost_rejected_min)
    costs = np.maximum(costs, 0.0)

    # Check if each accepted contract is rationalized by some candidate action (IC & IR)
    def explains_contract(w_i: np.ndarray) -> bool:
        utilities = p_candidates @ w_i - costs
        return np.any(utilities >= -1e-12)

    # Add new actions for accepted contracts not explained by current candidates
    for idx in accepted_ix:
        w_i = contracts[idx]
        if not explains_contract(w_i):
            p_new = np.clip(w_i, 0.0, None)
            s = p_new.sum()
            if s < 1e-12:
                p_new = np.ones(m_outcomes) / m_outcomes
            else:
                p_new /= s
            c_new = p_new @ w_i  # minimum cost consistent with IR for this contract
            p_candidates = np.vstack([p_candidates, p_new])
            costs = np.append(costs, c_new)

    # Refine costs to strictly satisfy rejection constraints with small margin
    if rejected_ix.size > 0:
        rejected_w = contracts[rejected_ix]
        p_w_rejected = p_candidates @ rejected_w.T
        for a_idx in range(len(costs)):
            max_rej_util = p_w_rejected[a_idx].max()
            if costs[a_idx] <= max_rej_util + 1e-12:
                costs[a_idx] = max_rej_util + 1e-4  # safety margin for strict inequality

    # Final projection and normalization of probabilities onto simplex
    p_candidates = np.clip(p_candidates, 0.0, None)
    row_sums = p_candidates.sum(axis=1, keepdims=True)
    zero_sum_mask = row_sums < 1e-12
    row_sums[zero_sum_mask] = 1.0
    p_candidates /= row_sums

    costs = np.maximum(costs, 0.0)

    agent_setting = np.hstack([p_candidates, costs[:, None]])
    return agent_setting
```
