```python
import numpy as np
from sklearn.cluster import AgglomerativeClustering
from scipy.optimize import linprog

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix consistent with historical contract logs.
    Each action corresponds to a probability distribution over outcomes plus a cost,
    satisfying agent IR and IC constraints given the logs of contracts and accept/reject.

    Parameters:
        v (np.ndarray): Principal's value vector of length 5.
        content (list[dict]): Historical logs with keys:
            'Contract': list of 5 floats (payments),
            'Principal Utility': float,
            'Agent Action': 1 (accept) or -1 (reject).

    Returns:
        np.ndarray: n_actions x 6 matrix. Each row is (p_1,...,p_5, cost).
                    p_i >=0, sum p_i=1, cost >=0.
    """
    m_outcomes = v.size
    L = len(content)

    # Extract arrays
    contracts = np.array([log['Contract'] for log in content], dtype=np.float64)  # (L,5)
    principal_utils = np.array([log['Principal Utility'] for log in content], dtype=np.float64)  # (L,)
    agent_actions = np.array([log['Agent Action'] for log in content], dtype=int)  # (L,)

    accepted_ix = np.where(agent_actions == 1)[0]
    rejected_ix = np.where(agent_actions == -1)[0]

    # If no accepted contracts, return trivial uniform action with zero cost
    if accepted_ix.size == 0:
        uniform_p = np.ones(m_outcomes) / m_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.zeros((1, 1), dtype=np.float64)])

    accepted_contracts = contracts[accepted_ix]

    # Normalize accepted contracts to probability simplex safely (avoid division by zero)
    accepted_sums = accepted_contracts.sum(axis=1, keepdims=True)
    accepted_sums[accepted_sums < 1e-12] = 1.0
    normalized_accepted = accepted_contracts / accepted_sums

    # Adaptive number of clusters for candidate actions
    n_accepted = accepted_ix.size
    n_max = max(1, min(10, n_accepted, int(np.sqrt(n_accepted))))
    clustering = AgglomerativeClustering(n_clusters=n_max, linkage='average')
    labels = clustering.fit_predict(normalized_accepted)

    p_candidates = []
    costs_lb = []

    # Build candidate actions by weighted averaging with principal util shift and projecting to simplex
    for cid in range(n_max):
        cluster_mask = (labels == cid)
        cluster_indices = accepted_ix[cluster_mask]
        if cluster_indices.size == 0:
            continue

        cluster_contracts = contracts[cluster_indices]
        cluster_putils = principal_utils[cluster_indices]

        # Shift principal utilities to positive weights to emphasize better contracts
        w_min = cluster_putils.min()
        weights = cluster_putils - w_min + 1.0

        avg_w = np.average(cluster_contracts, axis=0, weights=weights)

        # Project onto simplex: clip negatives then renormalize
        p = np.clip(avg_w, 0, None)
        p_sum = p.sum()
        if p_sum < 1e-12:
            p = np.ones(m_outcomes) / m_outcomes
        else:
            p /= p_sum

        p_candidates.append(p)

        # Cost lower bound from IR constraints of accepted contracts in cluster
        cluster_costs = np.dot(cluster_contracts, p)
        min_cost = cluster_costs.min()
        costs_lb.append(min_cost)

    if len(p_candidates) == 0:
        # fallback: uniform distribution with zero cost
        uniform_p = np.ones(m_outcomes) / m_outcomes
        return np.hstack([uniform_p.reshape(1, -1), np.zeros((1, 1), dtype=np.float64)])

    p_candidates = np.array(p_candidates)  # (n_actions, 5)
    costs_lb = np.array(costs_lb)

    # Rejection constraints: cost must exceed max utility on rejected contracts
    if rejected_ix.size > 0:
        rejected_contracts = contracts[rejected_ix]  # (R,5)
        p_w_rej = p_candidates @ rejected_contracts.T  # (n_actions, R)
        costs_rej_min = p_w_rej.max(axis=1) + 1e-6
    else:
        costs_rej_min = np.zeros_like(costs_lb)

    costs = np.maximum(costs_lb, costs_rej_min)
    costs = np.maximum(costs, 0.0)

    # Helper: check if an action rationalizes acceptance of contract w_i (utility >=0)
    def explains_acceptance(w_i: np.ndarray) -> int | None:
        for idx, (p, c) in enumerate(zip(p_candidates, costs)):
            if (p @ w_i) - c >= -1e-8:
                return idx
        return None

    # Add minimal explaining actions for accepted contracts not covered so far
    unexplained_ix = [i for i in accepted_ix if explains_acceptance(contracts[i]) is None]
    if unexplained_ix:
        unexplained_contracts = contracts[unexplained_ix]
        # Cluster unexplained contracts moderately (up to 5 clusters)
        n_dummy = min(5, len(unexplained_ix))
        unexplained_sums = unexplained_contracts.sum(axis=1, keepdims=True)
        unexplained_sums[unexplained_sums < 1e-12] = 1.0
        norm_unexplained = unexplained_contracts / unexplained_sums

        if len(unexplained_ix) > 1 and n_dummy > 1:
            dummy_clustering = AgglomerativeClustering(n_clusters=n_dummy, linkage='average')
            dummy_labels = dummy_clustering.fit_predict(norm_unexplained)
        else:
            dummy_labels = np.zeros(len(unexplained_ix), dtype=int)
            n_dummy = 1

        for cluster_id in range(n_dummy):
            cluster_mask = (dummy_labels == cluster_id)
            cluster_indices = np.array(unexplained_ix)[cluster_mask]
            if cluster_indices.size == 0:
                continue
            cluster_contracts = contracts[cluster_indices]

            avg_p = np.clip(cluster_contracts.mean(axis=0), 0, None)
            p_sum = avg_p.sum()
            if p_sum < 1e-12:
                avg_p = np.ones(m_outcomes) / m_outcomes
            else:
                avg_p /= p_sum

            # Cost set to max p@w_i over cluster contracts to guarantee IR
            cost_new = max(np.dot(avg_p, contracts[i]) for i in cluster_indices)
            p_candidates = np.vstack([p_candidates, avg_p])
            costs = np.append(costs, cost_new)

    # After adding new actions, re-check rejection constraints and refine costs via LP
    n_actions = p_candidates.shape[0]
    if rejected_ix.size > 0:
        rejected_contracts = contracts[rejected_ix]
        p_w_rej = p_candidates @ rejected_contracts.T  # (n_actions, R)

        # LP variables: costs vector (size n_actions)
        c_obj = np.zeros(n_actions)  # minimize zero, feasibility only

        # Inequality constraints: for each rejected contract r and action a:
        # cost_a >= p_a @ w_r + epsilon  ->  -cost_a <= - (p_a @ w_r + epsilon)
        epsilon = 1e-7
        A_ub = []
        b_ub = []
        for a in range(n_actions):
            for ridx in range(len(rejected_ix)):
                val = p_w_rej[a, ridx] + epsilon
                row = np.zeros(n_actions)
                row[a] = -1
                A_ub.append(row)
                b_ub.append(-val)
        A_ub = np.array(A_ub) if A_ub else None
        b_ub = np.array(b_ub) if b_ub else None

        bounds = [(0, None)] * n_actions  # costs >=0

        if A_ub is not None:
            res = linprog(c=c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')
            if res.success:
                costs = np.maximum(res.x, 0.0)  # enforce nonnegativity numerical stability

    # Final robust normalization of probabilities
    p_candidates = np.clip(p_candidates, 0, None)
    p_sums = p_candidates.sum(axis=1, keepdims=True)
    p_sums[p_sums < 1e-12] = 1.0
    p_candidates /= p_sums

    # Assemble final agent setting matrix
    agent_setting = np.hstack([p_candidates, costs[:, None]])

    return agent_setting
```
