```python
import numpy as np
from scipy.optimize import linprog
from sklearn.cluster import DBSCAN

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix from historical logs with contracts, principal utilities,
    and agent actions. This version infers outcome distributions via LP feasibility,
    clusters them adaptively, and iteratively adjusts costs to strictly enforce IR/IC constraints.

    Args:
        v: np.ndarray, shape (5,), principal's reward vector for 5 outcomes.
        content: list of dicts, each dict has keys:
            'Contract': list or array of length 5 (payment vector),
            'Principal Utility': float,
            'Agent Action': int (1 for accept, -1 for reject)

    Returns:
        agent_setting: np.ndarray, shape (n_actions, 6), each row is [p(outcomes), cost]
            where p sums to 1 and cost >= 0.
    """
    contracts = np.array([log['Contract'] for log in content])  # shape (L,5)
    principal_utils = np.array([log['Principal Utility'] for log in content])  # shape (L,)
    agent_actions = np.array([log['Agent Action'] for log in content])  # shape (L,)
    L, m = contracts.shape

    accepted_idx = np.where(agent_actions == 1)[0]
    rejected_idx = np.where(agent_actions == -1)[0]

    # If no accepted contracts, return trivial uniform action with zero cost
    if len(accepted_idx) == 0:
        uniform_p = np.ones(m) / m
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])

    # Step 1: Infer candidate outcome distributions p for accepted contracts
    candidate_ps = []
    accepted_idx_valid = []
    for i in accepted_idx:
        w = contracts[i]
        u = principal_utils[i]
        # Solve LP: find p >=0, sum(p)=1, p@(v - w) = u
        # linprog handles equalities, set c=0 to find any feasible p
        A_eq = np.vstack([np.ones(m), v - w])
        b_eq = np.array([1.0, u])
        bounds = [(0, 1)] * m

        res = linprog(c=np.zeros(m), A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            # Numerical cleanup: clip and renormalize
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
                candidate_ps.append(p)
                accepted_idx_valid.append(i)
        # else ignore this accepted contract as infeasible

    # If no feasible candidate p found, fallback uniform distribution with zero cost
    if len(candidate_ps) == 0:
        uniform_p = np.ones(m) / m
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])

    candidate_ps = np.array(candidate_ps)
    accepted_idx_valid = np.array(accepted_idx_valid)

    # Step 2: Cluster candidate_ps into agent actions using DBSCAN
    # Adaptive eps heuristic: median pairwise L1 distance * 0.5, min 0.05 max 0.3
    from sklearn.metrics import pairwise_distances
    if len(candidate_ps) > 1:
        dists = pairwise_distances(candidate_ps, metric='manhattan')
        median_dist = np.median(dists[np.triu_indices(len(candidate_ps), k=1)])
        eps = np.clip(median_dist * 0.5, 0.05, 0.3)
    else:
        eps = 0.1

    clustering = DBSCAN(eps=eps, min_samples=3).fit(candidate_ps)
    labels = clustering.labels_
    unique_labels = set(labels)
    if -1 in unique_labels:
        unique_labels.remove(-1)  # remove noise points

    # Handle noise points by assigning them to nearest cluster center or create singleton clusters
    noise_indices = np.where(labels == -1)[0]
    if len(unique_labels) == 0:
        # No clusters found, treat all as one cluster
        unique_labels = {0}
        labels[:] = 0
    else:
        cluster_centers_init = []
        for lbl in unique_labels:
            cluster_centers_init.append(candidate_ps[labels == lbl].mean(axis=0))
        cluster_centers_init = np.array(cluster_centers_init)
        for ni in noise_indices:
            p_noise = candidate_ps[ni]
            dists_noise = np.sum(np.abs(cluster_centers_init - p_noise), axis=1)
            nearest = np.argmin(dists_noise)
            labels[ni] = list(unique_labels)[nearest]

    unique_labels = sorted(set(labels))
    n_actions = len(unique_labels)

    # Step 3: Compute cluster centers (actions' outcome distributions)
    cluster_centers = np.zeros((n_actions, m))
    for idx, lbl in enumerate(unique_labels):
        members = candidate_ps[labels == lbl]
        center = members.mean(axis=0)
        # Clean and normalize center
        center = np.clip(center, 0, None)
        s = center.sum()
        if s > 0:
            center /= s
        else:
            center = np.ones(m) / m
        cluster_centers[idx] = center

    # Step 4: Assign accepted contracts to clusters and infer initial costs
    costs = np.zeros(n_actions)
    accepted_labels = np.full(len(accepted_idx_valid), -1, dtype=int)
    label_to_idx = {lbl: idx for idx, lbl in enumerate(unique_labels)}
    for i, lbl in enumerate(labels):
        accepted_labels[i] = label_to_idx[lbl]

    # For each action, cost must satisfy IR for all assigned accepted contracts:
    # cost_a <= min_{i in cluster} p_a @ w_i
    for a in range(n_actions):
        assigned_indices = np.where(accepted_labels == a)[0]
        if len(assigned_indices) == 0:
            costs[a] = 0.0
            continue
        p_a = cluster_centers[a]
        assigned_contracts = contracts[accepted_idx_valid[assigned_indices]]
        upper_bounds = assigned_contracts @ p_a  # p_a @ w_i
        costs[a] = max(0.0, upper_bounds.min())

    # Step 5: Enforce IC constraints for rejected contracts:
    # For each rejected contract w, for all actions a: p_a @ w - cost_a < 0
    # If violated, increase cost_a accordingly
    if len(rejected_idx) > 0:
        rejected_contracts = contracts[rejected_idx]
        epsilon = 1e-7
        for a in range(n_actions):
            p_a = cluster_centers[a]
            vals = rejected_contracts @ p_a
            max_rej_val = vals.max()
            if costs[a] <= max_rej_val:
                costs[a] = max_rej_val + epsilon

    # Step 6: Iterative refinement of costs to ensure IR and IC simultaneously
    max_iter = 15
    for _ in range(max_iter):
        changed = False
        # IR check: for accepted contracts, utility >= 0
        for i, idx_log in enumerate(accepted_idx_valid):
            a = accepted_labels[i]
            p_a = cluster_centers[a]
            cost_a = costs[a]
            util = p_a @ contracts[idx_log] - cost_a
            if util < -1e-10:
                new_cost = p_a @ contracts[idx_log]
                if new_cost > cost_a + 1e-12:
                    costs[a] = new_cost
                    changed = True

        # IC check: for rejected contracts, utility < 0 for all actions
        for idx_log in rejected_idx:
            w = contracts[idx_log]
            for a in range(n_actions):
                p_a = cluster_centers[a]
                cost_a = costs[a]
                util = p_a @ w - cost_a
                if util >= -1e-10:
                    new_cost = p_a @ w + 1e-7
                    if new_cost > cost_a + 1e-12:
                        costs[a] = new_cost
                        changed = True

        if not changed:
            break

    # Step 7: Final normalization of cluster centers (numerical safety)
    for a in range(n_actions):
        p = cluster_centers[a]
        p = np.clip(p, 0, None)
        s = p.sum()
        if s > 0:
            cluster_centers[a] = p / s
        else:
            cluster_centers[a] = np.ones(m) / m

    # Step 8: Compose final agent setting matrix
    agent_setting = np.hstack([cluster_centers, costs.reshape(-1, 1)])

    return agent_setting
```
