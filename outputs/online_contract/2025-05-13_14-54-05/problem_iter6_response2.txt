```python
import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.neighbors import NearestNeighbors
from scipy.optimize import linprog

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x [probabilities over 5 outcomes + cost])
    that explains all historical interactions under IR and IC constraints.

    Args:
        v: np.ndarray of shape (5,), principal's reward vector for 5 outcomes.
        content: list of dicts, each with keys 'Contract' (list of 5 float payments),
                 'Principal Utility' (float), and 'Agent Action' (1 or -1).

    Returns:
        np.ndarray of shape (n_actions, 6), rows are [p1,...,p5,cost]
    """
    m = v.shape[0]  # expected 5 outcomes
    L = len(content)

    # Separate accepted and rejected logs
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]

    # If no accepted logs, return trivial uniform distribution with zero cost (agent always rejects)
    if not accepted_logs:
        p_uniform = np.ones(m) / m
        return np.array([np.append(p_uniform, 0.0)])

    accepted_contracts = np.array([log['Contract'] for log in accepted_logs])
    rejected_contracts = np.array([log['Contract'] for log in rejected_logs]) if rejected_logs else np.empty((0, m))

    # L1 normalize accepted contracts to emphasize shape over scale for clustering
    accepted_norms = accepted_contracts.sum(axis=1, keepdims=True)
    accepted_norms[accepted_norms == 0] = 1.0  # avoid division by zero
    accepted_normalized = accepted_contracts / accepted_norms

    # Use nearest neighbors distances to find eps candidates for DBSCAN (elbow method)
    neigh = NearestNeighbors(n_neighbors=2, metric='euclidean')
    neigh.fit(accepted_normalized)
    distances, _ = neigh.kneighbors(accepted_normalized)
    nearest_dists = distances[:, 1]  # distance to nearest neighbor (exclude self)
    sorted_dists = np.sort(nearest_dists)

    # Compute second discrete derivative to find elbow
    diffs = np.diff(sorted_dists)
    diffs2 = np.diff(diffs)
    if len(diffs2) == 0:
        eps_candidates = [0.1]
    else:
        elbow_idx = np.argmax(diffs2) + 2  # offset for double diff
        base_eps = sorted_dists[elbow_idx]
        eps_candidates = [base_eps, base_eps * 0.5, base_eps * 1.5]
        eps_candidates = [eps for eps in eps_candidates if eps > 0]

    best_labels = None
    best_eps = None
    best_n_clusters = 0

    # Threshold for max average cluster radius to accept clustering
    max_avg_radius_threshold = 0.05

    for eps in sorted(eps_candidates):
        clustering = DBSCAN(eps=eps, min_samples=3, metric='euclidean')
        labels = clustering.fit_predict(accepted_normalized)
        unique_labels = set(labels)
        if -1 in unique_labels:
            unique_labels.remove(-1)
        n_clusters = len(unique_labels)
        if n_clusters == 0:
            continue

        # Compute average cluster radius per cluster
        avg_radii = []
        for cid in unique_labels:
            cluster_pts = accepted_normalized[labels == cid]
            center = cluster_pts.mean(axis=0)
            dists = np.linalg.norm(cluster_pts - center, axis=1)
            avg_radii.append(np.mean(dists))
        max_avg_radius = max(avg_radii) if avg_radii else np.inf

        if max_avg_radius <= max_avg_radius_threshold:
            best_labels = labels
            best_eps = eps
            best_n_clusters = n_clusters
            break

    # If no suitable clustering found, fallback to single cluster (all accepted)
    if best_labels is None:
        best_labels = np.zeros(len(accepted_contracts), dtype=int)
        best_n_clusters = 1

    # Assign noise points (-1) to nearest cluster center by Euclidean distance
    if best_n_clusters > 0:
        centers = []
        for cid in range(best_n_clusters):
            cluster_pts = accepted_normalized[best_labels == cid]
            center = cluster_pts.mean(axis=0)
            centers.append(center)
        centers = np.array(centers)

        noise_idx = np.where(best_labels == -1)[0]
        if len(noise_idx) > 0:
            noise_pts = accepted_normalized[noise_idx]
            dists = np.linalg.norm(noise_pts[:, None, :] - centers[None, :, :], axis=2)
            nearest_clusters = dists.argmin(axis=1)
            for i, idx in enumerate(noise_idx):
                best_labels[idx] = nearest_clusters[i]
    else:
        centers = accepted_normalized.mean(axis=0, keepdims=True)
        best_n_clusters = 1
        best_labels = np.zeros(len(accepted_contracts), dtype=int)

    # Compute cluster mean payment vectors (not normalized)
    cluster_payments = np.zeros((best_n_clusters, m))
    for cid in range(best_n_clusters):
        cluster_payments[cid] = accepted_contracts[best_labels == cid].mean(axis=0)

    # Normalize cluster payment vectors to valid probability distributions (nonnegative, sum=1)
    ps = np.zeros_like(cluster_payments)
    eps_norm = 1e-12
    for i in range(best_n_clusters):
        p = np.maximum(cluster_payments[i], 0.0)
        s = p.sum()
        if s > eps_norm:
            p /= s
        else:
            p = np.ones(m) / m
        ps[i] = p

    # Assign accepted contracts to closest cluster by Euclidean distance on normalized contracts
    # Normalize ps rows to sum=1 (already done), but ensure shape for broadcasting
    dist_to_centers = np.linalg.norm(accepted_normalized[:, None, :] - ps[None, :, :], axis=2)
    assigned_actions = dist_to_centers.argmin(axis=1)

    n_actions = best_n_clusters

    # IR constraints: for accepted contracts i assigned to action a:
    # cost_a <= p_a @ w_i (agent utility >= 0)
    # IC constraints: for rejected contracts j:
    # cost_a > p_a @ w_j for all a (agent utility < 0)
    # We approximate strict inequalities by small margin eps_margin

    eps_margin = 1e-8

    # Compute upper bounds on costs from IR constraints
    cost_ub = np.full(n_actions, np.inf)
    for a in range(n_actions):
        idxs = np.where(assigned_actions == a)[0]
        if len(idxs) > 0:
            vals = np.array([ps[a] @ accepted_contracts[i] for i in idxs])
            cost_ub[a] = vals.min()
        else:
            cost_ub[a] = np.inf  # no accepted contracts assigned

    # Compute lower bounds on costs from IC constraints
    if rejected_contracts.shape[0] > 0:
        rej_vals = ps @ rejected_contracts.T  # shape (n_actions, n_rejections)
        cost_lb = rej_vals.max(axis=1) + eps_margin
    else:
        cost_lb = np.zeros(n_actions)

    # Ensure cost bounds are consistent: cost_lb <= cost_ub; if not, relax cost_ub slightly
    bounds = []
    for a in range(n_actions):
        lb = max(cost_lb[a], 0.0)
        ub = cost_ub[a]
        if ub < lb:
            ub = lb + 1e-6
        if np.isinf(ub):
            ub = None
        bounds.append((lb, ub))

    # Minimize sum of costs subject to bounds
    c_obj = np.ones(n_actions)
    res = linprog(c=c_obj, bounds=bounds, method='highs')

    if res.success:
        costs = res.x
    else:
        # fallback: costs = max(cost_lb, 0)
        costs = np.maximum(cost_lb, 0.0)

    # Compose final agent setting matrix: rows [p1,...,p5, cost]
    agent_setting = np.hstack([ps, costs.reshape(-1, 1)])

    return agent_setting
```
