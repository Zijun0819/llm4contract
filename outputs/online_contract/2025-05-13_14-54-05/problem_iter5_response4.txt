```python
import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.neighbors import NearestNeighbors
from scipy.optimize import linprog

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x [probabilities over 5 outcomes + cost])
    that explains all historical interactions under IR and IC constraints.

    Args:
        v: np.ndarray of shape (5,), principal's reward vector for 5 outcomes.
        content: list of dicts, each with keys 'Contract' (list of 5 float payments),
                 'Principal Utility' (float), and 'Agent Action' (1 or -1).

    Returns:
        np.ndarray of shape (n_actions, 6), rows are [p1,...,p5,cost]
    """
    m = v.shape[0]  # number of outcomes (expected 5)
    L = len(content)

    # Separate accepted and rejected logs
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]

    # If no accepted logs, return trivial uniform distribution with zero cost
    if not accepted_logs:
        p_uniform = np.ones(m) / m
        return np.array([np.append(p_uniform, 0.0)])

    accepted_contracts = np.array([log['Contract'] for log in accepted_logs])
    rejected_contracts = np.array([log['Contract'] for log in rejected_logs]) if rejected_logs else np.empty((0, m))

    # Normalize accepted contracts by their L1 norm to emphasize shape over scale for clustering
    accepted_norms = accepted_contracts.sum(axis=1, keepdims=True)
    accepted_norms[accepted_norms == 0] = 1.0  # avoid div by zero
    accepted_normalized = accepted_contracts / accepted_norms

    # Adaptive DBSCAN clustering with elbow method on eps to find meaningful clusters
    # Use cosine distance (1 - cosine similarity) since payments are positive and normalized
    # Compute nearest neighbor distances to choose eps
    neigh = NearestNeighbors(n_neighbors=2, metric='euclidean')
    neigh.fit(accepted_normalized)
    distances, _ = neigh.kneighbors(accepted_normalized)
    # distances[:,1] is distance to nearest neighbor (excluding self)
    sorted_distances = np.sort(distances[:,1])
    # Heuristic: elbow at max second derivative approx
    diffs = np.diff(sorted_distances)
    diffs2 = np.diff(diffs)
    if len(diffs2) == 0:
        eps_candidates = [0.1]
    else:
        elbow_idx = np.argmax(diffs2) + 2  # offset due to diff twice
        eps_candidates = [sorted_distances[elbow_idx]]
    # Add a few eps candidates around elbow for robustness
    eps_candidates += [eps_candidates[0]*0.5, eps_candidates[0]*1.5]
    eps_candidates = [eps for eps in eps_candidates if eps > 0]

    best_labels = None
    best_eps = None
    best_n_clusters = 0
    best_core_samples_mask = None

    for eps in sorted(eps_candidates):
        clustering = DBSCAN(eps=eps, min_samples=3, metric='euclidean')
        labels = clustering.fit_predict(accepted_normalized)
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        if n_clusters == 0:
            continue
        # Compute avg cluster radius (mean distance to cluster center)
        avg_radii = []
        for cluster_id in range(n_clusters):
            cluster_points = accepted_normalized[labels == cluster_id]
            center = cluster_points.mean(axis=0)
            dists = np.linalg.norm(cluster_points - center, axis=1)
            avg_radii.append(np.mean(dists))
        max_avg_radius = max(avg_radii)
        # We want smallest eps yielding max_avg_radius <= threshold (0.05)
        if max_avg_radius <= 0.05:
            best_labels = labels
            best_eps = eps
            best_n_clusters = n_clusters
            best_core_samples_mask = clustering.core_sample_indices_
            break

    # If no suitable clustering found, fallback to one cluster (all accepted)
    if best_labels is None:
        best_labels = np.zeros(len(accepted_contracts), dtype=int)
        best_n_clusters = 1

    # Handle noise points assigned -1 by DBSCAN: assign to nearest cluster center
    if best_n_clusters > 0:
        centers = []
        for cid in range(best_n_clusters):
            cluster_points = accepted_normalized[best_labels == cid]
            center = cluster_points.mean(axis=0)
            centers.append(center)
        centers = np.array(centers)
        noise_idx = np.where(best_labels == -1)[0]
        if len(noise_idx) > 0:
            # Assign noise points to nearest center by Euclidean distance
            noise_points = accepted_normalized[noise_idx]
            dists = np.linalg.norm(noise_points[:, None, :] - centers[None, :, :], axis=2)
            nearest_clusters = dists.argmin(axis=1)
            for i, idx in enumerate(noise_idx):
                best_labels[idx] = nearest_clusters[i]
    else:
        centers = accepted_normalized.mean(axis=0, keepdims=True)
        best_n_clusters = 1
        best_labels = np.zeros(len(accepted_contracts), dtype=int)

    # For each cluster, compute payment pattern as mean contract vector (not normalized)
    cluster_payments = np.zeros((best_n_clusters, m))
    for cid in range(best_n_clusters):
        cluster_payments[cid] = accepted_contracts[best_labels == cid].mean(axis=0)

    # Normalize cluster payment vectors to probability distributions (nonnegative, sum=1)
    ps = np.zeros_like(cluster_payments)
    eps_norm = 1e-12
    for i in range(best_n_clusters):
        p = np.maximum(cluster_payments[i], 0.0)
        s = p.sum()
        if s > eps_norm:
            p /= s
        else:
            p = np.ones(m) / m
        ps[i] = p

    # Assign accepted contracts to closest cluster by Euclidean distance on normalized contracts
    dist_to_centers = np.linalg.norm(accepted_normalized[:, None, :] - (ps / ps.sum(axis=1, keepdims=True)) [None,:,:], axis=2)
    assigned_actions = dist_to_centers.argmin(axis=1)

    # Setup linear program variables:
    # Variables: for each action a: p_a1,...,p_a5, cost_a
    # But p_a fixed as ps from above (cluster means normalized),
    # optimize costs to satisfy IR and IC constraints strictly.

    n_actions = best_n_clusters
    # Variables: costs only (n_actions)
    # Constraints:
    # IR: for each accepted contract i assigned to action a:
    #     p_a @ w_i - cost_a >= 0  => cost_a <= p_a @ w_i
    # IC: for each rejected contract j:
    #     max_a (p_a @ w_j - cost_a) < 0
    # <=> for all a: cost_a > p_a @ w_j

    # Collect IR upper bounds for each cost_a
    cost_ub = np.full(n_actions, np.inf)
    for a in range(n_actions):
        idxs = np.where(assigned_actions == a)[0]
        if len(idxs) > 0:
            vals = np.array([ps[a] @ accepted_contracts[i] for i in idxs])
            cost_ub[a] = vals.min()
        else:
            # No accepted contract assigned: cost upper bound infinity
            cost_ub[a] = np.inf

    # Collect IC lower bounds for each cost_a from rejected contracts
    if rejected_contracts.shape[0] > 0:
        rej_vals = ps @ rejected_contracts.T  # shape (n_actions, n_rej)
        # For each rejected contract, cost_a > p_a @ w_j for all a
        # So cost_a > max_j p_a @ w_j
        cost_lb = rej_vals.max(axis=1) + 1e-8  # strict inequality approx
    else:
        cost_lb = np.zeros(n_actions)

    # Final cost bounds: cost_lb <= cost_a <= cost_ub
    # If cost_ub < cost_lb for any a, no feasible solution; relax with slack

    # Solve LP to find costs minimizing sum(costs) subject to bounds
    # Minimize c^T x with bounds lb <= x <= ub
    c = np.ones(n_actions)
    bounds = []
    for a in range(n_actions):
        lb = max(cost_lb[a], 0.0)
        ub = cost_ub[a]
        if ub < lb:
            # Relax ub to lb + small margin to keep feasibility
            ub = lb + 1e-6
        if np.isinf(ub):
            ub = None
        bounds.append((lb, ub))

    # Use linprog with identity objective and bounds only
    res = linprog(c=c, bounds=bounds, method='highs')
    if res.success:
        costs = res.x
    else:
        # fallback: costs = max(cost_lb, 0)
        costs = np.maximum(cost_lb, 0.0)

    # Final agent setting matrix: each row [p1, ..., p5, cost]
    agent_setting = np.hstack([ps, costs.reshape(-1, 1)])

    return agent_setting
```
