```python
import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import normalize
from sklearn.metrics import pairwise_distances
from scipy.optimize import linprog

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x [probabilities over 5 outcomes + cost])
    that explains all historical interactions under IR and IC constraints.

    Args:
        v: np.ndarray of shape (5,), principal's reward vector for 5 outcomes.
        content: list of dicts, each with keys 'Contract' (list of 5 float payments),
                 'Principal Utility' (float), and 'Agent Action' (1 or -1).

    Returns:
        np.ndarray of shape (n_actions, 6), rows are [p1,...,p5,cost]
    """
    m = v.shape[0]  # number of outcomes (expected 5)
    L = len(content)

    # Separate accepted and rejected logs
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]

    # Handle trivial case: no accepted logs
    if not accepted_logs:
        p_uniform = np.ones(m) / m
        return np.array([np.append(p_uniform, 0.0)])

    accepted_contracts = np.array([log['Contract'] for log in accepted_logs])  # shape (N_acc, m)
    accepted_contracts = np.maximum(accepted_contracts, 0)  # ensure non-negativity

    # Normalize accepted contracts to sum to 1 for clustering (L1 norm)
    accepted_contracts_norm = normalize(accepted_contracts, norm='l1', axis=1)

    # Adaptive DBSCAN clustering with L1 distance and elbow method on eps
    # Use a range of eps values to find a stable clustering with reasonable number of clusters
    # We want clusters with average L1 radius <= 0.1 (tunable)
    eps_values = np.linspace(0.01, 0.5, 30)
    best_labels = None
    best_n_clusters = 1
    best_eps = None
    best_centers = None
    threshold = 0.1

    for eps in eps_values:
        clustering = DBSCAN(eps=eps, min_samples=3, metric='manhattan')
        labels = clustering.fit_predict(accepted_contracts_norm)
        unique_labels = set(labels)
        if -1 in unique_labels:
            unique_labels.remove(-1)  # remove noise label
        n_clusters = len(unique_labels)
        if n_clusters == 0:
            continue
        # Compute cluster centers and average L1 radius
        centers = np.zeros((n_clusters, m))
        max_avg_radius = 0.0
        for i, lbl in enumerate(sorted(unique_labels)):
            cluster_points = accepted_contracts_norm[labels == lbl]
            center = cluster_points.mean(axis=0)
            centers[i] = center
            avg_radius = np.mean(np.sum(np.abs(cluster_points - center), axis=1))
            if avg_radius > max_avg_radius:
                max_avg_radius = avg_radius
        if max_avg_radius <= threshold:
            best_labels = labels
            best_n_clusters = n_clusters
            best_eps = eps
            best_centers = centers
            break

    # If no suitable clustering found, fallback to AgglomerativeClustering with 1 cluster
    if best_centers is None:
        from sklearn.cluster import AgglomerativeClustering
        best_n_clusters = 1
        best_labels = np.zeros(len(accepted_contracts), dtype=int)
        best_centers = accepted_contracts_norm.mean(axis=0, keepdims=True)

    # Assign accepted contracts to clusters (actions)
    # For noise points (-1), assign to nearest cluster by L1 distance
    assigned_actions = np.array(best_labels)
    if -1 in assigned_actions:
        noise_idxs = np.where(assigned_actions == -1)[0]
        # Compute L1 distances to cluster centers for noise points
        noise_points = accepted_contracts_norm[noise_idxs]
        dists = pairwise_distances(noise_points, best_centers, metric='manhattan')
        nearest_clusters = dists.argmin(axis=1)
        assigned_actions[noise_idxs] = nearest_clusters

    n_actions = best_n_clusters
    ps = best_centers.copy()  # shape (n_actions, m)

    # Re-normalize cluster centers to sum to 1 exactly (numerical safety)
    ps = normalize(ps, norm='l1', axis=1)

    # Prepare all contracts for IR and IC constraints
    # Accepted contracts grouped by action
    accepted_contracts_by_action = [[] for _ in range(n_actions)]
    for idx, a in enumerate(assigned_actions):
        accepted_contracts_by_action[a].append(accepted_contracts[idx])
    accepted_contracts_by_action = [np.array(lst) if len(lst) > 0 else np.empty((0, m)) for lst in accepted_contracts_by_action]

    # Rejected contracts
    if rejected_logs:
        rejected_contracts = np.array([log['Contract'] for log in rejected_logs])
    else:
        rejected_contracts = np.empty((0, m))

    # Formulate LP to find costs satisfying IR and IC constraints

    # Variables: cost_a for each action a, total n_actions variables
    # Objective: minimize sum(costs) (or zero vector) to find feasible solution

    # Constraints:
    # IR for accepted:
    # For each accepted contract w assigned to action a:
    # p_a @ w - cost_a >= 0  => cost_a <= p_a @ w
    # => cost_a <= min_{w in action a} p_a @ w

    # IC for rejected:
    # For each rejected contract w:
    # max_a (p_a @ w - cost_a) < 0
    # => for all a: cost_a > p_a @ w
    # We enforce cost_a >= p_a @ w + margin (strict inequality approximated by margin)

    # We encode constraints as:
    # For each action a:
    # cost_a <= min_{w in accepted contracts for a} p_a @ w  (upper bound)
    # cost_a >= max_{w in rejected contracts} p_a @ w + margin (lower bound)

    # If no accepted contracts for action a, set upper bound to large number (e.g. +inf)
    # If no rejected contracts, lower bound is 0

    margin = 1e-6  # small positive margin for strict inequalities

    # Compute upper bounds (IR)
    upper_bounds = np.full(n_actions, np.inf)
    for a in range(n_actions):
        if accepted_contracts_by_action[a].shape[0] > 0:
            vals = accepted_contracts_by_action[a] @ ps[a]
            upper_bounds[a] = vals.min()
        else:
            # No accepted contracts assigned to action a, no upper bound from IR
            upper_bounds[a] = np.inf

    # Compute lower bounds (IC)
    if rejected_contracts.shape[0] > 0:
        rej_vals = rejected_contracts @ ps.T  # shape (num_rej, n_actions)
        lower_bounds = rej_vals.max(axis=0) + margin  # shape (n_actions,)
    else:
        lower_bounds = np.zeros(n_actions)

    # Ensure feasibility: lower_bounds <= upper_bounds
    # If not feasible, relax margin to zero and try again
    if np.any(lower_bounds > upper_bounds):
        margin = 0.0
        if rejected_contracts.shape[0] > 0:
            lower_bounds = rejected_contracts @ ps.T
            lower_bounds = lower_bounds.max(axis=0)
        else:
            lower_bounds = np.zeros(n_actions)

    # Also costs >= 0
    lb = np.maximum(lower_bounds, 0)
    ub = upper_bounds

    # Formulate LP:
    # minimize sum costs
    # subject to: lb_i <= cost_i <= ub_i

    # If any ub_i < lb_i, no feasible solution, fallback to heuristic

    feasible = np.all(ub >= lb)
    if not feasible:
        # fallback: set costs = max(lb, 0)
        costs = np.maximum(lb, 0)
    else:
        # linprog formulation: minimize c^T x with bounds lb <= x <= ub
        c = np.ones(n_actions)
        bounds = [(lb[i], ub[i] if np.isfinite(ub[i]) else None) for i in range(n_actions)]
        res = linprog(c, bounds=bounds, method='highs')
        if res.success:
            costs = res.x
        else:
            # fallback: use mid-point between lb and ub where possible
            costs = np.zeros(n_actions)
            for i in range(n_actions):
                if np.isfinite(ub[i]):
                    costs[i] = max(lb[i], 0)
                else:
                    costs[i] = max(lb[i], 0)

    # Final agent setting matrix: each row [p1, ..., p5, cost]
    agent_setting = np.hstack([ps, costs.reshape(-1, 1)])

    return agent_setting
```
