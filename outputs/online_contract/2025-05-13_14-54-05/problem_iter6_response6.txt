```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import DBSCAN
from sklearn.neighbors import NearestNeighbors
from scipy.spatial.distance import cdist

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x [probabilities over 5 outcomes + cost])
    that explains all historical interactions under IR and IC constraints.

    Args:
        v: np.ndarray of shape (5,), principal's reward vector for 5 outcomes.
        content: list of dicts, each with keys 'Contract' (list of 5 float payments),
                 'Principal Utility' (float), and 'Agent Action' (1 or -1).

    Returns:
        np.ndarray of shape (n_actions, 6), rows are [p1,...,p5,cost]
    """
    eps = 1e-12
    m = v.shape[0]  # expected 5 outcomes

    # Separate accepted and rejected logs
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]

    # If no accepted logs, return trivial uniform distribution with zero cost
    if not accepted_logs:
        p_uniform = np.ones(m) / m
        return np.array([np.append(p_uniform, 0.0)])

    accepted_contracts = np.array([log['Contract'] for log in accepted_logs])  # shape (A, 5)
    n_accepted = accepted_contracts.shape[0]

    # Normalize contracts for clustering: scale each contract vector to sum=1 (shape)
    contract_sums = accepted_contracts.sum(axis=1, keepdims=True) + eps
    normalized_contracts = accepted_contracts / contract_sums

    # Determine adaptive eps for DBSCAN by k-distance elbow heuristic (k=5 neighbors)
    neigh = NearestNeighbors(n_neighbors=5)
    nbrs = neigh.fit(normalized_contracts)
    distances, _ = nbrs.kneighbors(normalized_contracts)
    k_distances = np.sort(distances[:, -1])

    # Curvature estimation for elbow detection
    def curvature(x):
        if len(x) < 3:
            return np.zeros_like(x)
        g1 = np.gradient(x)
        g2 = np.gradient(g1)
        return np.abs(g2)

    curv = curvature(k_distances)
    if len(curv) > 0:
        eps_idx = np.argmax(curv)
        eps_val = k_distances[eps_idx]
    else:
        eps_val = 0.1
    eps_val = max(eps_val, 0.01)

    # Run DBSCAN with adaptive eps, increase eps if too many noise points (>10%)
    eps_try = eps_val
    max_eps = 0.5
    noise_fraction = 1.0
    min_samples = 5
    while noise_fraction > 0.1 and eps_try <= max_eps:
        db = DBSCAN(eps=eps_try, min_samples=min_samples)
        labels = db.fit_predict(normalized_contracts)
        noise_fraction = np.mean(labels == -1)
        if noise_fraction > 0.1:
            eps_try *= 1.5

    # If still too noisy or no clusters, fallback uniform
    unique_labels = set(labels)
    unique_labels.discard(-1)
    if not unique_labels:
        p_uniform = np.ones(m) / m
        return np.array([np.append(p_uniform, 0.0)])

    # Group contracts by cluster label
    clusters = [accepted_contracts[labels == lab] for lab in sorted(unique_labels)]

    # Assign noise points to nearest cluster center (in normalized contract space)
    noise_idx = np.where(labels == -1)[0]
    if noise_idx.size > 0 and clusters:
        noise_points = accepted_contracts[noise_idx]
        noise_norm = normalized_contracts[noise_idx]
        cluster_centers_norm = np.array([
            (c / (np.sum(c, axis=1, keepdims=True) + eps)).mean(axis=0) for c in clusters
        ])
        dist_noise_to_centers = cdist(noise_norm, cluster_centers_norm, metric='euclidean')
        nearest_clusters = dist_noise_to_centers.argmin(axis=1)
        for idx, cluster_idx in enumerate(nearest_clusters):
            clusters[cluster_idx] = np.vstack([clusters[cluster_idx], noise_points[idx]])

    n_actions = len(clusters)

    # For each cluster, infer p (distribution over outcomes) minimizing average L1 deviation
    ps = []
    for cluster in clusters:
        n_i = cluster.shape[0]
        cluster_sums = cluster.sum(axis=1, keepdims=True) + eps
        cluster_norm = cluster / cluster_sums  # shape (n_i, m)

        # Variables: p_j (m), s_ij (m*n_i) for absolute deviations
        num_vars = m + m * n_i
        c = np.zeros(num_vars)
        c[m:] = 1.0 / n_i  # minimize average absolute deviation over s_ij

        # Inequality constraints: 2*m*n_i
        A_ub = np.zeros((2 * m * n_i, num_vars))
        b_ub = np.zeros(2 * m * n_i)

        row = 0
        for j in range(m):
            for i_ in range(n_i):
                s_idx = m + j * n_i + i_
                # p_j - cluster_norm[i,j] <= s_ij  => p_j - s_ij <= cluster_norm[i,j]
                A_ub[row, j] = 1.0
                A_ub[row, s_idx] = -1.0
                b_ub[row] = cluster_norm[i_, j]
                row += 1
                # cluster_norm[i,j] - p_j <= s_ij => -p_j - s_ij <= -cluster_norm[i,j]
                A_ub[row, j] = -1.0
                A_ub[row, s_idx] = -1.0
                b_ub[row] = -cluster_norm[i_, j]
                row += 1

        # Equality constraint: sum_j p_j = 1
        A_eq = np.zeros((1, num_vars))
        A_eq[0, :m] = 1.0
        b_eq = np.array([1.0])

        # Bounds: p_j >= 0, s_ij >= 0
        bounds = [(0, None)] * num_vars

        lp_res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')

        if lp_res.success:
            p_opt = lp_res.x[:m]
            p_opt = np.clip(p_opt, 0, None)
            s = p_opt.sum()
            if s > eps:
                p_opt /= s
            else:
                p_opt = np.ones(m) / m
        else:
            p_opt = np.ones(m) / m

        ps.append(p_opt)

    ps = np.array(ps)  # shape (n_actions, m)

    # Assign each accepted contract to closest p in L1 norm (to determine action assignment)
    accepted_contracts_all = np.array([log['Contract'] for log in accepted_logs])
    dist = np.sum(np.abs(accepted_contracts_all[:, None, :] - ps[None, :, :]), axis=2)  # (A, n_actions)
    assigned_actions = dist.argmin(axis=1)

    # IR constraints: cost_a <= min_{assigned contracts} p_a @ w
    costs_upper = np.full(n_actions, np.inf)
    for a in range(n_actions):
        idxs = np.where(assigned_actions == a)[0]
        if idxs.size > 0:
            pay_ins = np.array([ps[a] @ accepted_contracts_all[i] for i in idxs])
            costs_upper[a] = pay_ins.min()
        else:
            costs_upper[a] = np.inf

    # IC constraints from rejected logs: cost_a > max_{rejected w} p_a @ w
    if rejected_logs:
        rejected_contracts = np.array([log['Contract'] for log in rejected_logs])
        rej_utilities = ps @ rejected_contracts.T  # (n_actions, R)
        costs_lower = rej_utilities.max(axis=1) + 1e-6  # strict inequality margin
    else:
        costs_lower = np.zeros(n_actions)

    # Resolve costs satisfying costs_lower < cost_a <= costs_upper (if finite)
    costs = np.zeros(n_actions)
    for a in range(n_actions):
        low = costs_lower[a]
        up = costs_upper[a]
        if up == np.inf:
            # No upper bound, pick cost slightly above lower bound or zero
            costs[a] = max(low, 0.0) + 1e-4
        else:
            # Ensure feasibility: if upper < lower, relax upper to lower + margin
            if up < low:
                up = low + 1e-4
            costs[a] = (low + up) / 2
            if costs[a] < 0:
                costs[a] = 0.0

    # Final safety: clip costs non-negative
    costs = np.maximum(costs, 0.0)

    # Output matrix: each row [p1,...,p5, cost]
    agent_setting = np.hstack([ps, costs.reshape(-1, 1)])

    return agent_setting
```
