```python
import numpy as np
from sklearn.cluster import DBSCAN
from scipy.optimize import linprog

def agent_solver(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x [probabilities over 5 outcomes + cost])
    that explains all historical interactions under IR and IC constraints.

    Args:
        v: np.ndarray of shape (5,), principal's reward vector for 5 outcomes.
        content: list of dicts, each with keys 'Contract' (list of 5 float payments),
                 'Principal Utility' (float), and 'Agent Action' (1 or -1).

    Returns:
        np.ndarray of shape (n_actions, 6), rows are [p1,...,p5,cost]
    """
    m = v.shape[0]  # number of outcomes, expected 5
    L = len(content)

    # Separate accepted and rejected logs
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]

    if not accepted_logs:
        # No accepted logs, trivial zero-cost uniform distribution action
        p_uniform = np.ones(m) / m
        return np.array([np.append(p_uniform, 0.0)])

    accepted_contracts = np.array([log['Contract'] for log in accepted_logs])  # shape (A,5)

    # Normalize contracts for clustering: scale each contract vector to sum=1 (to capture relative shape)
    # Add small epsilon to avoid division by zero
    eps = 1e-12
    contract_sums = accepted_contracts.sum(axis=1, keepdims=True) + eps
    normalized_contracts = accepted_contracts / contract_sums

    # Use DBSCAN to cluster accepted contracts adaptively
    # Determine eps via k-distance elbow method (k=5)
    from sklearn.neighbors import NearestNeighbors
    neigh = NearestNeighbors(n_neighbors=5)
    nbrs = neigh.fit(normalized_contracts)
    distances, _ = nbrs.kneighbors(normalized_contracts)
    k_distances = np.sort(distances[:, -1])
    # Heuristic: pick eps at elbow (max curvature) in k_distances
    # Compute discrete curvature
    def curvature(x):
        return np.abs(np.gradient(np.gradient(x)))
    curv = curvature(k_distances)
    if len(curv) > 0:
        eps_idx = np.argmax(curv)
        eps_val = k_distances[eps_idx]
    else:
        eps_val = 0.1  # fallback
    eps_val = max(eps_val, 0.01)  # minimal eps

    db = DBSCAN(eps=eps_val, min_samples=5)
    labels = db.fit_predict(normalized_contracts)
    # If too many noise points (-1), increase eps until noise fraction < 0.1 or eps > 0.5
    noise_fraction = np.mean(labels == -1)
    eps_try = eps_val
    while noise_fraction > 0.1 and eps_try < 0.5:
        eps_try *= 1.5
        db = DBSCAN(eps=eps_try, min_samples=5)
        labels = db.fit_predict(normalized_contracts)
        noise_fraction = np.mean(labels == -1)
    # If still too noisy, assign noise points to nearest cluster center after initial clustering

    # Extract clusters ignoring noise
    unique_labels = set(labels)
    unique_labels.discard(-1)
    if not unique_labels:
        # All noise, fallback: one cluster with uniform distribution
        p_uniform = np.ones(m) / m
        return np.array([np.append(p_uniform, 0.0)])

    clusters = []
    for lab in unique_labels:
        cluster_points = accepted_contracts[labels == lab]
        clusters.append(cluster_points)

    # For noise points, assign to nearest cluster by Euclidean distance in normalized contract space
    noise_points = accepted_contracts[labels == -1]
    noise_norm = normalized_contracts[labels == -1]
    if noise_points.shape[0] > 0 and clusters:
        cluster_centers_norm = np.array([np.mean(c / (np.sum(c, axis=1, keepdims=True) + eps), axis=0) for c in clusters])
        from scipy.spatial.distance import cdist
        dist_noise_to_centers = cdist(noise_norm, cluster_centers_norm)
        nearest_clusters = dist_noise_to_centers.argmin(axis=1)
        for idx, cluster_idx in enumerate(nearest_clusters):
            clusters[cluster_idx] = np.vstack([clusters[cluster_idx], noise_points[idx]])

    # Now each cluster corresponds to one agent action candidate
    n_actions = len(clusters)

    # Step: For each cluster, find a probability distribution p over outcomes that explains contracts
    # We solve LP to find p s.t. for all contracts w in cluster:
    #  p @ v - cost >= 0 (IR), cost unknown yet
    # But we want p to be a probability distribution (sum=1, p>=0)
    # To get p, solve LP minimizing total absolute deviation between p@v and observed contract payments along v direction
    # Actually, contracts are payment vectors, p is distribution over outcomes,
    # expected payment under contract w is p @ w (agent utility = p@w - cost)
    # We want to find p that approximates the normalized shape of contracts in cluster.

    # We approximate p by solving:
    # minimize sum_i ||p - w_i_norm||_1 subject to p>=0, sum p=1
    # where w_i_norm = contract_i / sum(contract_i)
    # This is a linear program.

    ps = []
    for cluster in clusters:
        # Normalize cluster contracts by sum
        cluster_sums = cluster.sum(axis=1, keepdims=True) + eps
        cluster_norm = cluster / cluster_sums

        # Objective: minimize sum of absolute deviations ||p - cluster_norm_i||_1
        # Introduce variables p (length m), and slack variables s_pos, s_neg for each contract and each dimension
        # But to keep complexity low, minimize sum of L1 deviations averaged over cluster points:
        # Equivalent to minimize sum over j=1..m of average absolute deviation over cluster points in dimension j

        # So minimize sum_j d_j, where d_j >= average absolute deviation of p_j

        # Formulate as LP:
        # Variables: p_j (m), d_j (m)
        # Constraints:
        #   p_j >= 0
        #   sum_j p_j =1
        #   For each j:
        #       for each i: p_j - cluster_norm[i,j] <= s_ij_pos
        #       cluster_norm[i,j] - p_j <= s_ij_neg
        #   d_j >= average over i of s_ij_pos + s_ij_neg

        # To reduce variables, approximate by minimizing sum_j average absolute deviation:
        # That is, minimize sum_j d_j
        # subject to for all j,i: -s_ij <= p_j - cluster_norm[i,j] <= s_ij
        # and d_j >= average_i s_ij

        # But this is complex, so approximate by minimizing sum_j average absolute deviation:
        # We discretize by minimizing sum_j sum_i |p_j - cluster_norm[i,j]| / n_i
        # = sum_j sum_i s_ij / n_i

        # We'll implement a simplified LP:
        # Variables: p_j (m), s_ij (m x n)
        # Minimize sum_j sum_i s_ij / n_i
        # Constraints:
        #   p_j - cluster_norm[i,j] <= s_ij
        #   cluster_norm[i,j] - p_j <= s_ij
        #   p_j >= 0
        #   sum_j p_j = 1
        #   s_ij >= 0

        n_i = cluster.shape[0]
        c = np.zeros(m + m * n_i)  # p_j vars + s_ij vars
        c[m:] = 1.0 / n_i  # objective on s_ij

        # Constraints:
        # 2 * m * n_i inequalities for s_ij bounds
        # p_j >=0, sum p_j=1

        # Build matrices for linprog (standard form: minimize c^T x, Ax <= b, Aeq x = beq, bounds)

        # Variables order: [p_0,...p_{m-1}, s_{0,0},..., s_{0,n_i-1}, s_{1,0},..., s_{m-1,n_i-1}]
        # Actually, s_ij arranged as s_j*n_i block per j

        # Number of variables: m + m*n_i
        num_vars = m + m * n_i

        # Inequality constraints: 2 * m * n_i
        A_ub = np.zeros((2 * m * n_i, num_vars))
        b_ub = np.zeros(2 * m * n_i)

        # For each j in [0,m), for each i in [0, n_i):
        # p_j - cluster_norm[i,j] <= s_ij
        # cluster_norm[i,j] - p_j <= s_ij

        # Indexing s_ij in variables:
        # s_ij index = m + j * n_i + i

        row = 0
        for j in range(m):
            for i_ in range(n_i):
                s_idx = m + j * n_i + i_
                # p_j - cluster_norm[i,j] - s_ij <= 0  => p_j - s_ij <= cluster_norm[i,j]
                A_ub[row, j] = 1.0
                A_ub[row, s_idx] = -1.0
                b_ub[row] = cluster_norm[i_, j]
                row += 1
                # cluster_norm[i,j] - p_j - s_ij <= 0 => -p_j - s_ij <= -cluster_norm[i,j]
                A_ub[row, j] = -1.0
                A_ub[row, s_idx] = -1.0
                b_ub[row] = -cluster_norm[i_, j]
                row += 1

        # Equality constraint: sum_j p_j = 1
        A_eq = np.zeros((1, num_vars))
        A_eq[0, :m] = 1.0
        b_eq = np.array([1.0])

        # Bounds: p_j >=0, s_ij >=0
        bounds = [(0, None)] * num_vars

        # Solve LP
        lp_res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')

        if lp_res.success:
            p_opt = lp_res.x[:m]
            # Numerical fix: clip and renormalize
            p_opt = np.clip(p_opt, 0, None)
            s = p_opt.sum()
            if s > eps:
                p_opt /= s
            else:
                p_opt = np.ones(m) / m
        else:
            # fallback uniform
            p_opt = np.ones(m) / m

        ps.append(p_opt)

    ps = np.array(ps)  # shape (n_actions, m)

    # Step: Determine cost per action satisfying IR and IC constraints

    # Build IR constraints from accepted logs:
    # For each accepted log with contract w and assigned action a (closest p in L1 norm),
    # agent utility: p_a @ w - cost_a >= 0 => cost_a <= p_a @ w

    accepted_contracts_all = np.array([log['Contract'] for log in accepted_logs])
    # Assign each accepted contract to closest p in L1 norm
    dist = np.sum(np.abs(accepted_contracts_all[:, None, :] - ps[None, :, :]), axis=2)  # shape (A, n_actions)
    assigned_actions = dist.argmin(axis=1)

    # For each action, get min p_a @ w over assigned accepted contracts (upper bound on cost)
    costs_upper = np.full(n_actions, np.inf)
    for a in range(n_actions):
        idxs = np.where(assigned_actions == a)[0]
        if idxs.size > 0:
            pay_ins = np.array([ps[a] @ accepted_contracts_all[i] for i in idxs])
            costs_upper[a] = pay_ins.min()
        else:
            # No accepted contract assigned: no upper bound from IR
            costs_upper[a] = np.inf

    # Build IC constraints from rejected logs:
    # For each rejected contract w, agent utility max_a (p_a @ w - cost_a) < 0
    # => cost_a > p_a @ w for all a, for that w

    if rejected_logs:
        rejected_contracts = np.array([log['Contract'] for log in rejected_logs])
        rej_utilities = ps @ rejected_contracts.T  # shape (n_actions, R)
        # For each action a, cost_a > max over rejected contracts p_a @ w
        costs_lower = rej_utilities.max(axis=1) + 1e-6  # epsilon for strict inequality
    else:
        costs_lower = np.zeros(n_actions)

    # Now solve for costs satisfying costs_lower < cost_a <= costs_upper (if upper finite),
    # else cost_a >= costs_lower

    costs = np.zeros(n_actions)
    for a in range(n_actions):
        low = costs_lower[a]
        up = costs_upper[a]
        if up == np.inf:
            # No upper bound, set cost = low + margin
            costs[a] = max(low, 0.0) + 1e-4
        else:
            if up < low:
                # Conflict, relax upper bound by increasing up to low + margin
                up = low + 1e-4
            # Choose cost as midpoint in feasible interval
            costs[a] = (low + up) / 2
            if costs[a] < 0:
                costs[a] = 0.0

    # Final sanity check: costs >= 0
    costs = np.maximum(costs, 0.0)

    # Output matrix: each row [p1,...,p5,cost]
    agent_setting = np.hstack([ps, costs.reshape(-1, 1)])

    return agent_setting
```
