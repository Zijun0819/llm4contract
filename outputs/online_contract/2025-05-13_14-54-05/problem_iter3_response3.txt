```python
import numpy as np
from sklearn.cluster import DBSCAN
from scipy.optimize import linprog

def agent_solver(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x [probabilities over 5 outcomes + cost])
    that explains all historical interactions under IR and IC constraints.

    Args:
        v: np.ndarray of shape (5,), principal's reward vector for 5 outcomes.
        content: list of dicts, each with keys 'Contract' (list of 5 float payments),
                 'Principal Utility' (float), and 'Agent Action' (1 or -1).

    Returns:
        np.ndarray of shape (n_actions, 6), rows are [p1,...,p5,cost]
    """
    m = v.shape[0]  # number of outcomes, expected 5
    L = len(content)

    # Separate accepted and rejected logs
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]

    # If no accepted logs, return trivial uniform distribution with zero cost
    if not accepted_logs:
        p_uniform = np.ones(m) / m
        return np.array([np.append(p_uniform, 0.0)])

    accepted_contracts = np.array([log['Contract'] for log in accepted_logs])  # shape (N_acc, 5)
    accepted_contracts = np.clip(accepted_contracts, 0, None)  # Ensure non-negative payments

    # Normalize contracts for clustering: scale each contract vector to sum=1 (to focus on shape)
    contract_sums = accepted_contracts.sum(axis=1, keepdims=True)
    contract_sums[contract_sums < 1e-12] = 1.0  # avoid division by zero
    contracts_norm = accepted_contracts / contract_sums

    # Use DBSCAN clustering on normalized contracts to adaptively find number of actions
    # Parameters chosen to balance cluster count and noise: eps and min_samples tuned heuristically
    eps = 0.15
    min_samples = 3
    clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='euclidean')
    labels = clustering.fit_predict(contracts_norm)
    unique_labels = set(labels)
    # If all noise (-1), fallback to single cluster
    if unique_labels == {-1}:
        labels = np.zeros(len(accepted_contracts), dtype=int)
        unique_labels = {0}

    # For noise points (-1), assign each to closest cluster center after initial centers computed
    noise_idx = np.where(labels == -1)[0]

    # Compute initial cluster centers (mean of original contracts, not normalized)
    cluster_ids = [l for l in unique_labels if l != -1]
    centers = []
    for cid in cluster_ids:
        pts = accepted_contracts[labels == cid]
        centers.append(pts.mean(axis=0))
    centers = np.array(centers)  # shape (k,5)

    # Assign noise points to nearest center by Euclidean distance (on original contracts)
    if len(noise_idx) > 0 and len(centers) > 0:
        noise_points = accepted_contracts[noise_idx]
        dists = np.linalg.norm(noise_points[:, None, :] - centers[None, :, :], axis=2)  # (noise_count, k)
        nearest_clusters = dists.argmin(axis=1)
        for i, ni in enumerate(noise_idx):
            labels[ni] = cluster_ids[nearest_clusters[i]]
        cluster_ids = sorted(set(labels))

    # Recompute centers with noise assigned
    centers = []
    for cid in cluster_ids:
        pts = accepted_contracts[labels == cid]
        centers.append(pts.mean(axis=0))
    centers = np.array(centers)  # shape (k,5)

    n_actions = len(cluster_ids)

    # Step: For each center (payment vector), infer outcome distribution p (probabilities over 5 outcomes)
    # by solving LP:
    # minimize ||p @ v - center||_1 subject to sum p =1, p >=0
    # We linearize ||p@v - center||_1 by introducing slack variables.
    ps = []
    for i in range(n_actions):
        w = centers[i]  # payment vector shape (5,)

        # LP variables: p (5), s_pos(5), s_neg(5)
        # Objective: minimize sum(s_pos + s_neg)
        # Constraints:
        #   p @ v - w = s_pos - s_neg
        #   sum p = 1
        #   p >=0, s_pos >=0, s_neg >=0

        # Construct LP matrices
        # Variables order: p0..p4, s_pos0..s_pos4, s_neg0..s_neg4  => total 15 vars
        c = np.hstack([np.zeros(m), np.ones(m), np.ones(m)])  # minimize sum of s_pos + s_neg

        # Equality constraints: p@v - w - s_pos + s_neg = 0 for each outcome (5 eqs)
        A_eq = np.zeros((m + 1, 3 * m))
        b_eq = np.zeros(m + 1)
        # For each outcome j:
        # p @ v_j = sum_k p_k * v_k_j but v is (5,), so p@v is scalar, but w is vector (5,)
        # Actually, p@v is scalar, w is vector (5,), so p@v - w_j does not make sense.
        # Correction: We want p@v ≈ w_j for each j? No, inconsistent.
        # Actually, payments w correspond to payments per outcome.
        # p is distribution over outcomes, so expected payment is p @ w (scalar).
        # We want to find p so that p @ v ≈ w_j for each j? No.
        # Instead, we want p to be a probability over outcomes.
        # The agent's expected payment under contract w is p @ w (scalar).
        # The principal's reward vector v is unrelated to payment vector w.
        # So the previous approach is invalid.

        # New approach:
        # Since payment vector w corresponds to payments for each outcome,
        # and p is distribution over outcomes,
        # the expected payment under p is p @ w (scalar).
        # We want to find p such that p @ v ≈ principal utility observed,
        # but we do not have agent utility directly.

        # Instead, we approximate p by normalizing w (payments) to sum to 1,
        # assuming that payments roughly reflect outcome probabilities scaled by cost.
        # So we set p_i = max(w_i,0) / sum max(w_i,0)
        p_i = np.maximum(w, 0)
        s = p_i.sum()
        if s < 1e-12:
            p_i = np.ones(m) / m
        else:
            p_i = p_i / s
        ps.append(p_i)

    ps = np.array(ps)  # shape (n_actions, 5)

    # Step: Determine costs for each action to satisfy IR and IC constraints

    # Assign accepted contracts to closest center by Euclidean distance on original contracts
    accepted_contracts_all = np.array([log['Contract'] for log in accepted_logs])
    dist_to_centers = np.linalg.norm(accepted_contracts_all[:, None, :] - centers[None, :, :], axis=2)  # (N_acc, n_actions)
    assigned_actions = dist_to_centers.argmin(axis=1)

    costs = np.zeros(n_actions)

    # IR constraints: for action a, cost_a <= min_{accepted contracts assigned to a} p[a] @ contract
    for a in range(n_actions):
        idxs = np.where(assigned_actions == a)[0]
        if len(idxs) > 0:
            pay_ins = np.array([ps[a] @ accepted_contracts_all[i] for i in idxs])
            costs[a] = pay_ins.min()
        else:
            costs[a] = 0.0

    # IC constraints from rejected contracts:
    # For each rejected contract w, agent utility = max_a (p[a] @ w - cost_a) < 0
    # So cost_a > p[a] @ w for all a, for that w
    if rejected_logs:
        rejected_contracts = np.array([log['Contract'] for log in rejected_logs])
        rej_utilities = ps @ rejected_contracts.T  # shape (n_actions, n_rej)
        # For each action a, cost_a must be > max over rejected contracts of p[a]@w
        cost_rej_min = rej_utilities.max(axis=1) + 1e-7  # epsilon margin
        costs = np.maximum(costs, cost_rej_min)

    # Ensure costs non-negative
    costs = np.maximum(costs, 0.0)

    # Final output: concatenate ps and costs
    agent_setting = np.hstack([ps, costs.reshape(-1, 1)])

    return agent_setting
```
