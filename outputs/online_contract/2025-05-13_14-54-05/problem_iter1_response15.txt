```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import AgglomerativeClustering


def agent_solver_v2(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    """
    Infers a valid agent setting (action distributions and costs) consistent with historical logs.
    
    Args:
        v: 1D np.ndarray of length 5, principal's reward for each outcome.
        content: pd.DataFrame with columns ['Contract', 'Principal Utility', 'Agent Action'].
                 Contract is list-like of length 5.
                 
    Returns:
        np.ndarray with shape (n_actions, 6), where each row is:
          - first 5: outcome probabilities (sum to 1)
          - last: agent's cost (>=0)
    """
    m_outcomes = len(v)
    logs = content.copy()
    L = len(logs)

    # Convert Contracts to np.array shape (L,5)
    W = np.array(logs['Contract'].to_list())  # each row contract payment vector

    # Step 1: Separate accepted and rejected logs
    accept_mask = logs['Agent Action'] == 1
    reject_mask = logs['Agent Action'] == -1

    W_accept = W[accept_mask]
    U_accept = logs.loc[accept_mask, 'Principal Utility'].to_numpy()
    W_reject = W[reject_mask]

    # Step 2: Infer candidate outcome distributions p for each accepted contract
    # Solve for p: maximize agent utility = p@w - cost >= 0, guess cost=0 initially
    # subject to sum(p)=1, p>=0, and p@v = c (unknown)
    # We approximate p by solving a convex LP for each accepted contract that fits the log

    def infer_p_given_w_u(w: np.ndarray, u_p: float):
        # Since Principal Utility = p@v - w@p = p@(v - w), and is given as u_p,
        # We want to find p s.t sum p=1, p>=0, and p@(v - w) = u_p,
        # and p@w = agent cost + agent utility
        # Here, agent utility >=0 since accepted, agent cost unknown.
        # We'll find p minimizing ||p*(v) - (u_p + w@p)|| or simply find feasible p.

        # We reformulate: p@(v - w) = u_p.
        # Constraints:
        # sum p = 1
        # p >=0
        # p @ (v - w) = u_p

        A_eq = np.vstack([np.ones(m_outcomes), v - w])
        b_eq = np.array([1.0, u_p])
        bounds = [(0, 1)] * m_outcomes
        # Objective: minimize 0 (feasibility LP)
        res = linprog(c=np.zeros(m_outcomes), A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            return res.x
        else:
            # Sometimes exact solution not found, fallback: solve approx by least squares
            A = np.vstack([np.ones(m_outcomes), (v - w)]).T
            b = np.array([1.0, u_p])
            # Solve min ||A p - b||^2 s.t p>=0
            from scipy.optimize import lsq_linear
            res2 = lsq_linear(A, b, bounds=(0, 1))
            p = res2.x
            p /= p.sum()
            return p

    candidate_ps = []
    for w_i, u_i in zip(W_accept, U_accept):
        p_i = infer_p_given_w_u(w_i, u_i)
        candidate_ps.append(p_i)
    candidate_ps = np.array(candidate_ps)

    # Step 3: Cluster the candidate_ps using agglomerative clustering
    # to find representative agent actions, adaptive n_clusters based on explained variance
    max_actions = min(10, len(candidate_ps))
    if max_actions < 1:
        # fallback trivial uniform action with zero cost
        uniform_p = np.ones(m_outcomes) / m_outcomes
        return np.hstack([uniform_p, [0.0]])

    # Use Agglomerative clustering to avoid random init, linkage='ward' minimizes variance
    best_n = 1
    best_score = -np.inf
    best_labels = None
    best_centers = None

    for n_clusters in range(1, max_actions + 1):
        clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')
        labels = clustering.fit_predict(candidate_ps)
        centers = np.zeros((n_clusters, m_outcomes))
        # Compute centers as mean p in each cluster
        for c in range(n_clusters):
            centers[c] = candidate_ps[labels == c].mean(axis=0)
            centers[c] = np.clip(centers[c], 0, None)
            centers[c] /= max(np.sum(centers[c]), 1e-8)
        # Compute explained variance ratio (inertia like)
        total_var = np.sum(np.var(candidate_ps, axis=0))
        intra_var = 0
        for c in range(n_clusters):
            cluster_points = candidate_ps[labels == c]
            if cluster_points.shape[0] > 0:
                intra_var += np.sum(np.linalg.norm(cluster_points - centers[c], axis=1) ** 2)
        explained = 1 - intra_var / max(total_var * candidate_ps.shape[0], 1e-8)
        if explained > best_score:
            best_score = explained
            best_n = n_clusters
            best_labels = labels
            best_centers = centers

    n_actions = best_n
    p0 = best_centers

    # Step 4: Estimate costs for each action from accepted contracts
    costs = np.zeros(n_actions)
    for a in range(n_actions):
        idx = np.where(best_labels == a)[0]
        accepted_idx = np.where(accept_mask)[0][idx]
        if len(accepted_idx) == 0:
            costs[a] = 0.0
            continue
        # For each accepted contract linked to action a:
        # agent utility >= 0 => p_a @ w - cost >= 0 => cost <= p_a @ w
        # agent utility = p_a@w - cost
        # Principal utility = p_a@v - w@p_a = given by logs
        # Use max lower bound on cost from acceptance:
        upper_cost_candidates = []
        for i in accepted_idx:
            w_i = W[i]
            p_a = p0[a]
            agent_util = p_a @ w_i - 0  # unknown cost
            # Given acceptance, agent_util >=0 => cost <= p_a @ w_i
            upper_cost_candidates.append(p_a @ w_i)
        costs[a] = max(0.0, min(upper_cost_candidates))

    # Step 5: Enforce IR and IC for rejected contracts:
    # For each rejected contract w_j, agent rejects => max_a (p_a @ w_j - cost_a) < 0
    # If violated, increase costs minimally to enforce rejection
    if W_reject.shape[0] > 0:
        for j in range(W_reject.shape[0]):
            w_j = W_reject[j]
            utilities = p0 @ w_j - costs
            max_util = utilities.max()
            if max_util >= 0:
                # Increase cost of the maximizing action by at least max_util + epsilon
                epsilon = 1e-6
                idx_max = np.argmax(utilities)
                costs[idx_max] += max_util + epsilon

    # Step 6: Final normalize p0 to sum to 1 and clamp costs >=0
    for a in range(n_actions):
        p0[a] = np.clip(p0[a], 0, None)
        s = p0[a].sum()
        if s > 0:
            p0[a] /= s
        costs[a] = max(costs[a], 0)

    agent_setting = np.hstack([p0, costs[:, None]])
    return agent_setting
```
