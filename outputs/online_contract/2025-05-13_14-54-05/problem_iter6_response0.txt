```python
import numpy as np
from scipy.optimize import linprog
from sklearn.cluster import DBSCAN
from sklearn.metrics import pairwise_distances

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x [probabilities over 5 outcomes + cost])
    that explains all historical interactions under IR and IC constraints.

    Args:
        v: np.ndarray of shape (5,), principal's reward vector for 5 outcomes.
        content: list of dicts, each with keys 'Contract' (list of 5 float payments),
                 'Principal Utility' (float), and 'Agent Action' (1 or -1).

    Returns:
        np.ndarray of shape (n_actions, 6), rows are [p1,...,p5,cost]
    """
    contracts = np.array([log['Contract'] for log in content])  # shape (L,5)
    principal_utils = np.array([log['Principal Utility'] for log in content])  # shape (L,)
    agent_actions = np.array([log['Agent Action'] for log in content])  # shape (L,)
    L, m = contracts.shape

    accepted_idx = np.where(agent_actions == 1)[0]
    rejected_idx = np.where(agent_actions == -1)[0]

    # If no accepted contracts, return trivial uniform action with zero cost
    if len(accepted_idx) == 0:
        uniform_p = np.ones(m) / m
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])

    # Step 1: Infer candidate outcome distributions p for accepted contracts
    # Solve LP for each accepted contract:
    # Find p >=0, sum(p)=1, p@(v - w) = principal_utility
    candidate_ps = []
    accepted_idx_valid = []
    for i in accepted_idx:
        w = contracts[i]
        u = principal_utils[i]
        A_eq = np.vstack([np.ones(m), v - w])
        b_eq = np.array([1.0, u])
        bounds = [(0, 1)] * m
        res = linprog(c=np.zeros(m), A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p = res.x
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 1e-12:
                p /= s
                candidate_ps.append(p)
                accepted_idx_valid.append(i)
    if len(candidate_ps) == 0:
        # fallback uniform
        uniform_p = np.ones(m) / m
        return np.hstack([uniform_p.reshape(1, -1), np.array([[0.0]])])

    candidate_ps = np.array(candidate_ps)  # shape (n_accepted_valid, m)
    accepted_idx_valid = np.array(accepted_idx_valid)

    # Step 2: Cluster candidate_ps into agent actions using DBSCAN
    # Adaptive eps heuristic: median pairwise L1 distance * 0.5, clipped
    if len(candidate_ps) > 1:
        dists = pairwise_distances(candidate_ps, metric='manhattan')
        median_dist = np.median(dists[np.triu_indices(len(candidate_ps), k=1)])
        eps = np.clip(median_dist * 0.5, 0.05, 0.25)
    else:
        eps = 0.1
    clustering = DBSCAN(eps=eps, min_samples=2).fit(candidate_ps)
    labels = clustering.labels_
    unique_labels = set(labels)
    if -1 in unique_labels:
        unique_labels.remove(-1)

    # Handle noise points (-1) by assigning to nearest cluster center or create singleton clusters
    noise_indices = np.where(labels == -1)[0]
    if len(unique_labels) == 0:
        # No clusters found, treat all as one cluster
        unique_labels = {0}
        labels[:] = 0
    else:
        cluster_centers_init = []
        for lbl in unique_labels:
            cluster_centers_init.append(candidate_ps[labels == lbl].mean(axis=0))
        cluster_centers_init = np.array(cluster_centers_init)
        for ni in noise_indices:
            p_noise = candidate_ps[ni]
            dists_noise = np.sum(np.abs(cluster_centers_init - p_noise), axis=1)
            nearest = np.argmin(dists_noise)
            labels[ni] = list(unique_labels)[nearest]

    unique_labels = sorted(set(labels))
    n_actions = len(unique_labels)

    # Step 3: Compute cluster centers (actions' outcome distributions)
    cluster_centers = np.zeros((n_actions, m))
    for idx, lbl in enumerate(unique_labels):
        members = candidate_ps[labels == lbl]
        center = members.mean(axis=0)
        center = np.clip(center, 0, None)
        s = center.sum()
        if s > 1e-12:
            center /= s
        else:
            center = np.ones(m) / m
        cluster_centers[idx] = center

    # Step 4: Assign accepted contracts to clusters and infer initial costs
    label_to_idx = {lbl: idx for idx, lbl in enumerate(unique_labels)}
    accepted_labels = np.array([label_to_idx[lbl] for lbl in labels])

    costs = np.zeros(n_actions)
    # For each action a, cost_a <= min_{accepted contracts i in cluster} p_a @ w_i (IR)
    for a in range(n_actions):
        idxs = np.where(accepted_labels == a)[0]
        if len(idxs) == 0:
            costs[a] = 0.0
            continue
        p_a = cluster_centers[a]
        assigned_contracts = contracts[accepted_idx_valid[idxs]]
        pay_ins = assigned_contracts @ p_a  # shape (#assigned,)
        costs[a] = max(0.0, pay_ins.min())

    # Step 5: Enforce IC constraints for rejected contracts:
    # For each rejected contract w, for all actions a: p_a @ w - cost_a < 0
    # If violated, increase cost_a accordingly
    if len(rejected_idx) > 0:
        rejected_contracts = contracts[rejected_idx]
        epsilon = 1e-8
        for a in range(n_actions):
            p_a = cluster_centers[a]
            vals = rejected_contracts @ p_a
            max_val = vals.max()
            if costs[a] <= max_val:
                costs[a] = max_val + epsilon

    # Step 6: Iterative refinement of costs to ensure IR and IC simultaneously
    max_iter = 30
    for _ in range(max_iter):
        changed = False
        # IR check
        for i, idx_log in enumerate(accepted_idx_valid):
            a = accepted_labels[i]
            p_a = cluster_centers[a]
            cost_a = costs[a]
            util = p_a @ contracts[idx_log] - cost_a
            if util < -1e-12:
                new_cost = p_a @ contracts[idx_log]
                if new_cost > cost_a + 1e-14:
                    costs[a] = new_cost
                    changed = True

        # IC check
        for idx_log in rejected_idx:
            w = contracts[idx_log]
            for a in range(n_actions):
                p_a = cluster_centers[a]
                cost_a = costs[a]
                util = p_a @ w - cost_a
                if util >= -1e-12:
                    new_cost = p_a @ w + 1e-8
                    if new_cost > cost_a + 1e-14:
                        costs[a] = new_cost
                        changed = True

        if not changed:
            break

    # Step 7: Final normalization of cluster centers (numerical safety)
    for a in range(n_actions):
        p = cluster_centers[a]
        p = np.clip(p, 0, None)
        s = p.sum()
        if s > 1e-12:
            cluster_centers[a] = p / s
        else:
            cluster_centers[a] = np.ones(m) / m

    # Step 8: Compose final agent setting matrix
    agent_setting = np.hstack([cluster_centers, costs.reshape(-1, 1)])

    return agent_setting
```
