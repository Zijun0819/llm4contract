```python
import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import normalize
from scipy.optimize import linprog

def agent_solver(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x [probabilities over 5 outcomes + cost])
    that explains all historical interactions under IR and IC constraints.

    Args:
        v: np.ndarray of shape (5,), principal's reward vector for 5 outcomes.
        content: list of dicts, each with keys 'Contract' (list of 5 float payments),
                 'Principal Utility' (float), and 'Agent Action' (1 or -1).

    Returns:
        np.ndarray of shape (n_actions, 6), rows are [p1,...,p5,cost]
    """
    m = v.shape[0]  # number of outcomes, expected 5
    L = len(content)

    # Separate accepted and rejected logs
    accepted_logs = [log for log in content if log['Agent Action'] == 1]
    rejected_logs = [log for log in content if log['Agent Action'] == -1]

    # If no accepted logs, return trivial uniform distribution with zero cost
    if not accepted_logs:
        p_uniform = np.ones(m) / m
        return np.array([np.append(p_uniform, 0.0)])

    accepted_contracts = np.array([log['Contract'] for log in accepted_logs])

    # Normalize contracts for clustering to reduce scale effects
    # Add small epsilon to avoid zero division
    contract_norms = np.linalg.norm(accepted_contracts, axis=1, keepdims=True) + 1e-8
    accepted_contracts_normed = accepted_contracts / contract_norms

    # Adaptive DBSCAN clustering on normalized contracts
    # Use k-dist elbow heuristic for eps selection
    from sklearn.neighbors import NearestNeighbors

    k = min(5, len(accepted_contracts_normed) - 1)
    if k < 1:
        # Not enough points to cluster, treat all as one cluster
        labels = np.zeros(len(accepted_contracts_normed), dtype=int)
    else:
        nbrs = NearestNeighbors(n_neighbors=k).fit(accepted_contracts_normed)
        distances, _ = nbrs.kneighbors(accepted_contracts_normed)
        k_distances = np.sort(distances[:, -1])
        # Elbow detection: max second derivative approx by discrete differences
        diffs = np.diff(k_distances)
        diffs2 = np.diff(diffs)
        if len(diffs2) == 0:
            eps = k_distances[-1] * 0.5
        else:
            elbow_idx = np.argmax(diffs2)
            eps = k_distances[elbow_idx + 1]
            # Clamp eps to reasonable bounds
            eps = max(min(eps, 0.5), 0.01)

        dbscan = DBSCAN(eps=eps, min_samples=max(2, k))
        labels = dbscan.fit_predict(accepted_contracts_normed)

        # If all noise, fallback to one cluster
        if np.all(labels == -1):
            labels = np.zeros(len(accepted_contracts_normed), dtype=int)

    unique_labels = set(labels)
    if -1 in unique_labels:
        # For noise points, assign to nearest cluster center or new cluster
        noise_idx = np.where(labels == -1)[0]
        non_noise_idx = np.where(labels != -1)[0]
        if len(non_noise_idx) == 0:
            # All noise, treat as one cluster
            labels[:] = 0
            unique_labels = {0}
        else:
            centers = []
            for ul in unique_labels:
                if ul == -1:
                    continue
                centers.append(accepted_contracts_normed[labels == ul].mean(axis=0))
            centers = np.array(centers)
            for ni in noise_idx:
                dists = np.linalg.norm(centers - accepted_contracts_normed[ni], axis=1)
                assign_label = list(unique_labels - {-1})[np.argmin(dists)]
                labels[ni] = assign_label
            unique_labels = set(labels)

    n_actions = len(unique_labels)
    # Compute cluster centers in original contract space (non-normalized)
    centers = np.zeros((n_actions, m))
    label_to_idx = {lab: idx for idx, lab in enumerate(sorted(unique_labels))}
    for lab in unique_labels:
        idxs = np.where(labels == lab)[0]
        cluster_contracts = accepted_contracts[idxs]
        centers[label_to_idx[lab]] = cluster_contracts.mean(axis=0)

    # Step: For each cluster center (payment vector), infer outcome distribution p
    # by solving LP:
    # minimize ||p @ v - center||_1 or ||p @ v - center||_âˆž subject to p in simplex
    # Here, we approximate by minimizing max absolute deviation per coordinate:
    # Set up LP:
    # Variables: p_1,...,p_5, t (t >= max |p @ v - center_j|)
    # minimize t
    # subject to:
    #   p @ v - center_j <= t
    #   center_j - p @ v <= t
    #   sum p_i = 1
    #   p_i >= 0

    ps = []
    for i in range(n_actions):
        w = centers[i]
        # Number of variables: 5 (p) + 1 (t)
        c = np.zeros(m + 1)
        c[-1] = 1  # minimize t

        # Constraints: for each coordinate j in [0..4]
        # p @ v - w_j <= t  => p @ v - t <= w_j
        # w_j - p @ v <= t  => -p @ v - t <= -w_j

        # Build constraint matrix A_ub x <= b_ub
        # For inequalities: A_ub shape (2*m, m+1)
        A_ub = np.zeros((2 * m, m + 1))
        b_ub = np.zeros(2 * m)

        # p @ v = sum_i p_i * v_i
        # Row j: p @ v - t <= w_j  => sum_i p_i * v_i - t <= w_j
        for j in range(m):
            A_ub[j, :m] = v
            A_ub[j, -1] = -1
            b_ub[j] = w[j]
        # Row m+j: -p @ v - t <= -w_j => -sum_i p_i * v_i - t <= -w_j
        for j in range(m):
            A_ub[m + j, :m] = -v
            A_ub[m + j, -1] = -1
            b_ub[m + j] = -w[j]

        # Equality constraint sum p_i =1
        A_eq = np.zeros((1, m + 1))
        A_eq[0, :m] = 1
        b_eq = np.array([1])

        # Bounds for p_i in [0,1], t >=0
        bounds = [(0, 1) for _ in range(m)] + [(0, None)]

        res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            p_i = res.x[:m]
            # Normalize to ensure sum to 1 (numerical safety)
            p_i = np.maximum(p_i, 0)
            s = p_i.sum()
            if s > 1e-8:
                p_i /= s
            else:
                p_i = np.ones(m) / m
        else:
            # fallback: normalize center vector as probability
            p_i = np.maximum(w, 0)
            s = p_i.sum()
            if s > 1e-8:
                p_i /= s
            else:
                p_i = np.ones(m) / m
        ps.append(p_i)
    ps = np.array(ps)

    # Step: Determine cost for each action
    # Assign accepted contracts to nearest cluster center (in original contract space)
    accepted_contracts_all = np.array([log['Contract'] for log in accepted_logs])
    dist_to_actions = np.linalg.norm(accepted_contracts_all[:, None, :] - centers[None, :, :], axis=2)
    assigned_actions = dist_to_actions.argmin(axis=1)

    costs = np.zeros(n_actions)
    for a in range(n_actions):
        assigned_idx = np.where(assigned_actions == a)[0]
        if assigned_idx.size > 0:
            # IR: cost_a <= min over assigned accepted contracts of p[a] @ w
            pay_ins = np.array([ps[a] @ accepted_contracts_all[i] for i in assigned_idx])
            costs[a] = pay_ins.min()
        else:
            costs[a] = 0.0

    # Step: Enforce IC for rejected contracts
    if rejected_logs:
        rejected_contracts = np.array([log['Contract'] for log in rejected_logs])
        rej_utilities = ps @ rejected_contracts.T  # shape (actions, rejected_count)
        # For each action a, cost_a must be > max over rejected contracts of p[a]@w
        cost_rej_min = rej_utilities.max(axis=1) + 1e-6  # small epsilon for strict inequality
        costs = np.maximum(costs, cost_rej_min)

    costs = np.maximum(costs, 0)

    # Output agent setting matrix: each row [p1,...,p5, cost]
    agent_setting = np.hstack([ps, costs.reshape(-1, 1)])

    return agent_setting
```
