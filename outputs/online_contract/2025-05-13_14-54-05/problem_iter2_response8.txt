```python
import numpy as np
import pandas as pd
from sklearn.cluster import AgglomerativeClustering
from scipy.optimize import linprog

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting (actions with outcome distributions and costs) that explains all historical logs.

    Args:
        v: Principal's value vector for 5 outcomes, shape (5,).
        content: List of dict logs, each with keys:
            - 'Contract': 5-dim payment vector,
            - 'Principal Utility': scalar,
            - 'Agent Action': 1 (accept) or -1 (reject).

    Returns:
        agent_setting: n_actions x 6 matrix:
            - first 5 cols: probabilities over outcomes (sum to 1),
            - last col: cost ≥ 0.
    """
    m = len(v)
    logs = pd.DataFrame(content)
    contracts = np.stack(logs['Contract'].values)  # (L,5)
    agent_actions = logs['Agent Action'].values    # (L,)
    principal_utils = logs['Principal Utility'].values  # (L,)

    accepted_idx = np.where(agent_actions == 1)[0]
    rejected_idx = np.where(agent_actions == -1)[0]

    # If no accepted logs, fallback to trivial uniform distribution with zero cost
    if len(accepted_idx) == 0:
        p0 = np.ones((1, m)) / m
        c0 = np.array([0.0])
        return np.hstack([p0, c0[:, None]])

    accepted_contracts = contracts[accepted_idx]

    # Adaptive clustering on accepted contracts using AgglomerativeClustering with distance threshold
    # Distance threshold chosen heuristically; can be tuned if needed
    clusterer = AgglomerativeClustering(n_clusters=None, distance_threshold=0.5, linkage='ward')
    labels = clusterer.fit_predict(accepted_contracts)
    n_actions = labels.max() + 1

    p_estimates = []
    costs = []

    # Step 1: Estimate p and initial cost per cluster (action)
    for a in range(n_actions):
        idx_a = accepted_idx[labels == a]
        if len(idx_a) == 0:
            # No data for this cluster, assign uniform p and zero cost
            p_estimates.append(np.ones(m) / m)
            costs.append(0.0)
            continue

        cont_a = contracts[idx_a]  # (n_a, m)
        util_a = principal_utils[idx_a]  # (n_a,)

        # Heuristic: approximate p_a by averaging normalized contracts in cluster
        cont_norm = cont_a / (cont_a.sum(axis=1, keepdims=True) + 1e-12)
        p_a = cont_norm.mean(axis=0)
        p_a = np.clip(p_a, 0, None)
        if p_a.sum() <= 0:
            p_a = np.ones(m) / m
        else:
            p_a /= p_a.sum()

        # Estimate cost c_a via IR: c_a ≤ min_i p_a @ contract_i
        # agent utility = p_a @ contract_i - c_a ≥ 0 => c_a ≤ p_a @ contract_i
        exp_utils = cont_a @ p_a
        c_a = exp_utils.min()
        c_a = max(0.0, c_a)

        p_estimates.append(p_a)
        costs.append(c_a)

    p_estimates = np.array(p_estimates)  # (n_actions, m)
    costs = np.array(costs)              # (n_actions,)

    # Step 2: Assign accepted logs to best action by max agent utility (p_a @ w_i - c_a)
    assigned_actions = np.full(len(agent_actions), -1, dtype=int)
    for i in range(len(agent_actions)):
        w_i = contracts[i]
        utilities = p_estimates @ w_i - costs
        if agent_actions[i] == 1:
            # Accepted: assign action that yields max utility (should be ≥ 0)
            if utilities.max() < 0:
                # Infeasible: lower cost of best action to fix
                a_best = utilities.argmax()
                costs[a_best] = min(costs[a_best], p_estimates[a_best] @ w_i)
                utilities = p_estimates @ w_i - costs
            assigned_actions[i] = utilities.argmax()
        else:
            # Rejected: assign -1 (no action)
            assigned_actions[i] = -1

    # Step 3: Formulate LP to refine costs ensuring IR and IC and rejection constraints

    # Variables: costs per action (n_actions)
    # Constraints:
    # IR: For accepted logs i with assigned action a_i: c_a_i ≤ p_a_i @ w_i
    # IC: For accepted logs i and any other action a': c_a' - c_a_i ≥ p_a'@w_i - p_a_i@w_i
    # Rejection: For rejected logs i and all actions a: c_a ≥ p_a @ w_i + epsilon

    epsilon = 1e-5
    n = n_actions
    L = len(agent_actions)

    A_ub = []
    b_ub = []

    # IR constraints: c_a ≤ p_a @ w_i  =>  c_a - p_a @ w_i ≤ 0
    # We write as: c_a - p_a @ w_i ≤ 0 => row with +1 at c_a position and b_ub = p_a @ w_i
    for i in accepted_idx:
        a_i = assigned_actions[i]
        if a_i == -1:
            # Defensive: skip if no assigned action
            continue
        w_i = contracts[i]
        p_a = p_estimates[a_i]
        row = np.zeros(n)
        row[a_i] = 1.0
        A_ub.append(row)
        b_ub.append(p_a @ w_i)

    # IC constraints:
    # For accepted logs i and a' != a_i:
    # c_a' - c_a_i ≥ p_a'@w_i - p_a_i@w_i
    # => c_a_i - c_a' ≤ p_a_i@w_i - p_a'@w_i
    # So for each i, a', add constraint: row[a_i] = 1, row[a'] = -1, b_ub = p_a_i@w_i - p_a'@w_i
    for i in accepted_idx:
        a_i = assigned_actions[i]
        if a_i == -1:
            continue
        w_i = contracts[i]
        p_a_i = p_estimates[a_i]
        for a_prime in range(n):
            if a_prime == a_i:
                continue
            p_a_prime = p_estimates[a_prime]
            row = np.zeros(n)
            row[a_i] = 1.0
            row[a_prime] = -1.0
            b_ub.append((p_a_i @ w_i) - (p_a_prime @ w_i))
            A_ub.append(row)

    # Rejection constraints:
    # For rejected logs i and all actions a:
    # c_a ≥ p_a @ w_i + epsilon
    # => -c_a ≤ -p_a @ w_i - epsilon
    for i in rejected_idx:
        w_i = contracts[i]
        for a in range(n):
            p_a = p_estimates[a]
            row = np.zeros(n)
            row[a] = -1.0
            A_ub.append(row)
            b_ub.append(-(p_a @ w_i + epsilon))

    A_ub = np.array(A_ub)
    b_ub = np.array(b_ub)

    # Objective: minimize sum of costs (small positive weights to keep costs minimal)
    c_obj = np.ones(n) * 1e-6

    bounds = [(0, None) for _ in range(n)]

    res = linprog(c=c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')

    if res.success:
        costs = res.x
    else:
        # If LP fails, fallback to previous costs clipped at zero
        costs = np.clip(costs, 0, None)

    # Final normalization and clipping of p_estimates and costs
    p_estimates = np.clip(p_estimates, 0, None)
    p_sums = p_estimates.sum(axis=1, keepdims=True)
    p_sums[p_sums == 0] = 1.0  # avoid division by zero
    p_estimates /= p_sums
    costs = np.clip(costs, 0, None)

    agent_setting = np.hstack([p_estimates, costs[:, np.newaxis]])
    return agent_setting
```
