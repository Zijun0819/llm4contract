```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import AgglomerativeClustering


def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting from historical logs to satisfy IR and IC constraints.

    Args:
        v (np.ndarray): Principal's reward vector for 5 outcomes.
        content (list[dict]): Historical logs with keys 'Contract', 'Principal Utility', 'Agent Action'.

    Returns:
        np.ndarray: n x 6 matrix:
            - first 5 cols: outcome distributions (sum to 1),
            - last col: non-negative cost for that action.
    """
    # Convert content list of dicts into DataFrame for easier manipulation
    df = pd.DataFrame(content)
    n_logs = len(df)
    m_outcomes = v.shape[0]

    # Extract arrays for convenience
    contracts = np.array(df['Contract'].to_list())  # shape (n_logs, m_outcomes)
    utilities = df['Principal Utility'].to_numpy()  # shape (n_logs,)
    actions = df['Agent Action'].to_numpy()          # shape (n_logs,)

    # Step 1: Separate accepted and rejected contracts
    accepted_mask = actions == 1
    rejected_mask = actions == -1

    # If no accepted contracts, fallback: assume agent always rejects, trivial setting
    if not accepted_mask.any():
        # Single action with uniform distribution, zero cost (agent always rejects)
        uniform_p = np.ones(m_outcomes) / m_outcomes
        cost = 0.0
        return np.hstack([uniform_p.reshape(1, -1), np.array([[cost]])])

    accepted_contracts = contracts[accepted_mask]
    accepted_utils = utilities[accepted_mask]

    # Step 2: Infer candidate outcome distributions from accepted contracts
    # Idea: For each accepted contract, find a feasible p that explains acceptance and principal utility

    def solve_p_for_contract(w, u):
        """
        Solve for p (distribution over outcomes) that satisfies:
          p @ w - c >= 0 (agent accepts)
          v @ p - w @ p = principal utility u
          p sums to 1, p >= 0
        Since c unknown, relax and find p s.t. p@w >= 0 (acceptance) and principal util approx u.
        We'll minimize ||p@v - w@p - u|| with linear constraints.

        Here, formulate a LP to find p maximizing p@w (acceptance) under sum(p)=1 and p>=0,
        with linear constraint p@(v - w) = u (principal util)
        """

        m = len(w)

        # Objective: maximize p @ w (agent's expected payment)
        # But agent accepts if p@w - c >= 0; cost unknown, so just find feasible p.
        # Instead, minimize norm of (p@(v-w) - u) by linear equality constraint.

        # Setup LP to find p:
        # Variables: p_i for i in outcomes
        # Constraints:
        #  sum p_i = 1
        #  p @ (v - w) = u
        #  p_i >= 0

        c_lp = np.zeros(m)  # no objective, just feasibility
        A_eq = np.vstack([np.ones(m), v - w])
        b_eq = np.array([1.0, u])
        bounds = [(0, 1)] * m

        res = linprog(c=c_lp, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            return res.x
        return None

    candidate_ps = []
    for w, u in zip(accepted_contracts, accepted_utils):
        p_sol = solve_p_for_contract(w, u)
        if p_sol is not None:
            candidate_ps.append(p_sol)

    if not candidate_ps:
        # fallback: cluster accepted contracts directly to get representative p's
        candidate_ps = accepted_contracts / accepted_contracts.sum(axis=1, keepdims=True)

    candidate_ps = np.array(candidate_ps)

    # Step 3: Cluster candidate p's to identify discrete agent actions
    # Use Agglomerative clustering with distance = L1 norm on distributions
    n_clusters = min(10, len(candidate_ps))  # adaptive cluster count
    clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity='manhattan', linkage='average')
    labels = clustering.fit_predict(candidate_ps)

    # Representative p for each cluster: average p in cluster
    p_actions = np.zeros((n_clusters, m_outcomes))
    for i in range(n_clusters):
        cluster_ps = candidate_ps[labels == i]
        # Average and re-normalize to ensure sum=1 (numerical safety)
        mean_p = cluster_ps.mean(axis=0)
        mean_p = np.clip(mean_p, 0, None)
        if mean_p.sum() == 0:
            mean_p = np.ones(m_outcomes) / m_outcomes
        else:
            mean_p /= mean_p.sum()
        p_actions[i] = mean_p

    # Step 4: Estimate costs c for each inferred action via IR constraints
    # IR: For accepted contracts assigned to action i,
    # expected payment p_i @ w >= cost c_i >= 0
    # So cost c_i <= min over assigned accepted contracts of p_i @ w

    # Assign each accepted contract to closest cluster by L1 distance on p
    assign_acc = np.full(len(accepted_contracts), -1, dtype=int)
    for idx, (w, u) in enumerate(zip(accepted_contracts, accepted_utils)):
        # For each cluster p_i, cost <= p_i @ w (agent gets paid)
        # Choose cluster maximizing p_i @ w (most plausible)
        payoffs = p_actions @ w
        assign_acc[idx] = np.argmax(payoffs)

    # Compute cost lower bound by min payoff per cluster among assigned contracts
    costs = np.zeros(n_clusters)
    for i in range(n_clusters):
        assigned_idx = np.where(assign_acc == i)[0]
        if len(assigned_idx) > 0:
            payoffs = (p_actions[i] @ accepted_contracts[assigned_idx].T)
            costs[i] = payoffs.min()
            if costs[i] < 0:
                costs[i] = 0.0
        else:
            costs[i] = 0.0

    # Step 5: Enforce rejection constraints (IC)
    # For each rejected contract w_r, agent's expected utility for all actions must be < 0:
    # p_i @ w_r - c_i < 0  =>  c_i > p_i @ w_r for all i
    # So cost c_i must be > max_{rejected contracts} p_i @ w_r

    rej_contracts = contracts[rejected_mask]
    if len(rej_contracts) > 0:
        rej_payoffs = p_actions @ rej_contracts.T  # shape (n_clusters, n_rejected)
        max_rej_payoff = rej_payoffs.max(axis=1)  # max payoff for each action among rejected contracts
    else:
        max_rej_payoff = np.full(n_clusters, -np.inf)

    # Cost must be at least max of IR and rejection threshold + small epsilon for strictness
    eps = 1e-6
    costs_final = np.maximum(costs, max_rej_payoff + eps)
    costs_final = np.clip(costs_final, 0, None)  # non-negative

    # Step 6: Normalize p_actions (safety) and assemble final agent setting matrix
    for i in range(n_clusters):
        p = p_actions[i]
        p[p < 0] = 0
        total = p.sum()
        if total > 0:
            p_actions[i] = p / total
        else:
            p_actions[i] = np.ones(m_outcomes) / m_outcomes

    agent_setting = np.hstack([p_actions, costs_final.reshape(-1, 1)])

    return agent_setting
```
