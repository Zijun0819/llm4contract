```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import DBSCAN


def agent_solver_v2(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    """
    Infer a valid agent setting matrix from historical interaction logs.
    The agent setting matrix rows:
      - first 5 columns: outcome probabilities (sum to 1)
      - last column: agent cost (non-negative)
    The inferred agent actions explain observed accept/reject behavior under IR and IC constraints.

    Parameters:
    - v: np.ndarray of shape (5,), principal's reward vector for 5 outcomes.
    - content: pd.DataFrame with columns:
        'Contract': list of 5 payments,
        'Principal Utility': float,
        'Agent Action': 1 (accept) or -1 (reject).

    Returns:
    - np.ndarray of shape (n_actions, 6)
    """
    m = v.shape[0]
    logs = content.copy()
    L = len(logs)

    # Extract arrays for efficiency:
    contracts = np.vstack(logs['Contract'].to_numpy())  # shape (L,5)
    p_utils = logs['Principal Utility'].to_numpy()      # shape (L,)
    a_actions = logs['Agent Action'].to_numpy()         # shape (L,)

    # Step 1: Infer candidate outcome distributions from accepted contracts by LP
    # For each accepted contract, agent's expected utility = p @ w - c >= 0,
    # principal utility = p @ (v - w), given.
    # We do not know c or p, but p is prob dist on 5 outcomes.
    # For a given contract w and principal utility u, we want p satisfying:
    # p @ (v - w) = u  AND  sum p = 1, p >=0.
    # Since agent accepts, p @ w >= c >= 0.

    def infer_p(w, u):
        # Solve for p: A_eq p = b_eq, p >= 0
        # A_eq = [[1,...,1],
        #         [v1 - w1, ..., v5 - w5]]
        # b_eq = [1, u]
        A_eq = np.vstack([np.ones(m), v - w])
        b_eq = np.array([1.0, u])
        bounds = [(0, 1)] * m
        res = linprog(c=np.zeros(m), A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            return res.x
        else:
            return None

    accepted_idx = np.where(a_actions == 1)[0]
    candidate_ps = []
    for i in accepted_idx:
        w = contracts[i]
        u = p_utils[i]
        p_i = infer_p(w, u)
        if p_i is not None:
            candidate_ps.append(p_i)

    if len(candidate_ps) == 0:
        # No accepted contracts with feasible p, fallback: assume uniform agent action
        p_uniform = np.ones(m) / m
        c_uniform = 0.0
        return np.hstack([p_uniform, [c_uniform]])[np.newaxis, :]

    candidate_ps = np.array(candidate_ps)

    # Step 2: Cluster candidate p vectors with DBSCAN to adaptively find number of actions
    # DBSCAN handles arbitrary shapes and filters noise, eps chosen by heuristic
    # Normalize candidate_ps rows sum=1, but they already do.
    clustering = DBSCAN(eps=0.15, min_samples=3).fit(candidate_ps)
    labels = clustering.labels_

    # Extract clusters ignoring noise (-1)
    unique_labels = sorted(set(labels) - {-1})
    if len(unique_labels) == 0:
        # All noise, fallback to mean p
        mean_p = candidate_ps.mean(axis=0)
        mean_p = np.clip(mean_p, 0, 1)
        mean_p /= mean_p.sum()
        return np.hstack([mean_p, [0.0]])[np.newaxis, :]

    p_actions = []
    for lbl in unique_labels:
        members = candidate_ps[labels == lbl]
        center = members.mean(axis=0)
        center = np.clip(center, 0, 1)
        center /= center.sum()
        p_actions.append(center)
    p_actions = np.array(p_actions)  # shape (n_actions, 5)

    n_actions = len(p_actions)

    # Step 3: Infer agent costs for each action from logs to satisfy IR and IC
    # Variables: costs c_i >= 0, i=0..n_actions-1
    # Constraints:
    #  - For each accepted contract: exists action a so that p_a @ w - c_a >= 0 (agent accepts)
    #  - For each rejected contract: for all actions a, p_a @ w - c_a < 0 (agent rejects)
    # We want to find c_i minimizing sum c_i (or zero if possible)

    # Build matrices for constraints:
    # For each accepted log, assign it to action with max p_a @ w (best action for agent)
    # We enforce IR: p_a @ w - c_a >= 0
    # For each rejected log, for all actions a: p_a @ w - c_a <= -epsilon (< 0)
    # epsilon small positive margin to enforce strict rejection

    epsilon = 1e-5

    # Compute expected payments for all actions and logs: shape (n_actions, L)
    exp_payments = p_actions @ contracts.T  # shape (n_actions, L)

    # Assign accepted logs to best action to minimize agent cost
    c = np.zeros(n_actions)
    # Constraints: p_a @ w - c_a >= 0 for accepted logs assigned to action a
    # We'll solve LP to find minimal c satisfying all constraints:

    # LP variables: c = [c0, c1, ..., c_{n-1}], length n_actions, bounds c_i >= 0
    # Constraints:
    # For accepted logs i:
    #   p_{a_i} @ w_i - c_{a_i} >= 0  => c_{a_i} <= p_{a_i} @ w_i
    # For rejected logs i:
    #   For all actions a: p_a @ w_i - c_a <= -epsilon  => c_a >= p_a @ w_i + epsilon

    from scipy.optimize import linprog

    # Objective: minimize sum of c_i
    obj = np.ones(n_actions)

    # Bounds: c_i >= 0
    bounds = [(0, None)] * n_actions

    # Constraints in format A_ub x <= b_ub
    A_ub = []
    b_ub = []

    # Map accepted logs to action with max expected payment
    assigned_actions = np.argmax(exp_payments[:, accepted_idx], axis=0)

    # For accepted logs: c_{a_i} <= p_{a_i} @ w_i  => -c_{a_i} <= -p_{a_i} @ w_i
    for idx_i, a_i in zip(accepted_idx, assigned_actions):
        row = np.zeros(n_actions)
        row[a_i] = -1
        A_ub.append(row)
        b_ub.append(-exp_payments[a_i, idx_i])

    # For rejected logs: for all actions a: c_a >= p_a @ w_i + epsilon
    # rewrite: -c_a <= -p_a @ w_i - epsilon
    rejected_idx = np.where(a_actions == -1)[0]
    for idx_i in rejected_idx:
        for a_i in range(n_actions):
            row = np.zeros(n_actions)
            row[a_i] = -1
            A_ub.append(row)
            b_ub.append(-exp_payments[a_i, idx_i] - epsilon)

    A_ub = np.array(A_ub)
    b_ub = np.array(b_ub)

    # Solve LP
    res = linprog(c=obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')

    if not res.success:
        # If infeasible, relax rejection margin epsilon to zero and retry once
        epsilon = 0.0
        b_ub = []
        for idx_i, a_i in zip(accepted_idx, assigned_actions):
            row = np.zeros(n_actions)
            row[a_i] = -1
            b_ub.append(-exp_payments[a_i, idx_i])
        for idx_i in rejected_idx:
            for a_i in range(n_actions):
                row = np.zeros(n_actions)
                row[a_i] = -1
                b_ub.append(-exp_payments[a_i, idx_i] - epsilon)
        b_ub = np.array(b_ub)
        res = linprog(c=obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')
        if not res.success:
            # Fall back to zero costs if no feasible solution
            costs = np.zeros(n_actions)
        else:
            costs = res.x
    else:
        costs = res.x

    costs = np.clip(costs, 0, None)

    # Step 4: Return formatted agent setting matrix shape (n_actions, 6)
    agent_setting = np.hstack([p_actions, costs[:, np.newaxis]])
    return agent_setting
```
