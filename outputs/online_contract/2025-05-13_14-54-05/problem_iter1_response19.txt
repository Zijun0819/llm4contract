```python
import numpy as np
import pandas as pd
from scipy.optimize import linprog
from sklearn.cluster import KMeans


def agent_solver_v2(v: np.ndarray, content: pd.DataFrame) -> np.ndarray:
    """
    Infer a valid agent setting (actions as outcome distributions + costs)
    consistent with historical contract acceptance/rejection logs.

    Parameters
    ----------
    v : np.ndarray, shape (5,)
        Principal's reward vector for 5 outcomes.
    content : pd.DataFrame, columns ['Contract', 'Principal Utility', 'Agent Action']
        Historical logs of contracts offered, principal utilities observed,
        and agent's acceptance (1) or rejection (-1).

    Returns
    -------
    agent_setting : np.ndarray, shape (n_actions, 6)
        Each row: 5 probabilities over outcomes (sum=1), 1 cost >=0.
    """
    m = v.shape[0]
    logs = content.copy()

    # Extract data arrays for convenience
    contracts = np.vstack(logs['Contract'].values)  # shape (L,5)
    utilities = logs['Principal Utility'].values    # shape (L,)
    actions = logs['Agent Action'].values            # shape (L,)

    L = len(logs)

    # Step 1: Separate accepted and rejected contracts
    accepted_idx = np.where(actions == 1)[0]
    rejected_idx = np.where(actions == -1)[0]

    contracts_acc = contracts[accepted_idx]
    utilities_acc = utilities[accepted_idx]

    # Step 2: Infer candidate agent outcome distributions (p vectors)
    # Instead of mini LP per log, we run convex optimization:
    # Try to explain accepted logs as mixture of unknown agent actions.

    # Heuristic: pick initial candidate count adaptively via elbow on accepted logs
    max_actions = min(10, max(2, len(accepted_idx)//5))
    if max_actions < 2:
        max_actions = 2

    # Use KMeans clustering on accepted contracts weighted by principal utility
    # First, normalize contracts by utility to highlight important features
    weighted_contracts = contracts_acc * utilities_acc[:, None]
    clustering = KMeans(n_clusters=max_actions, random_state=42, n_init=15)
    clustering.fit(weighted_contracts)
    p_init = clustering.cluster_centers_

    # p_init are candidate expected payments, not distributions yet
    # We want p vectors (probabilities over outcomes) such that p @ v approximate principal utilities

    # Step 3: Project cluster centers onto probability simplex to get outcome distributions
    def proj_simplex(y):
        # Project vector y onto probability simplex {x >=0, sum(x)=1}
        sorted_y = np.sort(y)[::-1]
        tmpsum = 0.0
        t_hat = 0.0
        for i in range(len(y)):
            tmpsum += sorted_y[i]
            t = (tmpsum - 1) / (i + 1)
            if i == len(y) - 1 or t >= sorted_y[i + 1]:
                t_hat = t
                break
        return np.maximum(y - t_hat, 0)

    p_candidates = np.zeros_like(p_init)
    for i in range(max_actions):
        # Solve min ||p * v - p_init[i]||^2 s.t p in simplex
        # Equivalent to projecting p_init[i] onto simplex for probabilities
        # But p_init[i] are expected payments, not probabilities.
        # So solve min ||p @ v - p_init[i]|| subject to p in simplex:
        # Since p @ v is scalar, project p_init[i] / v ?
        # Instead, do a quadratic program:
        # For simplicity, we use proj_simplex on p_init[i] normalized:
        # Normalize cluster center by sum to get positive vector, then project.

        x0 = p_init[i]
        # We want p such that p @ v ~ x0 @ v, so p approximates x0 / v elementwise
        # But v can have zeros? No, reward >0 always
        ratio = x0 / (v + 1e-8)
        ratio = np.clip(ratio, 0, None)
        p_candidates[i] = proj_simplex(ratio)

    # Step 4: Remove near-duplicates and re-normalize
    def unique_rows(a, tol=1e-3):
        unique_idx = []
        for i, row in enumerate(a):
            if not any(np.linalg.norm(row - a[j]) < tol for j in unique_idx):
                unique_idx.append(i)
        return a[unique_idx]

    p_candidates = unique_rows(p_candidates)
    n_actions = len(p_candidates)

    # Step 5: Infer costs c for each action to satisfy IR and IC constraints
    # IR (Individual Rationality): for accepted contracts, chosen action utility >=0
    # IC (Incentive Compatibility): chosen action utility >= utility from any other action
    # For rejected contracts, max over actions utility < 0

    # Variables: c in R^n_actions, costs >=0

    # Construct constraints:
    # For log i with agent action a_i (unknown), agent utility:
    # u_i = p_a_i @ w_i - c[a_i] >= 0 if accepted
    # u_i <0 if rejected: max_a p_a @ w_i - c[a] <0

    # Since agent action unknown, we assign actions to accepted logs by max utility

    # Step 5.1: Assign accepted logs to best fitting actions (maximize agent utility)
    assigned_actions = np.full(L, -1, dtype=int)
    for i in accepted_idx:
        w = contracts[i]
        util = p_candidates @ w  # shape (n_actions,)
        assigned_actions[i] = int(np.argmax(util))

    # Step 5.2: Build LP constraints matrices to solve for c:
    # For accepted logs i: p_a_i @ w_i - c[a_i] >= 0  -> -c[a_i] >= -p_a_i @ w_i
    # For rejected logs i: max_a (p_a @ w_i - c[a]) < 0  -> for all a: p_a @ w_i - c[a] < 0

    # We want to find c >= 0 satisfying:
    # For accepted i: c[a_i] <= p_a_i @ w_i
    # For rejected i, a: c[a] > p_a @ w_i

    # Because strict inequalities impossible in LP, we use small margin epsilon
    epsilon = 1e-5

    # For accepted logs:
    # c[a_i] <= p_candidates[a_i] @ w_i
    # For rejected logs and each action:
    # c[a] >= p_candidates[a] @ w_i + epsilon

    # Define LP variables: c (length n_actions), minimize sum(c) for simplicity
    c_vars = n_actions

    A_ub = []
    b_ub = []

    # Accepted constraints: c[a_i] <= utility_i
    for i in accepted_idx:
        a_i = assigned_actions[i]
        util_i = p_candidates[a_i] @ contracts[i]
        row = np.zeros(c_vars)
        row[a_i] = 1
        A_ub.append(row)
        b_ub.append(util_i)

    # Rejected constraints: c[a] >= p_candidates[a] @ w_i + epsilon -> -c[a] <= - (p_a @ w_i + epsilon)
    for i in rejected_idx:
        w_i = contracts[i]
        for a in range(n_actions):
            util = p_candidates[a] @ w_i + epsilon
            row = np.zeros(c_vars)
            row[a] = -1
            A_ub.append(row)
            b_ub.append(-util)

    A_ub = np.array(A_ub)
    b_ub = np.array(b_ub)

    bounds = [(0, None)] * c_vars
    c_obj = np.ones(c_vars)

    # Solve LP: minimize sum c subject to constraints
    res = linprog(c=c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')

    if not res.success:
        # fallback: set costs as max(0, min util over accepted logs assigned to actions)
        c_res = np.zeros(n_actions)
        for a in range(n_actions):
            idx_a = np.where(assigned_actions == a)[0]
            if len(idx_a) > 0:
                c_res[a] = max(0, min(p_candidates[a] @ contracts[i] for i in idx_a))
            else:
                c_res[a] = 0.0
    else:
        c_res = res.x

    # Step 6: Final agent setting: stack p_candidates and costs
    agent_setting = np.hstack([p_candidates, c_res[:, np.newaxis]])

    # Ensure numerical stability: normalize p rows again to sum=1 and costs >=0
    agent_setting[:, :m] = np.clip(agent_setting[:, :m], 0, None)
    agent_setting[:, :m] = agent_setting[:, :m] / agent_setting[:, :m].sum(axis=1, keepdims=True)
    agent_setting[:, -1] = np.clip(agent_setting[:, -1], 0, None)

    return agent_setting
```
