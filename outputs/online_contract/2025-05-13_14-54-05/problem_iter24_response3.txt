```python
import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from scipy.optimize import linprog

def agent_solver_v2(v: np.ndarray, content: list[dict]) -> np.ndarray:
    """
    Infer a valid agent setting matrix (actions x [probabilities over 5 outcomes + cost])
    that explains all historical interactions under IR and IC constraints.

    Args:
        v: np.ndarray of shape (5,), principal's reward vector for 5 outcomes.
        content: list of dicts, each with keys 'Contract' (list of 5 float payments),
                 'Principal Utility' (float), and 'Agent Action' (1 or -1).

    Returns:
        np.ndarray of shape (n_actions, 6), rows are [p1,...,p5,cost]
    """
    m = v.shape[0]
    logs_df = pd.DataFrame(content)

    accept_df = logs_df[logs_df['Agent Action'] == 1]
    reject_df = logs_df[logs_df['Agent Action'] == -1]

    # If no accepted contracts, return uniform distribution with zero cost
    if len(accept_df) == 0:
        p_uniform = np.ones(m) / m
        return np.array([np.append(p_uniform, 0.0)])

    accept_contracts = np.vstack(accept_df['Contract'].to_numpy())
    accept_putils = accept_df['Principal Utility'].to_numpy()
    reject_contracts = (
        np.vstack(reject_df['Contract'].to_numpy()) if len(reject_df) > 0 else np.empty((0, m))
    )

    # Robust normalization of accepted contracts by L1 norm for clustering stability
    accept_norms = np.linalg.norm(accept_contracts, ord=1, axis=1, keepdims=True)
    accept_norms[accept_norms < 1e-14] = 1.0  # avoid division by zero or very small norms
    norm_accept_contracts = accept_contracts / accept_norms

    def solve_p_for_accept(w: np.ndarray, pu: float) -> np.ndarray:
        # LP: find p s.t sum p=1, p@(v-w)=pu, 0<=p<=1
        A_eq = np.vstack([np.ones(m), v - w])
        b_eq = np.array([1.0, pu])
        bounds = [(0, 1) for _ in range(m)]
        res = linprog(c=np.zeros(m), A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs', options={"presolve": True})
        if res.success:
            p = res.x
            p = np.clip(p, 0, None)
            s = p.sum()
            if s > 0:
                p /= s
            else:
                p = np.ones(m) / m
            return p
        else:
            # fallback uniform if infeasible
            return np.ones(m) / m

    candidate_ps = np.array([solve_p_for_accept(w, pu) for w, pu in zip(accept_contracts, accept_putils)])

    # Normalize candidate_ps rows robustly for clustering stability
    candidate_ps = np.clip(candidate_ps, 0, None)
    row_sums = candidate_ps.sum(axis=1, keepdims=True)
    row_sums[row_sums < 1e-14] = 1.0
    candidate_ps /= row_sums

    max_clusters = min(10, len(candidate_ps))
    if max_clusters == 1:
        n_actions = 1
        p_centers = candidate_ps.mean(axis=0, keepdims=True)
        accept_assign = np.zeros(len(candidate_ps), dtype=int)
    else:
        inertias = []
        km_models = []
        for k in range(1, max_clusters + 1):
            kmeans = KMeans(n_clusters=k, random_state=0, n_init=20).fit(candidate_ps)
            inertias.append(kmeans.inertia_)
            km_models.append(kmeans)
        inertias = np.array(inertias)
        deltas = -np.diff(inertias)  # positive reductions
        if len(deltas) >= 2:
            ratios = deltas[1:] / (deltas[:-1] + 1e-14)
            elbow_candidates = np.where(ratios < 0.4)[0] + 2
            n_actions = elbow_candidates[0] if len(elbow_candidates) > 0 else max_clusters
        elif len(deltas) == 1:
            n_actions = 1 if deltas[0] < 1e-7 else 2
        else:
            n_actions = 1
        kmeans = km_models[n_actions - 1]
        p_centers = kmeans.cluster_centers_
        accept_assign = kmeans.predict(candidate_ps)

    # Remove empty clusters robustly and reindex accept_assign
    unique_clusters, counts = np.unique(accept_assign, return_counts=True)
    nonempty_clusters = unique_clusters[counts > 0]
    if len(nonempty_clusters) < n_actions:
        p_centers = p_centers[nonempty_clusters]
        n_actions = len(nonempty_clusters)
        mapping = {old: new for new, old in enumerate(nonempty_clusters)}
        accept_assign = np.array([mapping[a] for a in accept_assign])

    # Normalize p_centers rows robustly for numeric stability
    p_centers = np.clip(p_centers, 0, None)
    row_sums = p_centers.sum(axis=1, keepdims=True)
    row_sums[row_sums < 1e-14] = 1.0
    p_centers /= row_sums

    # Initialize costs from IR constraints (agent rationality on accepted contracts)
    costs = np.zeros(n_actions)
    ir_margin = 1e-11
    ic_margin_base = 1e-9
    max_iters = 300

    for a in range(n_actions):
        idxs = np.where(accept_assign == a)[0]
        if len(idxs) == 0:
            costs[a] = 0.0
            continue
        p_a = p_centers[a]
        payoffs = accept_contracts[idxs] @ p_a
        cost_upper_bound = np.min(payoffs) - ir_margin
        costs[a] = max(0.0, cost_upper_bound)

    # Iteratively refine costs to satisfy IR and IC strictly with adaptive margins
    for _ in range(max_iters):
        prev_costs = costs.copy()

        # Enforce IC constraints from rejected contracts:
        if reject_contracts.shape[0] > 0:
            rej_utils = reject_contracts @ p_centers.T  # shape (#rej, n_actions)
            max_rej_util = np.max(rej_utils, axis=0)
            # Adaptive margin proportional to scale of max rejected utility or base margin
            margins = np.maximum(ic_margin_base, ic_margin_base * np.maximum(1.0, np.abs(max_rej_util)))
            costs = np.maximum(costs, max_rej_util + margins)

        # Enforce IR constraints from accepted contracts:
        for a in range(n_actions):
            idxs = np.where(accept_assign == a)[0]
            if len(idxs) == 0:
                continue
            p_a = p_centers[a]
            payoffs = accept_contracts[idxs] @ p_a
            min_agent_util = np.min(payoffs - costs[a])
            if min_agent_util < ir_margin:
                costs[a] = max(0.0, costs[a] + (ir_margin - min_agent_util))

        # Break if costs converge within a very tight tolerance
        if np.all(np.abs(costs - prev_costs) < 1e-16):
            break

    costs = np.maximum(costs, 0.0)

    # Final normalization of p_centers for numeric stability
    p_centers = np.clip(p_centers, 0, None)
    row_sums = p_centers.sum(axis=1, keepdims=True)
    row_sums[row_sums < 1e-14] = 1.0
    p_centers /= row_sums

    agent_setting = np.hstack([p_centers, costs.reshape(-1, 1)])
    return agent_setting
```
